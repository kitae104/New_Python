{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 기본 케라스 구조 및 학습과정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. 사용할 패키지 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 데이터셋 생성하기\n",
    "* 원본 데이터를 불러오거나 시뮬레이션을 통해 데이터를 생성합니다.\n",
    "* 데이터로부터 훈련셋, 검증셋, 시험셋을 생성합니다.\n",
    "* 이 때 딥러닝 모델의 학습 및 평가를 할 수 있도록 포맷 변환을 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 훈련셋과 시험셋 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (50000, 28, 28)\n",
      "X_train (50000,)\n",
      "X_train (10000, 28, 28)\n",
      "X_train (10000,)\n"
     ]
    }
   ],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "# 훈련셋과 검증셋 분리\n",
    "X_val = X_train[50000:]        \n",
    "Y_val = Y_train[50000:]\n",
    "X_train = X_train[:50000]\n",
    "Y_train = Y_train[:50000]\n",
    "print('X_train', X_train.shape)\n",
    "print('X_train', Y_train.shape)\n",
    "print('X_train', X_val.shape)\n",
    "print('X_train', Y_val.shape)\n",
    "\n",
    "X_train = X_train.reshape(50000, 784).astype('float32') / 255.0\n",
    "X_val = X_val.reshape(10000, 784).astype('float32') / 255.0\n",
    "X_test = X_test.reshape(10000, 784).astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 훈련셋, 검증셋 고르기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rand_idxs = np.random.choice(50000, 700)\n",
    "val_rand_idxs = np.random.choice(10000, 300)\n",
    "\n",
    "X_train = X_train[train_rand_idxs]\n",
    "Y_train = Y_train[train_rand_idxs]\n",
    "X_val = X_val[val_rand_idxs]\n",
    "Y_val = Y_val[val_rand_idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 라벨 데이터 원핫인코딩 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = to_categorical(Y_train)\n",
    "Y_val = to_categorical(Y_val)\n",
    "Y_test = to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 모델 구성하기\n",
    "* 시퀀스 모델을 생성한 뒤 필요한 레이어를 추가하여 구성합니다.\n",
    "* 좀 더 복잡한 모델이 필요할 때는 케라스 함수 API를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 50,890\n",
      "Trainable params: 50,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=64, input_dim=28*28, activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 모델 학습과정 설정하기\n",
    "* 학습하기 전에 학습에 대한 설정을 수행합니다.\n",
    "* 손실 함수 및 최적화 방법을 정의합니다.\n",
    "* 케라스에서는 compile() 함수를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 모델 학습시키기\n",
    "* 훈련셋을 이용하여 구성한 모델로 학습시킵니다.\n",
    "* 케라스에서는 fit() 함수를 사용합니다.\n",
    "#### 4.1 배치사이즈\n",
    "* 몇 개를  처리하고 해답을 맞추는지를 의미함 \n",
    "    * 100 : 100개를 처리하고 해답을 맞춤\n",
    "    * 1: 1개를 처리하고 해답을 맞춤\n",
    "* 배치사이즈가 작을수록 갱신이 자주 발생함 \n",
    "#### 4.2 에폭\n",
    "* 같은 데이터셋으로 반복적으로 가중치를 갱신하면서 학습\n",
    "* 서로 다른 20문제를 1번 푸는 경우보다 같은 1문제를 20번 푸는 경우 정확도가 높다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1000\n",
      "700/700 [==============================] - 1s 863us/sample - loss: 2.0943 - accuracy: 0.3229 - val_loss: 1.8196 - val_accuracy: 0.5200\n",
      "Epoch 2/1000\n",
      "700/700 [==============================] - 0s 225us/sample - loss: 1.6207 - accuracy: 0.6114 - val_loss: 1.4456 - val_accuracy: 0.6533\n",
      "Epoch 3/1000\n",
      "700/700 [==============================] - 0s 225us/sample - loss: 1.2658 - accuracy: 0.7100 - val_loss: 1.1702 - val_accuracy: 0.6933\n",
      "Epoch 4/1000\n",
      "700/700 [==============================] - 0s 231us/sample - loss: 1.0268 - accuracy: 0.7571 - val_loss: 1.0025 - val_accuracy: 0.7300\n",
      "Epoch 5/1000\n",
      "700/700 [==============================] - 0s 204us/sample - loss: 0.8638 - accuracy: 0.7986 - val_loss: 0.8610 - val_accuracy: 0.7767\n",
      "Epoch 6/1000\n",
      "700/700 [==============================] - 0s 207us/sample - loss: 0.7519 - accuracy: 0.8343 - val_loss: 0.7909 - val_accuracy: 0.7800\n",
      "Epoch 7/1000\n",
      "700/700 [==============================] - 0s 215us/sample - loss: 0.6639 - accuracy: 0.8443 - val_loss: 0.7236 - val_accuracy: 0.8167\n",
      "Epoch 8/1000\n",
      "700/700 [==============================] - 0s 212us/sample - loss: 0.6037 - accuracy: 0.8586 - val_loss: 0.6915 - val_accuracy: 0.8067\n",
      "Epoch 9/1000\n",
      "700/700 [==============================] - 0s 188us/sample - loss: 0.5489 - accuracy: 0.8743 - val_loss: 0.6389 - val_accuracy: 0.8333\n",
      "Epoch 10/1000\n",
      "700/700 [==============================] - 0s 201us/sample - loss: 0.5093 - accuracy: 0.8786 - val_loss: 0.6091 - val_accuracy: 0.8500\n",
      "Epoch 11/1000\n",
      "700/700 [==============================] - 0s 235us/sample - loss: 0.4702 - accuracy: 0.8971 - val_loss: 0.5866 - val_accuracy: 0.8300\n",
      "Epoch 12/1000\n",
      "700/700 [==============================] - 0s 205us/sample - loss: 0.4384 - accuracy: 0.9057 - val_loss: 0.5723 - val_accuracy: 0.8400\n",
      "Epoch 13/1000\n",
      "700/700 [==============================] - 0s 229us/sample - loss: 0.4153 - accuracy: 0.9100 - val_loss: 0.5589 - val_accuracy: 0.8333\n",
      "Epoch 14/1000\n",
      "700/700 [==============================] - 0s 205us/sample - loss: 0.3880 - accuracy: 0.9243 - val_loss: 0.5365 - val_accuracy: 0.8400\n",
      "Epoch 15/1000\n",
      "700/700 [==============================] - 0s 215us/sample - loss: 0.3690 - accuracy: 0.9186 - val_loss: 0.5218 - val_accuracy: 0.8367\n",
      "Epoch 16/1000\n",
      "700/700 [==============================] - 0s 188us/sample - loss: 0.3497 - accuracy: 0.9329 - val_loss: 0.5167 - val_accuracy: 0.8333\n",
      "Epoch 17/1000\n",
      "700/700 [==============================] - 0s 212us/sample - loss: 0.3328 - accuracy: 0.9343 - val_loss: 0.5095 - val_accuracy: 0.8400\n",
      "Epoch 18/1000\n",
      "700/700 [==============================] - 0s 228us/sample - loss: 0.3165 - accuracy: 0.9414 - val_loss: 0.5019 - val_accuracy: 0.8300\n",
      "Epoch 19/1000\n",
      "700/700 [==============================] - 0s 224us/sample - loss: 0.3043 - accuracy: 0.9371 - val_loss: 0.4977 - val_accuracy: 0.8367\n",
      "Epoch 20/1000\n",
      "700/700 [==============================] - 0s 189us/sample - loss: 0.2893 - accuracy: 0.9443 - val_loss: 0.4949 - val_accuracy: 0.8333\n",
      "Epoch 21/1000\n",
      "700/700 [==============================] - 0s 219us/sample - loss: 0.2765 - accuracy: 0.9443 - val_loss: 0.4894 - val_accuracy: 0.8367\n",
      "Epoch 22/1000\n",
      "700/700 [==============================] - 0s 215us/sample - loss: 0.2639 - accuracy: 0.9514 - val_loss: 0.4856 - val_accuracy: 0.8400\n",
      "Epoch 23/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.2556 - accuracy: 0.9529 - val_loss: 0.4870 - val_accuracy: 0.8267\n",
      "Epoch 24/1000\n",
      "700/700 [==============================] - 0s 187us/sample - loss: 0.2435 - accuracy: 0.9514 - val_loss: 0.4845 - val_accuracy: 0.8300\n",
      "Epoch 25/1000\n",
      "700/700 [==============================] - 0s 228us/sample - loss: 0.2349 - accuracy: 0.9500 - val_loss: 0.4698 - val_accuracy: 0.8400\n",
      "Epoch 26/1000\n",
      "700/700 [==============================] - 0s 214us/sample - loss: 0.2254 - accuracy: 0.9586 - val_loss: 0.4820 - val_accuracy: 0.8300\n",
      "Epoch 27/1000\n",
      "700/700 [==============================] - 0s 194us/sample - loss: 0.2177 - accuracy: 0.9557 - val_loss: 0.4720 - val_accuracy: 0.8400\n",
      "Epoch 28/1000\n",
      "700/700 [==============================] - 0s 202us/sample - loss: 0.2080 - accuracy: 0.9600 - val_loss: 0.4739 - val_accuracy: 0.8367\n",
      "Epoch 29/1000\n",
      "700/700 [==============================] - 0s 202us/sample - loss: 0.2031 - accuracy: 0.9600 - val_loss: 0.4700 - val_accuracy: 0.8333\n",
      "Epoch 30/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.1952 - accuracy: 0.9643 - val_loss: 0.4737 - val_accuracy: 0.8333\n",
      "Epoch 31/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.1865 - accuracy: 0.9671 - val_loss: 0.4670 - val_accuracy: 0.8400\n",
      "Epoch 32/1000\n",
      "700/700 [==============================] - 0s 185us/sample - loss: 0.1817 - accuracy: 0.9671 - val_loss: 0.4693 - val_accuracy: 0.8300\n",
      "Epoch 33/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.1748 - accuracy: 0.9671 - val_loss: 0.4678 - val_accuracy: 0.8333\n",
      "Epoch 34/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.1690 - accuracy: 0.9700 - val_loss: 0.4681 - val_accuracy: 0.8400\n",
      "Epoch 35/1000\n",
      "700/700 [==============================] - 0s 188us/sample - loss: 0.1627 - accuracy: 0.9700 - val_loss: 0.4740 - val_accuracy: 0.8300\n",
      "Epoch 36/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.1577 - accuracy: 0.9743 - val_loss: 0.4705 - val_accuracy: 0.8533\n",
      "Epoch 37/1000\n",
      "700/700 [==============================] - 0s 187us/sample - loss: 0.1529 - accuracy: 0.9714 - val_loss: 0.4738 - val_accuracy: 0.8500\n",
      "Epoch 38/1000\n",
      "700/700 [==============================] - 0s 187us/sample - loss: 0.1477 - accuracy: 0.9771 - val_loss: 0.4736 - val_accuracy: 0.8500\n",
      "Epoch 39/1000\n",
      "700/700 [==============================] - 0s 217us/sample - loss: 0.1434 - accuracy: 0.9771 - val_loss: 0.4644 - val_accuracy: 0.8433\n",
      "Epoch 40/1000\n",
      "700/700 [==============================] - 0s 204us/sample - loss: 0.1394 - accuracy: 0.9800 - val_loss: 0.4674 - val_accuracy: 0.8433\n",
      "Epoch 41/1000\n",
      "700/700 [==============================] - 0s 198us/sample - loss: 0.1346 - accuracy: 0.9814 - val_loss: 0.4708 - val_accuracy: 0.8367\n",
      "Epoch 42/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.1314 - accuracy: 0.9800 - val_loss: 0.4703 - val_accuracy: 0.8333\n",
      "Epoch 43/1000\n",
      "700/700 [==============================] - 0s 191us/sample - loss: 0.1267 - accuracy: 0.9843 - val_loss: 0.4714 - val_accuracy: 0.8400\n",
      "Epoch 44/1000\n",
      "700/700 [==============================] - 0s 201us/sample - loss: 0.1224 - accuracy: 0.9814 - val_loss: 0.4714 - val_accuracy: 0.8367\n",
      "Epoch 45/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.1195 - accuracy: 0.9843 - val_loss: 0.4722 - val_accuracy: 0.8467\n",
      "Epoch 46/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.1154 - accuracy: 0.9857 - val_loss: 0.4748 - val_accuracy: 0.8433\n",
      "Epoch 47/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.1116 - accuracy: 0.9900 - val_loss: 0.4697 - val_accuracy: 0.8433\n",
      "Epoch 48/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.1095 - accuracy: 0.9857 - val_loss: 0.4736 - val_accuracy: 0.8367\n",
      "Epoch 49/1000\n",
      "700/700 [==============================] - 0s 185us/sample - loss: 0.1055 - accuracy: 0.9886 - val_loss: 0.4774 - val_accuracy: 0.8400\n",
      "Epoch 50/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.1026 - accuracy: 0.9929 - val_loss: 0.4735 - val_accuracy: 0.8500\n",
      "Epoch 51/1000\n",
      "700/700 [==============================] - 0s 207us/sample - loss: 0.1005 - accuracy: 0.9886 - val_loss: 0.4733 - val_accuracy: 0.8467\n",
      "Epoch 52/1000\n",
      "700/700 [==============================] - 0s 207us/sample - loss: 0.0972 - accuracy: 0.9914 - val_loss: 0.4748 - val_accuracy: 0.8400\n",
      "Epoch 53/1000\n",
      "700/700 [==============================] - 0s 202us/sample - loss: 0.0944 - accuracy: 0.9943 - val_loss: 0.4733 - val_accuracy: 0.8400\n",
      "Epoch 54/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0926 - accuracy: 0.9943 - val_loss: 0.4712 - val_accuracy: 0.8467\n",
      "Epoch 55/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0897 - accuracy: 0.9929 - val_loss: 0.4763 - val_accuracy: 0.8500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/1000\n",
      "700/700 [==============================] - 0s 208us/sample - loss: 0.0871 - accuracy: 0.9943 - val_loss: 0.4812 - val_accuracy: 0.8433\n",
      "Epoch 57/1000\n",
      "700/700 [==============================] - 0s 209us/sample - loss: 0.0846 - accuracy: 0.9957 - val_loss: 0.4817 - val_accuracy: 0.8433\n",
      "Epoch 58/1000\n",
      "700/700 [==============================] - 0s 197us/sample - loss: 0.0831 - accuracy: 0.9971 - val_loss: 0.4809 - val_accuracy: 0.8433\n",
      "Epoch 59/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0805 - accuracy: 0.9986 - val_loss: 0.4822 - val_accuracy: 0.8467\n",
      "Epoch 60/1000\n",
      "700/700 [==============================] - 0s 175us/sample - loss: 0.0787 - accuracy: 0.9986 - val_loss: 0.4793 - val_accuracy: 0.8500\n",
      "Epoch 61/1000\n",
      "700/700 [==============================] - 0s 191us/sample - loss: 0.0766 - accuracy: 0.9971 - val_loss: 0.4874 - val_accuracy: 0.8433\n",
      "Epoch 62/1000\n",
      "700/700 [==============================] - 0s 221us/sample - loss: 0.0749 - accuracy: 0.9971 - val_loss: 0.4861 - val_accuracy: 0.8467\n",
      "Epoch 63/1000\n",
      "700/700 [==============================] - 0s 221us/sample - loss: 0.0731 - accuracy: 0.9986 - val_loss: 0.4881 - val_accuracy: 0.8400\n",
      "Epoch 64/1000\n",
      "700/700 [==============================] - 0s 191us/sample - loss: 0.0712 - accuracy: 0.9986 - val_loss: 0.4875 - val_accuracy: 0.8467\n",
      "Epoch 65/1000\n",
      "700/700 [==============================] - 0s 177us/sample - loss: 0.0697 - accuracy: 0.9986 - val_loss: 0.4876 - val_accuracy: 0.8467\n",
      "Epoch 66/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0677 - accuracy: 1.0000 - val_loss: 0.4935 - val_accuracy: 0.8467\n",
      "Epoch 67/1000\n",
      "700/700 [==============================] - 0s 194us/sample - loss: 0.0664 - accuracy: 1.0000 - val_loss: 0.4917 - val_accuracy: 0.8367\n",
      "Epoch 68/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0651 - accuracy: 1.0000 - val_loss: 0.4915 - val_accuracy: 0.8467\n",
      "Epoch 69/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0635 - accuracy: 1.0000 - val_loss: 0.4936 - val_accuracy: 0.8433\n",
      "Epoch 70/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0619 - accuracy: 1.0000 - val_loss: 0.4899 - val_accuracy: 0.8467\n",
      "Epoch 71/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0607 - accuracy: 1.0000 - val_loss: 0.4953 - val_accuracy: 0.8367\n",
      "Epoch 72/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0595 - accuracy: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.8467\n",
      "Epoch 73/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0580 - accuracy: 1.0000 - val_loss: 0.4913 - val_accuracy: 0.8533\n",
      "Epoch 74/1000\n",
      "700/700 [==============================] - 0s 188us/sample - loss: 0.0570 - accuracy: 1.0000 - val_loss: 0.4934 - val_accuracy: 0.8467\n",
      "Epoch 75/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0557 - accuracy: 1.0000 - val_loss: 0.4985 - val_accuracy: 0.8367\n",
      "Epoch 76/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0546 - accuracy: 1.0000 - val_loss: 0.4956 - val_accuracy: 0.8500\n",
      "Epoch 77/1000\n",
      "700/700 [==============================] - 0s 185us/sample - loss: 0.0536 - accuracy: 1.0000 - val_loss: 0.4965 - val_accuracy: 0.8467\n",
      "Epoch 78/1000\n",
      "700/700 [==============================] - 0s 188us/sample - loss: 0.0525 - accuracy: 1.0000 - val_loss: 0.5003 - val_accuracy: 0.8467\n",
      "Epoch 79/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0511 - accuracy: 1.0000 - val_loss: 0.4995 - val_accuracy: 0.8367\n",
      "Epoch 80/1000\n",
      "700/700 [==============================] - 0s 187us/sample - loss: 0.0503 - accuracy: 1.0000 - val_loss: 0.5021 - val_accuracy: 0.8467\n",
      "Epoch 81/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0493 - accuracy: 1.0000 - val_loss: 0.5032 - val_accuracy: 0.8400\n",
      "Epoch 82/1000\n",
      "700/700 [==============================] - 0s 177us/sample - loss: 0.0483 - accuracy: 1.0000 - val_loss: 0.5022 - val_accuracy: 0.8433\n",
      "Epoch 83/1000\n",
      "700/700 [==============================] - 0s 188us/sample - loss: 0.0473 - accuracy: 1.0000 - val_loss: 0.5018 - val_accuracy: 0.8433\n",
      "Epoch 84/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0465 - accuracy: 1.0000 - val_loss: 0.5014 - val_accuracy: 0.8433\n",
      "Epoch 85/1000\n",
      "700/700 [==============================] - 0s 188us/sample - loss: 0.0457 - accuracy: 1.0000 - val_loss: 0.5054 - val_accuracy: 0.8467\n",
      "Epoch 86/1000\n",
      "700/700 [==============================] - 0s 185us/sample - loss: 0.0449 - accuracy: 1.0000 - val_loss: 0.5042 - val_accuracy: 0.8467\n",
      "Epoch 87/1000\n",
      "700/700 [==============================] - 0s 187us/sample - loss: 0.0441 - accuracy: 1.0000 - val_loss: 0.5035 - val_accuracy: 0.8467\n",
      "Epoch 88/1000\n",
      "700/700 [==============================] - 0s 188us/sample - loss: 0.0431 - accuracy: 1.0000 - val_loss: 0.5060 - val_accuracy: 0.8467\n",
      "Epoch 89/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0426 - accuracy: 1.0000 - val_loss: 0.5073 - val_accuracy: 0.8400\n",
      "Epoch 90/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0419 - accuracy: 1.0000 - val_loss: 0.5077 - val_accuracy: 0.8400\n",
      "Epoch 91/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0410 - accuracy: 1.0000 - val_loss: 0.5099 - val_accuracy: 0.8467\n",
      "Epoch 92/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0405 - accuracy: 1.0000 - val_loss: 0.5087 - val_accuracy: 0.8400\n",
      "Epoch 93/1000\n",
      "700/700 [==============================] - 0s 195us/sample - loss: 0.0396 - accuracy: 1.0000 - val_loss: 0.5108 - val_accuracy: 0.8400\n",
      "Epoch 94/1000\n",
      "700/700 [==============================] - 0s 191us/sample - loss: 0.0390 - accuracy: 1.0000 - val_loss: 0.5091 - val_accuracy: 0.8433\n",
      "Epoch 95/1000\n",
      "700/700 [==============================] - 0s 188us/sample - loss: 0.0384 - accuracy: 1.0000 - val_loss: 0.5111 - val_accuracy: 0.8433\n",
      "Epoch 96/1000\n",
      "700/700 [==============================] - 0s 189us/sample - loss: 0.0378 - accuracy: 1.0000 - val_loss: 0.5137 - val_accuracy: 0.8433\n",
      "Epoch 97/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0369 - accuracy: 1.0000 - val_loss: 0.5123 - val_accuracy: 0.8533\n",
      "Epoch 98/1000\n",
      "700/700 [==============================] - 0s 185us/sample - loss: 0.0366 - accuracy: 1.0000 - val_loss: 0.5151 - val_accuracy: 0.8400\n",
      "Epoch 99/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0360 - accuracy: 1.0000 - val_loss: 0.5151 - val_accuracy: 0.8467\n",
      "Epoch 100/1000\n",
      "700/700 [==============================] - 0s 187us/sample - loss: 0.0355 - accuracy: 1.0000 - val_loss: 0.5135 - val_accuracy: 0.8433\n",
      "Epoch 101/1000\n",
      "700/700 [==============================] - 0s 187us/sample - loss: 0.0349 - accuracy: 1.0000 - val_loss: 0.5163 - val_accuracy: 0.8433\n",
      "Epoch 102/1000\n",
      "700/700 [==============================] - 0s 191us/sample - loss: 0.0344 - accuracy: 1.0000 - val_loss: 0.5165 - val_accuracy: 0.8467\n",
      "Epoch 103/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0339 - accuracy: 1.0000 - val_loss: 0.5157 - val_accuracy: 0.8467\n",
      "Epoch 104/1000\n",
      "700/700 [==============================] - 0s 188us/sample - loss: 0.0333 - accuracy: 1.0000 - val_loss: 0.5163 - val_accuracy: 0.8433\n",
      "Epoch 105/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0328 - accuracy: 1.0000 - val_loss: 0.5163 - val_accuracy: 0.8433\n",
      "Epoch 106/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0322 - accuracy: 1.0000 - val_loss: 0.5163 - val_accuracy: 0.8500\n",
      "Epoch 107/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0319 - accuracy: 1.0000 - val_loss: 0.5176 - val_accuracy: 0.8400\n",
      "Epoch 108/1000\n",
      "700/700 [==============================] - 0s 189us/sample - loss: 0.0314 - accuracy: 1.0000 - val_loss: 0.5197 - val_accuracy: 0.8367\n",
      "Epoch 109/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0310 - accuracy: 1.0000 - val_loss: 0.5203 - val_accuracy: 0.8400\n",
      "Epoch 110/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0306 - accuracy: 1.0000 - val_loss: 0.5205 - val_accuracy: 0.8433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0301 - accuracy: 1.0000 - val_loss: 0.5217 - val_accuracy: 0.8433\n",
      "Epoch 112/1000\n",
      "700/700 [==============================] - 0s 189us/sample - loss: 0.0298 - accuracy: 1.0000 - val_loss: 0.5207 - val_accuracy: 0.8400\n",
      "Epoch 113/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0293 - accuracy: 1.0000 - val_loss: 0.5231 - val_accuracy: 0.8433\n",
      "Epoch 114/1000\n",
      "700/700 [==============================] - 0s 195us/sample - loss: 0.0289 - accuracy: 1.0000 - val_loss: 0.5219 - val_accuracy: 0.8433\n",
      "Epoch 115/1000\n",
      "700/700 [==============================] - 0s 177us/sample - loss: 0.0285 - accuracy: 1.0000 - val_loss: 0.5247 - val_accuracy: 0.8433\n",
      "Epoch 116/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0282 - accuracy: 1.0000 - val_loss: 0.5248 - val_accuracy: 0.8467\n",
      "Epoch 117/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0278 - accuracy: 1.0000 - val_loss: 0.5240 - val_accuracy: 0.8433\n",
      "Epoch 118/1000\n",
      "700/700 [==============================] - 0s 175us/sample - loss: 0.0273 - accuracy: 1.0000 - val_loss: 0.5252 - val_accuracy: 0.8500\n",
      "Epoch 119/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0271 - accuracy: 1.0000 - val_loss: 0.5253 - val_accuracy: 0.8467\n",
      "Epoch 120/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0267 - accuracy: 1.0000 - val_loss: 0.5268 - val_accuracy: 0.8500\n",
      "Epoch 121/1000\n",
      "700/700 [==============================] - 0s 195us/sample - loss: 0.0264 - accuracy: 1.0000 - val_loss: 0.5270 - val_accuracy: 0.8500\n",
      "Epoch 122/1000\n",
      "700/700 [==============================] - 0s 202us/sample - loss: 0.0261 - accuracy: 1.0000 - val_loss: 0.5278 - val_accuracy: 0.8467\n",
      "Epoch 123/1000\n",
      "700/700 [==============================] - 0s 201us/sample - loss: 0.0257 - accuracy: 1.0000 - val_loss: 0.5295 - val_accuracy: 0.8400\n",
      "Epoch 124/1000\n",
      "700/700 [==============================] - 0s 207us/sample - loss: 0.0254 - accuracy: 1.0000 - val_loss: 0.5298 - val_accuracy: 0.8467\n",
      "Epoch 125/1000\n",
      "700/700 [==============================] - 0s 198us/sample - loss: 0.0251 - accuracy: 1.0000 - val_loss: 0.5290 - val_accuracy: 0.8467\n",
      "Epoch 126/1000\n",
      "700/700 [==============================] - 0s 201us/sample - loss: 0.0248 - accuracy: 1.0000 - val_loss: 0.5298 - val_accuracy: 0.8467\n",
      "Epoch 127/1000\n",
      "700/700 [==============================] - 0s 211us/sample - loss: 0.0245 - accuracy: 1.0000 - val_loss: 0.5311 - val_accuracy: 0.8467\n",
      "Epoch 128/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0243 - accuracy: 1.0000 - val_loss: 0.5323 - val_accuracy: 0.8467\n",
      "Epoch 129/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0239 - accuracy: 1.0000 - val_loss: 0.5336 - val_accuracy: 0.8533\n",
      "Epoch 130/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0237 - accuracy: 1.0000 - val_loss: 0.5324 - val_accuracy: 0.8467\n",
      "Epoch 131/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0234 - accuracy: 1.0000 - val_loss: 0.5340 - val_accuracy: 0.8500\n",
      "Epoch 132/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0231 - accuracy: 1.0000 - val_loss: 0.5341 - val_accuracy: 0.8433\n",
      "Epoch 133/1000\n",
      "700/700 [==============================] - 0s 194us/sample - loss: 0.0228 - accuracy: 1.0000 - val_loss: 0.5339 - val_accuracy: 0.8400\n",
      "Epoch 134/1000\n",
      "700/700 [==============================] - 0s 199us/sample - loss: 0.0226 - accuracy: 1.0000 - val_loss: 0.5353 - val_accuracy: 0.8433\n",
      "Epoch 135/1000\n",
      "700/700 [==============================] - 0s 189us/sample - loss: 0.0223 - accuracy: 1.0000 - val_loss: 0.5357 - val_accuracy: 0.8400\n",
      "Epoch 136/1000\n",
      "700/700 [==============================] - 0s 202us/sample - loss: 0.0221 - accuracy: 1.0000 - val_loss: 0.5360 - val_accuracy: 0.8433\n",
      "Epoch 137/1000\n",
      "700/700 [==============================] - 0s 205us/sample - loss: 0.0219 - accuracy: 1.0000 - val_loss: 0.5356 - val_accuracy: 0.8433\n",
      "Epoch 138/1000\n",
      "700/700 [==============================] - 0s 224us/sample - loss: 0.0216 - accuracy: 1.0000 - val_loss: 0.5364 - val_accuracy: 0.8467\n",
      "Epoch 139/1000\n",
      "700/700 [==============================] - 0s 188us/sample - loss: 0.0214 - accuracy: 1.0000 - val_loss: 0.5363 - val_accuracy: 0.8433\n",
      "Epoch 140/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0211 - accuracy: 1.0000 - val_loss: 0.5389 - val_accuracy: 0.8433\n",
      "Epoch 141/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0209 - accuracy: 1.0000 - val_loss: 0.5379 - val_accuracy: 0.8500\n",
      "Epoch 142/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0207 - accuracy: 1.0000 - val_loss: 0.5383 - val_accuracy: 0.8433\n",
      "Epoch 143/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0205 - accuracy: 1.0000 - val_loss: 0.5391 - val_accuracy: 0.8467\n",
      "Epoch 144/1000\n",
      "700/700 [==============================] - 0s 185us/sample - loss: 0.0203 - accuracy: 1.0000 - val_loss: 0.5403 - val_accuracy: 0.8467\n",
      "Epoch 145/1000\n",
      "700/700 [==============================] - 0s 198us/sample - loss: 0.0201 - accuracy: 1.0000 - val_loss: 0.5404 - val_accuracy: 0.8433\n",
      "Epoch 146/1000\n",
      "700/700 [==============================] - 0s 211us/sample - loss: 0.0198 - accuracy: 1.0000 - val_loss: 0.5402 - val_accuracy: 0.8433\n",
      "Epoch 147/1000\n",
      "700/700 [==============================] - 0s 201us/sample - loss: 0.0196 - accuracy: 1.0000 - val_loss: 0.5411 - val_accuracy: 0.8500\n",
      "Epoch 148/1000\n",
      "700/700 [==============================] - 0s 175us/sample - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.5415 - val_accuracy: 0.8433\n",
      "Epoch 149/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.5430 - val_accuracy: 0.8467\n",
      "Epoch 150/1000\n",
      "700/700 [==============================] - 0s 185us/sample - loss: 0.0191 - accuracy: 1.0000 - val_loss: 0.5437 - val_accuracy: 0.8500\n",
      "Epoch 151/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.5431 - val_accuracy: 0.8433\n",
      "Epoch 152/1000\n",
      "700/700 [==============================] - 0s 185us/sample - loss: 0.0187 - accuracy: 1.0000 - val_loss: 0.5447 - val_accuracy: 0.8467\n",
      "Epoch 153/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0185 - accuracy: 1.0000 - val_loss: 0.5451 - val_accuracy: 0.8467\n",
      "Epoch 154/1000\n",
      "700/700 [==============================] - 0s 207us/sample - loss: 0.0183 - accuracy: 1.0000 - val_loss: 0.5458 - val_accuracy: 0.8467\n",
      "Epoch 155/1000\n",
      "700/700 [==============================] - 0s 228us/sample - loss: 0.0181 - accuracy: 1.0000 - val_loss: 0.5451 - val_accuracy: 0.8500\n",
      "Epoch 156/1000\n",
      "700/700 [==============================] - 0s 215us/sample - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.5463 - val_accuracy: 0.8500\n",
      "Epoch 157/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.5463 - val_accuracy: 0.8500\n",
      "Epoch 158/1000\n",
      "700/700 [==============================] - 0s 194us/sample - loss: 0.0176 - accuracy: 1.0000 - val_loss: 0.5486 - val_accuracy: 0.8500\n",
      "Epoch 159/1000\n",
      "700/700 [==============================] - 0s 191us/sample - loss: 0.0175 - accuracy: 1.0000 - val_loss: 0.5479 - val_accuracy: 0.8500\n",
      "Epoch 160/1000\n",
      "700/700 [==============================] - 0s 214us/sample - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.5492 - val_accuracy: 0.8467\n",
      "Epoch 161/1000\n",
      "700/700 [==============================] - 0s 219us/sample - loss: 0.0172 - accuracy: 1.0000 - val_loss: 0.5491 - val_accuracy: 0.8500\n",
      "Epoch 162/1000\n",
      "700/700 [==============================] - 0s 201us/sample - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.5489 - val_accuracy: 0.8500\n",
      "Epoch 163/1000\n",
      "700/700 [==============================] - 0s 195us/sample - loss: 0.0168 - accuracy: 1.0000 - val_loss: 0.5489 - val_accuracy: 0.8467\n",
      "Epoch 164/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.5489 - val_accuracy: 0.8467\n",
      "Epoch 165/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 187us/sample - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.5515 - val_accuracy: 0.8467\n",
      "Epoch 166/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.5521 - val_accuracy: 0.8467\n",
      "Epoch 167/1000\n",
      "700/700 [==============================] - 0s 225us/sample - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.5525 - val_accuracy: 0.8467\n",
      "Epoch 168/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.5527 - val_accuracy: 0.8500\n",
      "Epoch 169/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.5534 - val_accuracy: 0.8467\n",
      "Epoch 170/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.5539 - val_accuracy: 0.8467\n",
      "Epoch 171/1000\n",
      "700/700 [==============================] - 0s 185us/sample - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.5536 - val_accuracy: 0.8467\n",
      "Epoch 172/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.5538 - val_accuracy: 0.8467\n",
      "Epoch 173/1000\n",
      "700/700 [==============================] - 0s 185us/sample - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.5542 - val_accuracy: 0.8467\n",
      "Epoch 174/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.5544 - val_accuracy: 0.8467\n",
      "Epoch 175/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.5550 - val_accuracy: 0.8467\n",
      "Epoch 176/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.5550 - val_accuracy: 0.8467\n",
      "Epoch 177/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.5559 - val_accuracy: 0.8467\n",
      "Epoch 178/1000\n",
      "700/700 [==============================] - 0s 177us/sample - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.5561 - val_accuracy: 0.8500\n",
      "Epoch 179/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.5567 - val_accuracy: 0.8467\n",
      "Epoch 180/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.5578 - val_accuracy: 0.8467\n",
      "Epoch 181/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.5568 - val_accuracy: 0.8467\n",
      "Epoch 182/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.5585 - val_accuracy: 0.8500\n",
      "Epoch 183/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.5594 - val_accuracy: 0.8467\n",
      "Epoch 184/1000\n",
      "700/700 [==============================] - 0s 185us/sample - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.5593 - val_accuracy: 0.8467\n",
      "Epoch 185/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.5600 - val_accuracy: 0.8467\n",
      "Epoch 186/1000\n",
      "700/700 [==============================] - 0s 175us/sample - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.5605 - val_accuracy: 0.8467\n",
      "Epoch 187/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.5605 - val_accuracy: 0.8467\n",
      "Epoch 188/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.5611 - val_accuracy: 0.8467\n",
      "Epoch 189/1000\n",
      "700/700 [==============================] - 0s 189us/sample - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.5613 - val_accuracy: 0.8467\n",
      "Epoch 190/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.5621 - val_accuracy: 0.8467\n",
      "Epoch 191/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.5628 - val_accuracy: 0.8467\n",
      "Epoch 192/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.5630 - val_accuracy: 0.8467\n",
      "Epoch 193/1000\n",
      "700/700 [==============================] - 0s 177us/sample - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.5629 - val_accuracy: 0.8500\n",
      "Epoch 194/1000\n",
      "700/700 [==============================] - 0s 175us/sample - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.5629 - val_accuracy: 0.8533\n",
      "Epoch 195/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.5639 - val_accuracy: 0.8467\n",
      "Epoch 196/1000\n",
      "700/700 [==============================] - 0s 212us/sample - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.5637 - val_accuracy: 0.8467\n",
      "Epoch 197/1000\n",
      "700/700 [==============================] - 0s 248us/sample - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.5649 - val_accuracy: 0.8500\n",
      "Epoch 198/1000\n",
      "700/700 [==============================] - 0s 209us/sample - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.5654 - val_accuracy: 0.8467\n",
      "Epoch 199/1000\n",
      "700/700 [==============================] - 0s 189us/sample - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.5656 - val_accuracy: 0.8467\n",
      "Epoch 200/1000\n",
      "700/700 [==============================] - 0s 177us/sample - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.5664 - val_accuracy: 0.8467\n",
      "Epoch 201/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.5663 - val_accuracy: 0.8467\n",
      "Epoch 202/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.5662 - val_accuracy: 0.8467\n",
      "Epoch 203/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.5670 - val_accuracy: 0.8467\n",
      "Epoch 204/1000\n",
      "700/700 [==============================] - 0s 214us/sample - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.5676 - val_accuracy: 0.8467\n",
      "Epoch 205/1000\n",
      "700/700 [==============================] - 0s 224us/sample - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.5681 - val_accuracy: 0.8500\n",
      "Epoch 206/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.5681 - val_accuracy: 0.8500\n",
      "Epoch 207/1000\n",
      "700/700 [==============================] - 0s 202us/sample - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.5676 - val_accuracy: 0.8500\n",
      "Epoch 208/1000\n",
      "700/700 [==============================] - 0s 199us/sample - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.5684 - val_accuracy: 0.8500\n",
      "Epoch 209/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.5694 - val_accuracy: 0.8467\n",
      "Epoch 210/1000\n",
      "700/700 [==============================] - 0s 201us/sample - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.5700 - val_accuracy: 0.8467\n",
      "Epoch 211/1000\n",
      "700/700 [==============================] - 0s 202us/sample - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.5703 - val_accuracy: 0.8467\n",
      "Epoch 212/1000\n",
      "700/700 [==============================] - 0s 188us/sample - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.5710 - val_accuracy: 0.8433\n",
      "Epoch 213/1000\n",
      "700/700 [==============================] - 0s 211us/sample - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.5712 - val_accuracy: 0.8467\n",
      "Epoch 214/1000\n",
      "700/700 [==============================] - 0s 208us/sample - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.5710 - val_accuracy: 0.8467\n",
      "Epoch 215/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.5717 - val_accuracy: 0.8467\n",
      "Epoch 216/1000\n",
      "700/700 [==============================] - 0s 204us/sample - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.5721 - val_accuracy: 0.8533\n",
      "Epoch 217/1000\n",
      "700/700 [==============================] - 0s 209us/sample - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.5730 - val_accuracy: 0.8467\n",
      "Epoch 218/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.5730 - val_accuracy: 0.8467\n",
      "Epoch 219/1000\n",
      "700/700 [==============================] - 0s 207us/sample - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.5734 - val_accuracy: 0.8500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 220/1000\n",
      "700/700 [==============================] - 0s 199us/sample - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.5738 - val_accuracy: 0.8500\n",
      "Epoch 221/1000\n",
      "700/700 [==============================] - 0s 188us/sample - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.5732 - val_accuracy: 0.8500\n",
      "Epoch 222/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.5739 - val_accuracy: 0.8500\n",
      "Epoch 223/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.5752 - val_accuracy: 0.8467\n",
      "Epoch 224/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.5752 - val_accuracy: 0.8533\n",
      "Epoch 225/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.5755 - val_accuracy: 0.8533\n",
      "Epoch 226/1000\n",
      "700/700 [==============================] - 0s 185us/sample - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.5755 - val_accuracy: 0.8500\n",
      "Epoch 227/1000\n",
      "700/700 [==============================] - 0s 192us/sample - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.5759 - val_accuracy: 0.8467\n",
      "Epoch 228/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.5760 - val_accuracy: 0.8467\n",
      "Epoch 229/1000\n",
      "700/700 [==============================] - 0s 188us/sample - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.5758 - val_accuracy: 0.8500\n",
      "Epoch 230/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.5764 - val_accuracy: 0.8467\n",
      "Epoch 231/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.5770 - val_accuracy: 0.8500\n",
      "Epoch 232/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.5772 - val_accuracy: 0.8533\n",
      "Epoch 233/1000\n",
      "700/700 [==============================] - 0s 185us/sample - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.5774 - val_accuracy: 0.8500\n",
      "Epoch 234/1000\n",
      "700/700 [==============================] - 0s 197us/sample - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.5778 - val_accuracy: 0.8500\n",
      "Epoch 235/1000\n",
      "700/700 [==============================] - 0s 201us/sample - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.5789 - val_accuracy: 0.8500\n",
      "Epoch 236/1000\n",
      "700/700 [==============================] - 0s 189us/sample - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.5791 - val_accuracy: 0.8467\n",
      "Epoch 237/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.5793 - val_accuracy: 0.8533\n",
      "Epoch 238/1000\n",
      "700/700 [==============================] - 0s 177us/sample - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.5796 - val_accuracy: 0.8467\n",
      "Epoch 239/1000\n",
      "700/700 [==============================] - 0s 192us/sample - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.5799 - val_accuracy: 0.8500\n",
      "Epoch 240/1000\n",
      "700/700 [==============================] - 0s 197us/sample - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.5803 - val_accuracy: 0.8500\n",
      "Epoch 241/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.5801 - val_accuracy: 0.8500\n",
      "Epoch 242/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.5806 - val_accuracy: 0.8500\n",
      "Epoch 243/1000\n",
      "700/700 [==============================] - 0s 201us/sample - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.5812 - val_accuracy: 0.8467\n",
      "Epoch 244/1000\n",
      "700/700 [==============================] - 0s 209us/sample - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.5821 - val_accuracy: 0.8500\n",
      "Epoch 245/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.5819 - val_accuracy: 0.8500\n",
      "Epoch 246/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.5821 - val_accuracy: 0.8500\n",
      "Epoch 247/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.5828 - val_accuracy: 0.8500\n",
      "Epoch 248/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.5832 - val_accuracy: 0.8467\n",
      "Epoch 249/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.5830 - val_accuracy: 0.8533\n",
      "Epoch 250/1000\n",
      "700/700 [==============================] - 0s 195us/sample - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.5837 - val_accuracy: 0.8533\n",
      "Epoch 251/1000\n",
      "700/700 [==============================] - 0s 191us/sample - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.5836 - val_accuracy: 0.8500\n",
      "Epoch 252/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.5837 - val_accuracy: 0.8533\n",
      "Epoch 253/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.5841 - val_accuracy: 0.8533\n",
      "Epoch 254/1000\n",
      "700/700 [==============================] - 0s 188us/sample - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.5848 - val_accuracy: 0.8500\n",
      "Epoch 255/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.5854 - val_accuracy: 0.8500\n",
      "Epoch 256/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.5856 - val_accuracy: 0.8500\n",
      "Epoch 257/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.5855 - val_accuracy: 0.8500\n",
      "Epoch 258/1000\n",
      "700/700 [==============================] - 0s 208us/sample - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.5862 - val_accuracy: 0.8500\n",
      "Epoch 259/1000\n",
      "700/700 [==============================] - 0s 194us/sample - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.5866 - val_accuracy: 0.8500\n",
      "Epoch 260/1000\n",
      "700/700 [==============================] - 0s 199us/sample - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.5869 - val_accuracy: 0.8467\n",
      "Epoch 261/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.5869 - val_accuracy: 0.8500\n",
      "Epoch 262/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.5871 - val_accuracy: 0.8500\n",
      "Epoch 263/1000\n",
      "700/700 [==============================] - 0s 185us/sample - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.5873 - val_accuracy: 0.8533\n",
      "Epoch 264/1000\n",
      "700/700 [==============================] - 0s 197us/sample - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.5875 - val_accuracy: 0.8533\n",
      "Epoch 265/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.5884 - val_accuracy: 0.8500\n",
      "Epoch 266/1000\n",
      "700/700 [==============================] - 0s 185us/sample - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.5886 - val_accuracy: 0.8500\n",
      "Epoch 267/1000\n",
      "700/700 [==============================] - 0s 185us/sample - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.5892 - val_accuracy: 0.8500\n",
      "Epoch 268/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.5893 - val_accuracy: 0.8500\n",
      "Epoch 269/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.5892 - val_accuracy: 0.8500\n",
      "Epoch 270/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.5897 - val_accuracy: 0.8500\n",
      "Epoch 271/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.5902 - val_accuracy: 0.8500\n",
      "Epoch 272/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.5905 - val_accuracy: 0.8500\n",
      "Epoch 273/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.5909 - val_accuracy: 0.8500\n",
      "Epoch 274/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.5912 - val_accuracy: 0.8500\n",
      "Epoch 275/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.5916 - val_accuracy: 0.8500\n",
      "Epoch 276/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.5916 - val_accuracy: 0.8500\n",
      "Epoch 277/1000\n",
      "700/700 [==============================] - 0s 187us/sample - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.5920 - val_accuracy: 0.8500\n",
      "Epoch 278/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.5923 - val_accuracy: 0.8500\n",
      "Epoch 279/1000\n",
      "700/700 [==============================] - 0s 199us/sample - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.5926 - val_accuracy: 0.8500\n",
      "Epoch 280/1000\n",
      "700/700 [==============================] - 0s 191us/sample - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.5931 - val_accuracy: 0.8500\n",
      "Epoch 281/1000\n",
      "700/700 [==============================] - 0s 189us/sample - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.5936 - val_accuracy: 0.8500\n",
      "Epoch 282/1000\n",
      "700/700 [==============================] - 0s 197us/sample - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.5934 - val_accuracy: 0.8500\n",
      "Epoch 283/1000\n",
      "700/700 [==============================] - 0s 177us/sample - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.5940 - val_accuracy: 0.8500\n",
      "Epoch 284/1000\n",
      "700/700 [==============================] - 0s 192us/sample - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.5944 - val_accuracy: 0.8500\n",
      "Epoch 285/1000\n",
      "700/700 [==============================] - 0s 188us/sample - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.5946 - val_accuracy: 0.8500\n",
      "Epoch 286/1000\n",
      "700/700 [==============================] - 0s 195us/sample - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.5952 - val_accuracy: 0.8500\n",
      "Epoch 287/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.5952 - val_accuracy: 0.8500\n",
      "Epoch 288/1000\n",
      "700/700 [==============================] - 0s 187us/sample - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.5950 - val_accuracy: 0.8500\n",
      "Epoch 289/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.5957 - val_accuracy: 0.8500\n",
      "Epoch 290/1000\n",
      "700/700 [==============================] - 0s 188us/sample - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.5958 - val_accuracy: 0.8500\n",
      "Epoch 291/1000\n",
      "700/700 [==============================] - 0s 187us/sample - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.5960 - val_accuracy: 0.8500\n",
      "Epoch 292/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.5961 - val_accuracy: 0.8500\n",
      "Epoch 293/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.5966 - val_accuracy: 0.8500\n",
      "Epoch 294/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.5968 - val_accuracy: 0.8500\n",
      "Epoch 295/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.5969 - val_accuracy: 0.8500\n",
      "Epoch 296/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.5971 - val_accuracy: 0.8500\n",
      "Epoch 297/1000\n",
      "700/700 [==============================] - 0s 198us/sample - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.5973 - val_accuracy: 0.8500\n",
      "Epoch 298/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.5977 - val_accuracy: 0.8500\n",
      "Epoch 299/1000\n",
      "700/700 [==============================] - 0s 185us/sample - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.5979 - val_accuracy: 0.8500\n",
      "Epoch 300/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.5984 - val_accuracy: 0.8500\n",
      "Epoch 301/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.5993 - val_accuracy: 0.8500\n",
      "Epoch 302/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.5991 - val_accuracy: 0.8500\n",
      "Epoch 303/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.5992 - val_accuracy: 0.8500\n",
      "Epoch 304/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.5995 - val_accuracy: 0.8500\n",
      "Epoch 305/1000\n",
      "700/700 [==============================] - 0s 187us/sample - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.5998 - val_accuracy: 0.8500\n",
      "Epoch 306/1000\n",
      "700/700 [==============================] - 0s 207us/sample - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.5999 - val_accuracy: 0.8500\n",
      "Epoch 307/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.6003 - val_accuracy: 0.8500\n",
      "Epoch 308/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.6004 - val_accuracy: 0.8500\n",
      "Epoch 309/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.6006 - val_accuracy: 0.8500\n",
      "Epoch 310/1000\n",
      "700/700 [==============================] - 0s 195us/sample - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.6010 - val_accuracy: 0.8500\n",
      "Epoch 311/1000\n",
      "700/700 [==============================] - 0s 198us/sample - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.6013 - val_accuracy: 0.8500\n",
      "Epoch 312/1000\n",
      "700/700 [==============================] - 0s 185us/sample - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.6014 - val_accuracy: 0.8500\n",
      "Epoch 313/1000\n",
      "700/700 [==============================] - 0s 185us/sample - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.6015 - val_accuracy: 0.8500\n",
      "Epoch 314/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.6020 - val_accuracy: 0.8500\n",
      "Epoch 315/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.6026 - val_accuracy: 0.8500\n",
      "Epoch 316/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.6030 - val_accuracy: 0.8500\n",
      "Epoch 317/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.6031 - val_accuracy: 0.8500\n",
      "Epoch 318/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.6034 - val_accuracy: 0.8500\n",
      "Epoch 319/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.6035 - val_accuracy: 0.8500\n",
      "Epoch 320/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.6036 - val_accuracy: 0.8500\n",
      "Epoch 321/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.6043 - val_accuracy: 0.8500\n",
      "Epoch 322/1000\n",
      "700/700 [==============================] - 0s 195us/sample - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.6044 - val_accuracy: 0.8500\n",
      "Epoch 323/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.6046 - val_accuracy: 0.8500\n",
      "Epoch 324/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.6047 - val_accuracy: 0.8500\n",
      "Epoch 325/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.6051 - val_accuracy: 0.8500\n",
      "Epoch 326/1000\n",
      "700/700 [==============================] - 0s 189us/sample - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.6052 - val_accuracy: 0.8500\n",
      "Epoch 327/1000\n",
      "700/700 [==============================] - 0s 192us/sample - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.6057 - val_accuracy: 0.8500\n",
      "Epoch 328/1000\n",
      "700/700 [==============================] - 0s 204us/sample - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.6057 - val_accuracy: 0.8500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329/1000\n",
      "700/700 [==============================] - 0s 228us/sample - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.6061 - val_accuracy: 0.8500\n",
      "Epoch 330/1000\n",
      "700/700 [==============================] - 0s 208us/sample - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.6062 - val_accuracy: 0.8500\n",
      "Epoch 331/1000\n",
      "700/700 [==============================] - 0s 218us/sample - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.6061 - val_accuracy: 0.8500\n",
      "Epoch 332/1000\n",
      "700/700 [==============================] - 0s 227us/sample - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.6063 - val_accuracy: 0.8500\n",
      "Epoch 333/1000\n",
      "700/700 [==============================] - 0s 192us/sample - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.6067 - val_accuracy: 0.8500\n",
      "Epoch 334/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.6068 - val_accuracy: 0.8500\n",
      "Epoch 335/1000\n",
      "700/700 [==============================] - 0s 205us/sample - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.6075 - val_accuracy: 0.8500\n",
      "Epoch 336/1000\n",
      "700/700 [==============================] - 0s 219us/sample - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.6079 - val_accuracy: 0.8500\n",
      "Epoch 337/1000\n",
      "700/700 [==============================] - 0s 192us/sample - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.6081 - val_accuracy: 0.8500\n",
      "Epoch 338/1000\n",
      "700/700 [==============================] - 0s 199us/sample - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.6084 - val_accuracy: 0.8500\n",
      "Epoch 339/1000\n",
      "700/700 [==============================] - 0s 201us/sample - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.6084 - val_accuracy: 0.8500\n",
      "Epoch 340/1000\n",
      "700/700 [==============================] - 0s 215us/sample - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.6087 - val_accuracy: 0.8500\n",
      "Epoch 341/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.6090 - val_accuracy: 0.8500\n",
      "Epoch 342/1000\n",
      "700/700 [==============================] - 0s 228us/sample - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.6094 - val_accuracy: 0.8500\n",
      "Epoch 343/1000\n",
      "700/700 [==============================] - 0s 204us/sample - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.6097 - val_accuracy: 0.8500\n",
      "Epoch 344/1000\n",
      "700/700 [==============================] - 0s 189us/sample - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.6097 - val_accuracy: 0.8500\n",
      "Epoch 345/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.6101 - val_accuracy: 0.8500\n",
      "Epoch 346/1000\n",
      "700/700 [==============================] - 0s 191us/sample - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.6103 - val_accuracy: 0.8500\n",
      "Epoch 347/1000\n",
      "700/700 [==============================] - 0s 214us/sample - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.6102 - val_accuracy: 0.8500\n",
      "Epoch 348/1000\n",
      "700/700 [==============================] - 0s 199us/sample - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.6104 - val_accuracy: 0.8500\n",
      "Epoch 349/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.6110 - val_accuracy: 0.8500\n",
      "Epoch 350/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.6113 - val_accuracy: 0.8500\n",
      "Epoch 351/1000\n",
      "700/700 [==============================] - 0s 191us/sample - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.6115 - val_accuracy: 0.8500\n",
      "Epoch 352/1000\n",
      "700/700 [==============================] - 0s 204us/sample - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.6116 - val_accuracy: 0.8500\n",
      "Epoch 353/1000\n",
      "700/700 [==============================] - 0s 198us/sample - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.6119 - val_accuracy: 0.8500\n",
      "Epoch 354/1000\n",
      "700/700 [==============================] - 0s 191us/sample - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.6123 - val_accuracy: 0.8500\n",
      "Epoch 355/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.6124 - val_accuracy: 0.8500\n",
      "Epoch 356/1000\n",
      "700/700 [==============================] - 0s 192us/sample - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.6126 - val_accuracy: 0.8500\n",
      "Epoch 357/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.6127 - val_accuracy: 0.8500\n",
      "Epoch 358/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.6129 - val_accuracy: 0.8500\n",
      "Epoch 359/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.6131 - val_accuracy: 0.8500\n",
      "Epoch 360/1000\n",
      "700/700 [==============================] - 0s 189us/sample - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.6130 - val_accuracy: 0.8500\n",
      "Epoch 361/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.6137 - val_accuracy: 0.8500\n",
      "Epoch 362/1000\n",
      "700/700 [==============================] - 0s 202us/sample - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.6139 - val_accuracy: 0.8500\n",
      "Epoch 363/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.6141 - val_accuracy: 0.8500\n",
      "Epoch 364/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.6143 - val_accuracy: 0.8500\n",
      "Epoch 365/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.6145 - val_accuracy: 0.8500\n",
      "Epoch 366/1000\n",
      "700/700 [==============================] - 0s 188us/sample - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.6148 - val_accuracy: 0.8500\n",
      "Epoch 367/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.6149 - val_accuracy: 0.8500\n",
      "Epoch 368/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.6152 - val_accuracy: 0.8500\n",
      "Epoch 369/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.6154 - val_accuracy: 0.8500\n",
      "Epoch 370/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.6155 - val_accuracy: 0.8500\n",
      "Epoch 371/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.6155 - val_accuracy: 0.8500\n",
      "Epoch 372/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.6158 - val_accuracy: 0.8500\n",
      "Epoch 373/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.6161 - val_accuracy: 0.8500\n",
      "Epoch 374/1000\n",
      "700/700 [==============================] - 0s 185us/sample - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.6163 - val_accuracy: 0.8500\n",
      "Epoch 375/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.6165 - val_accuracy: 0.8500\n",
      "Epoch 376/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.6171 - val_accuracy: 0.8500\n",
      "Epoch 377/1000\n",
      "700/700 [==============================] - 0s 188us/sample - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.6174 - val_accuracy: 0.8500\n",
      "Epoch 378/1000\n",
      "700/700 [==============================] - 0s 187us/sample - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.6175 - val_accuracy: 0.8500\n",
      "Epoch 379/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.6175 - val_accuracy: 0.8500\n",
      "Epoch 380/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.6178 - val_accuracy: 0.8500\n",
      "Epoch 381/1000\n",
      "700/700 [==============================] - 0s 188us/sample - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.6179 - val_accuracy: 0.8500\n",
      "Epoch 382/1000\n",
      "700/700 [==============================] - 0s 187us/sample - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.6182 - val_accuracy: 0.8500\n",
      "Epoch 383/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.6182 - val_accuracy: 0.8500\n",
      "Epoch 384/1000\n",
      "700/700 [==============================] - 0s 197us/sample - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.6187 - val_accuracy: 0.8500\n",
      "Epoch 385/1000\n",
      "700/700 [==============================] - 0s 205us/sample - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.6188 - val_accuracy: 0.8500\n",
      "Epoch 386/1000\n",
      "700/700 [==============================] - 0s 209us/sample - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.6191 - val_accuracy: 0.8500\n",
      "Epoch 387/1000\n",
      "700/700 [==============================] - 0s 232us/sample - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.6193 - val_accuracy: 0.8500\n",
      "Epoch 388/1000\n",
      "700/700 [==============================] - 0s 207us/sample - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.6195 - val_accuracy: 0.8500\n",
      "Epoch 389/1000\n",
      "700/700 [==============================] - 0s 211us/sample - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.6196 - val_accuracy: 0.8500\n",
      "Epoch 390/1000\n",
      "700/700 [==============================] - 0s 204us/sample - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.6195 - val_accuracy: 0.8500\n",
      "Epoch 391/1000\n",
      "700/700 [==============================] - 0s 229us/sample - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.6198 - val_accuracy: 0.8500\n",
      "Epoch 392/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.6200 - val_accuracy: 0.8500\n",
      "Epoch 393/1000\n",
      "700/700 [==============================] - 0s 195us/sample - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.6201 - val_accuracy: 0.8500\n",
      "Epoch 394/1000\n",
      "700/700 [==============================] - 0s 211us/sample - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.6202 - val_accuracy: 0.8500\n",
      "Epoch 395/1000\n",
      "700/700 [==============================] - 0s 212us/sample - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.6205 - val_accuracy: 0.8500\n",
      "Epoch 396/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.6208 - val_accuracy: 0.8500\n",
      "Epoch 397/1000\n",
      "700/700 [==============================] - 0s 185us/sample - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.6213 - val_accuracy: 0.8500\n",
      "Epoch 398/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.6217 - val_accuracy: 0.8500\n",
      "Epoch 399/1000\n",
      "700/700 [==============================] - 0s 195us/sample - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.6219 - val_accuracy: 0.8500\n",
      "Epoch 400/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.6222 - val_accuracy: 0.8500\n",
      "Epoch 401/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.6225 - val_accuracy: 0.8500\n",
      "Epoch 402/1000\n",
      "700/700 [==============================] - 0s 215us/sample - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.6225 - val_accuracy: 0.8500\n",
      "Epoch 403/1000\n",
      "700/700 [==============================] - 0s 204us/sample - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.6225 - val_accuracy: 0.8500\n",
      "Epoch 404/1000\n",
      "700/700 [==============================] - 0s 208us/sample - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.6226 - val_accuracy: 0.8500\n",
      "Epoch 405/1000\n",
      "700/700 [==============================] - 0s 188us/sample - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.6227 - val_accuracy: 0.8500\n",
      "Epoch 406/1000\n",
      "700/700 [==============================] - 0s 204us/sample - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.6231 - val_accuracy: 0.8500\n",
      "Epoch 407/1000\n",
      "700/700 [==============================] - 0s 205us/sample - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.6235 - val_accuracy: 0.8500\n",
      "Epoch 408/1000\n",
      "700/700 [==============================] - 0s 197us/sample - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.6237 - val_accuracy: 0.8500\n",
      "Epoch 409/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.6237 - val_accuracy: 0.8500\n",
      "Epoch 410/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.6239 - val_accuracy: 0.8500\n",
      "Epoch 411/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.6242 - val_accuracy: 0.8500\n",
      "Epoch 412/1000\n",
      "700/700 [==============================] - 0s 185us/sample - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.6245 - val_accuracy: 0.8500\n",
      "Epoch 413/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.6245 - val_accuracy: 0.8500\n",
      "Epoch 414/1000\n",
      "700/700 [==============================] - 0s 187us/sample - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.6247 - val_accuracy: 0.8500\n",
      "Epoch 415/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.6250 - val_accuracy: 0.8500\n",
      "Epoch 416/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.6251 - val_accuracy: 0.8500\n",
      "Epoch 417/1000\n",
      "700/700 [==============================] - 0s 188us/sample - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.6253 - val_accuracy: 0.8500\n",
      "Epoch 418/1000\n",
      "700/700 [==============================] - 0s 185us/sample - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.6254 - val_accuracy: 0.8500\n",
      "Epoch 419/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.6256 - val_accuracy: 0.8500\n",
      "Epoch 420/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.6260 - val_accuracy: 0.8500\n",
      "Epoch 421/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.6262 - val_accuracy: 0.8500\n",
      "Epoch 422/1000\n",
      "700/700 [==============================] - 0s 187us/sample - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.6264 - val_accuracy: 0.8500\n",
      "Epoch 423/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.6265 - val_accuracy: 0.8500\n",
      "Epoch 424/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.6267 - val_accuracy: 0.8500\n",
      "Epoch 425/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.6270 - val_accuracy: 0.8500\n",
      "Epoch 426/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.6273 - val_accuracy: 0.8500\n",
      "Epoch 427/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.6273 - val_accuracy: 0.8500\n",
      "Epoch 428/1000\n",
      "700/700 [==============================] - 0s 185us/sample - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.6275 - val_accuracy: 0.8500\n",
      "Epoch 429/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.6279 - val_accuracy: 0.8500\n",
      "Epoch 430/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.6278 - val_accuracy: 0.8500\n",
      "Epoch 431/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.6282 - val_accuracy: 0.8500\n",
      "Epoch 432/1000\n",
      "700/700 [==============================] - 0s 195us/sample - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.6281 - val_accuracy: 0.8500\n",
      "Epoch 433/1000\n",
      "700/700 [==============================] - 0s 189us/sample - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.6285 - val_accuracy: 0.8500\n",
      "Epoch 434/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.6286 - val_accuracy: 0.8500\n",
      "Epoch 435/1000\n",
      "700/700 [==============================] - 0s 185us/sample - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.6288 - val_accuracy: 0.8500\n",
      "Epoch 436/1000\n",
      "700/700 [==============================] - 0s 192us/sample - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.6290 - val_accuracy: 0.8500\n",
      "Epoch 437/1000\n",
      "700/700 [==============================] - 0s 189us/sample - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.6291 - val_accuracy: 0.8500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 438/1000\n",
      "700/700 [==============================] - 0s 192us/sample - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.6295 - val_accuracy: 0.8500\n",
      "Epoch 439/1000\n",
      "700/700 [==============================] - 0s 185us/sample - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.6296 - val_accuracy: 0.8500\n",
      "Epoch 440/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.6298 - val_accuracy: 0.8500\n",
      "Epoch 441/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.6301 - val_accuracy: 0.8500\n",
      "Epoch 442/1000\n",
      "700/700 [==============================] - 0s 188us/sample - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.6301 - val_accuracy: 0.8500\n",
      "Epoch 443/1000\n",
      "700/700 [==============================] - 0s 191us/sample - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.6304 - val_accuracy: 0.8500\n",
      "Epoch 444/1000\n",
      "700/700 [==============================] - 0s 195us/sample - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.6306 - val_accuracy: 0.8500\n",
      "Epoch 445/1000\n",
      "700/700 [==============================] - 0s 209us/sample - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.6306 - val_accuracy: 0.8500\n",
      "Epoch 446/1000\n",
      "700/700 [==============================] - 0s 192us/sample - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.6309 - val_accuracy: 0.8500\n",
      "Epoch 447/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.6311 - val_accuracy: 0.8500\n",
      "Epoch 448/1000\n",
      "700/700 [==============================] - 0s 188us/sample - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.6312 - val_accuracy: 0.8500\n",
      "Epoch 449/1000\n",
      "700/700 [==============================] - 0s 185us/sample - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.6312 - val_accuracy: 0.8500\n",
      "Epoch 450/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.6313 - val_accuracy: 0.8500\n",
      "Epoch 451/1000\n",
      "700/700 [==============================] - 0s 185us/sample - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.6317 - val_accuracy: 0.8500\n",
      "Epoch 452/1000\n",
      "700/700 [==============================] - 0s 187us/sample - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.6320 - val_accuracy: 0.8500\n",
      "Epoch 453/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.6322 - val_accuracy: 0.8500\n",
      "Epoch 454/1000\n",
      "700/700 [==============================] - 0s 191us/sample - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.6323 - val_accuracy: 0.8500\n",
      "Epoch 455/1000\n",
      "700/700 [==============================] - 0s 195us/sample - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.6327 - val_accuracy: 0.8500\n",
      "Epoch 456/1000\n",
      "700/700 [==============================] - 0s 195us/sample - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.6326 - val_accuracy: 0.8500\n",
      "Epoch 457/1000\n",
      "700/700 [==============================] - 0s 195us/sample - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.6329 - val_accuracy: 0.8500\n",
      "Epoch 458/1000\n",
      "700/700 [==============================] - 0s 192us/sample - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.6331 - val_accuracy: 0.8500\n",
      "Epoch 459/1000\n",
      "700/700 [==============================] - 0s 198us/sample - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.6331 - val_accuracy: 0.8500\n",
      "Epoch 460/1000\n",
      "700/700 [==============================] - 0s 188us/sample - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.6334 - val_accuracy: 0.8500\n",
      "Epoch 461/1000\n",
      "700/700 [==============================] - 0s 194us/sample - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.6335 - val_accuracy: 0.8500\n",
      "Epoch 462/1000\n",
      "700/700 [==============================] - 0s 197us/sample - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.6337 - val_accuracy: 0.8500\n",
      "Epoch 463/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.6338 - val_accuracy: 0.8500\n",
      "Epoch 464/1000\n",
      "700/700 [==============================] - 0s 194us/sample - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.6338 - val_accuracy: 0.8500\n",
      "Epoch 465/1000\n",
      "700/700 [==============================] - 0s 197us/sample - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.6341 - val_accuracy: 0.8500\n",
      "Epoch 466/1000\n",
      "700/700 [==============================] - 0s 189us/sample - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.6343 - val_accuracy: 0.8500\n",
      "Epoch 467/1000\n",
      "700/700 [==============================] - 0s 209us/sample - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.6346 - val_accuracy: 0.8500\n",
      "Epoch 468/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.6347 - val_accuracy: 0.8500\n",
      "Epoch 469/1000\n",
      "700/700 [==============================] - 0s 194us/sample - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.6347 - val_accuracy: 0.8500\n",
      "Epoch 470/1000\n",
      "700/700 [==============================] - 0s 197us/sample - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.6350 - val_accuracy: 0.8500\n",
      "Epoch 471/1000\n",
      "700/700 [==============================] - 0s 191us/sample - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.6352 - val_accuracy: 0.8500\n",
      "Epoch 472/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.6355 - val_accuracy: 0.8500\n",
      "Epoch 473/1000\n",
      "700/700 [==============================] - 0s 188us/sample - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.6357 - val_accuracy: 0.8500\n",
      "Epoch 474/1000\n",
      "700/700 [==============================] - 0s 205us/sample - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.6358 - val_accuracy: 0.8500\n",
      "Epoch 475/1000\n",
      "700/700 [==============================] - 0s 188us/sample - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.6360 - val_accuracy: 0.8500\n",
      "Epoch 476/1000\n",
      "700/700 [==============================] - 0s 204us/sample - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.6362 - val_accuracy: 0.8500\n",
      "Epoch 477/1000\n",
      "700/700 [==============================] - 0s 199us/sample - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.6363 - val_accuracy: 0.8500\n",
      "Epoch 478/1000\n",
      "700/700 [==============================] - 0s 198us/sample - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.6366 - val_accuracy: 0.8500\n",
      "Epoch 479/1000\n",
      "700/700 [==============================] - 0s 188us/sample - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.6368 - val_accuracy: 0.8500\n",
      "Epoch 480/1000\n",
      "700/700 [==============================] - 0s 194us/sample - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.6371 - val_accuracy: 0.8500\n",
      "Epoch 481/1000\n",
      "700/700 [==============================] - 0s 187us/sample - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.6371 - val_accuracy: 0.8500\n",
      "Epoch 482/1000\n",
      "700/700 [==============================] - 0s 204us/sample - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.6372 - val_accuracy: 0.8500\n",
      "Epoch 483/1000\n",
      "700/700 [==============================] - 0s 187us/sample - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.6375 - val_accuracy: 0.8500\n",
      "Epoch 484/1000\n",
      "700/700 [==============================] - 0s 208us/sample - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.6377 - val_accuracy: 0.8500\n",
      "Epoch 485/1000\n",
      "700/700 [==============================] - 0s 189us/sample - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.6378 - val_accuracy: 0.8500\n",
      "Epoch 486/1000\n",
      "700/700 [==============================] - 0s 188us/sample - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.6381 - val_accuracy: 0.8500\n",
      "Epoch 487/1000\n",
      "700/700 [==============================] - 0s 192us/sample - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.6382 - val_accuracy: 0.8500\n",
      "Epoch 488/1000\n",
      "700/700 [==============================] - 0s 187us/sample - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.6383 - val_accuracy: 0.8500\n",
      "Epoch 489/1000\n",
      "700/700 [==============================] - 0s 189us/sample - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.6383 - val_accuracy: 0.8500\n",
      "Epoch 490/1000\n",
      "700/700 [==============================] - 0s 209us/sample - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.6386 - val_accuracy: 0.8500\n",
      "Epoch 491/1000\n",
      "700/700 [==============================] - 0s 194us/sample - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.6387 - val_accuracy: 0.8500\n",
      "Epoch 492/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.6388 - val_accuracy: 0.8500\n",
      "Epoch 493/1000\n",
      "700/700 [==============================] - 0s 197us/sample - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.6389 - val_accuracy: 0.8500\n",
      "Epoch 494/1000\n",
      "700/700 [==============================] - 0s 191us/sample - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.6391 - val_accuracy: 0.8500\n",
      "Epoch 495/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.6395 - val_accuracy: 0.8500\n",
      "Epoch 496/1000\n",
      "700/700 [==============================] - 0s 195us/sample - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.6397 - val_accuracy: 0.8500\n",
      "Epoch 497/1000\n",
      "700/700 [==============================] - 0s 198us/sample - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.6397 - val_accuracy: 0.8500\n",
      "Epoch 498/1000\n",
      "700/700 [==============================] - 0s 187us/sample - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.6401 - val_accuracy: 0.8533\n",
      "Epoch 499/1000\n",
      "700/700 [==============================] - 0s 199us/sample - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.6403 - val_accuracy: 0.8533\n",
      "Epoch 500/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.6405 - val_accuracy: 0.8533\n",
      "Epoch 501/1000\n",
      "700/700 [==============================] - 0s 202us/sample - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.6406 - val_accuracy: 0.8533\n",
      "Epoch 502/1000\n",
      "700/700 [==============================] - 0s 192us/sample - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.6406 - val_accuracy: 0.8533\n",
      "Epoch 503/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.6409 - val_accuracy: 0.8533\n",
      "Epoch 504/1000\n",
      "700/700 [==============================] - 0s 185us/sample - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.6409 - val_accuracy: 0.8533\n",
      "Epoch 505/1000\n",
      "700/700 [==============================] - 0s 188us/sample - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.6411 - val_accuracy: 0.8533\n",
      "Epoch 506/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.6412 - val_accuracy: 0.8533\n",
      "Epoch 507/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.6414 - val_accuracy: 0.8533\n",
      "Epoch 508/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.6415 - val_accuracy: 0.8533\n",
      "Epoch 509/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.6417 - val_accuracy: 0.8533\n",
      "Epoch 510/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.6420 - val_accuracy: 0.8533\n",
      "Epoch 511/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.6422 - val_accuracy: 0.8533\n",
      "Epoch 512/1000\n",
      "700/700 [==============================] - 0s 189us/sample - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.6424 - val_accuracy: 0.8533\n",
      "Epoch 513/1000\n",
      "700/700 [==============================] - 0s 192us/sample - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.6426 - val_accuracy: 0.8533\n",
      "Epoch 514/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.6426 - val_accuracy: 0.8533\n",
      "Epoch 515/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.6427 - val_accuracy: 0.8533\n",
      "Epoch 516/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.6429 - val_accuracy: 0.8533\n",
      "Epoch 517/1000\n",
      "700/700 [==============================] - 0s 187us/sample - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.6431 - val_accuracy: 0.8533\n",
      "Epoch 518/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.6433 - val_accuracy: 0.8533\n",
      "Epoch 519/1000\n",
      "700/700 [==============================] - 0s 185us/sample - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.6433 - val_accuracy: 0.8533\n",
      "Epoch 520/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.6436 - val_accuracy: 0.8533\n",
      "Epoch 521/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.6437 - val_accuracy: 0.8533\n",
      "Epoch 522/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.6438 - val_accuracy: 0.8533\n",
      "Epoch 523/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.6440 - val_accuracy: 0.8533\n",
      "Epoch 524/1000\n",
      "700/700 [==============================] - 0s 195us/sample - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.6441 - val_accuracy: 0.8533\n",
      "Epoch 525/1000\n",
      "700/700 [==============================] - 0s 187us/sample - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.6441 - val_accuracy: 0.8533\n",
      "Epoch 526/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.6443 - val_accuracy: 0.8533\n",
      "Epoch 527/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.6447 - val_accuracy: 0.8533\n",
      "Epoch 528/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.6449 - val_accuracy: 0.8533\n",
      "Epoch 529/1000\n",
      "700/700 [==============================] - 0s 192us/sample - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.6449 - val_accuracy: 0.8533\n",
      "Epoch 530/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.6450 - val_accuracy: 0.8533\n",
      "Epoch 531/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.6452 - val_accuracy: 0.8533\n",
      "Epoch 532/1000\n",
      "700/700 [==============================] - 0s 201us/sample - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.6454 - val_accuracy: 0.8533\n",
      "Epoch 533/1000\n",
      "700/700 [==============================] - 0s 194us/sample - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.6457 - val_accuracy: 0.8533\n",
      "Epoch 534/1000\n",
      "700/700 [==============================] - 0s 185us/sample - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.6460 - val_accuracy: 0.8533\n",
      "Epoch 535/1000\n",
      "700/700 [==============================] - 0s 188us/sample - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.6461 - val_accuracy: 0.8533\n",
      "Epoch 536/1000\n",
      "700/700 [==============================] - 0s 198us/sample - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.6462 - val_accuracy: 0.8533\n",
      "Epoch 537/1000\n",
      "700/700 [==============================] - 0s 187us/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.6463 - val_accuracy: 0.8533\n",
      "Epoch 538/1000\n",
      "700/700 [==============================] - 0s 185us/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.6465 - val_accuracy: 0.8533\n",
      "Epoch 539/1000\n",
      "700/700 [==============================] - 0s 189us/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.6465 - val_accuracy: 0.8533\n",
      "Epoch 540/1000\n",
      "700/700 [==============================] - 0s 197us/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.6466 - val_accuracy: 0.8533\n",
      "Epoch 541/1000\n",
      "700/700 [==============================] - 0s 185us/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.6469 - val_accuracy: 0.8533\n",
      "Epoch 542/1000\n",
      "700/700 [==============================] - 0s 191us/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.6471 - val_accuracy: 0.8533\n",
      "Epoch 543/1000\n",
      "700/700 [==============================] - 0s 192us/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.6472 - val_accuracy: 0.8533\n",
      "Epoch 544/1000\n",
      "700/700 [==============================] - 0s 191us/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.6475 - val_accuracy: 0.8533\n",
      "Epoch 545/1000\n",
      "700/700 [==============================] - 0s 185us/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.6476 - val_accuracy: 0.8533\n",
      "Epoch 546/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.6477 - val_accuracy: 0.8533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 547/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.6478 - val_accuracy: 0.8533\n",
      "Epoch 548/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.6479 - val_accuracy: 0.8533\n",
      "Epoch 549/1000\n",
      "700/700 [==============================] - 0s 185us/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.6481 - val_accuracy: 0.8533\n",
      "Epoch 550/1000\n",
      "700/700 [==============================] - 0s 189us/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.6483 - val_accuracy: 0.8533\n",
      "Epoch 551/1000\n",
      "700/700 [==============================] - 0s 187us/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.6484 - val_accuracy: 0.8533\n",
      "Epoch 552/1000\n",
      "700/700 [==============================] - 0s 185us/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.6485 - val_accuracy: 0.8533\n",
      "Epoch 553/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.6486 - val_accuracy: 0.8533\n",
      "Epoch 554/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.6488 - val_accuracy: 0.8533\n",
      "Epoch 555/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.6489 - val_accuracy: 0.8533\n",
      "Epoch 556/1000\n",
      "700/700 [==============================] - 0s 189us/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.6491 - val_accuracy: 0.8533\n",
      "Epoch 557/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.6492 - val_accuracy: 0.8533\n",
      "Epoch 558/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.6494 - val_accuracy: 0.8533\n",
      "Epoch 559/1000\n",
      "700/700 [==============================] - 0s 188us/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.6495 - val_accuracy: 0.8533\n",
      "Epoch 560/1000\n",
      "700/700 [==============================] - 0s 187us/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.6496 - val_accuracy: 0.8533\n",
      "Epoch 561/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.6498 - val_accuracy: 0.8533\n",
      "Epoch 562/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.6500 - val_accuracy: 0.8533\n",
      "Epoch 563/1000\n",
      "700/700 [==============================] - 0s 187us/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.6503 - val_accuracy: 0.8533\n",
      "Epoch 564/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.6502 - val_accuracy: 0.8533\n",
      "Epoch 565/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.6504 - val_accuracy: 0.8533\n",
      "Epoch 566/1000\n",
      "700/700 [==============================] - 0s 185us/sample - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.6505 - val_accuracy: 0.8533\n",
      "Epoch 567/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.6507 - val_accuracy: 0.8533\n",
      "Epoch 568/1000\n",
      "700/700 [==============================] - 0s 187us/sample - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.6508 - val_accuracy: 0.8533\n",
      "Epoch 569/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.6511 - val_accuracy: 0.8533\n",
      "Epoch 570/1000\n",
      "700/700 [==============================] - 0s 192us/sample - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.6512 - val_accuracy: 0.8533\n",
      "Epoch 571/1000\n",
      "700/700 [==============================] - 0s 188us/sample - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.6513 - val_accuracy: 0.8533\n",
      "Epoch 572/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.6515 - val_accuracy: 0.8533\n",
      "Epoch 573/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.6516 - val_accuracy: 0.8533\n",
      "Epoch 574/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.6518 - val_accuracy: 0.8533\n",
      "Epoch 575/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.6519 - val_accuracy: 0.8533\n",
      "Epoch 576/1000\n",
      "700/700 [==============================] - 0s 185us/sample - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.6522 - val_accuracy: 0.8533\n",
      "Epoch 577/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.6521 - val_accuracy: 0.8533\n",
      "Epoch 578/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.6523 - val_accuracy: 0.8533\n",
      "Epoch 579/1000\n",
      "700/700 [==============================] - 0s 189us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.6524 - val_accuracy: 0.8533\n",
      "Epoch 580/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.6525 - val_accuracy: 0.8533\n",
      "Epoch 581/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.6527 - val_accuracy: 0.8533\n",
      "Epoch 582/1000\n",
      "700/700 [==============================] - 0s 188us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.6527 - val_accuracy: 0.8533\n",
      "Epoch 583/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.6528 - val_accuracy: 0.8533\n",
      "Epoch 584/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.6530 - val_accuracy: 0.8533\n",
      "Epoch 585/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.6531 - val_accuracy: 0.8533\n",
      "Epoch 586/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.6532 - val_accuracy: 0.8533\n",
      "Epoch 587/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.6535 - val_accuracy: 0.8533\n",
      "Epoch 588/1000\n",
      "700/700 [==============================] - 0s 185us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.6536 - val_accuracy: 0.8533\n",
      "Epoch 589/1000\n",
      "700/700 [==============================] - 0s 187us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.6537 - val_accuracy: 0.8533\n",
      "Epoch 590/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.6539 - val_accuracy: 0.8533\n",
      "Epoch 591/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.6543 - val_accuracy: 0.8533\n",
      "Epoch 592/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.6544 - val_accuracy: 0.8533\n",
      "Epoch 593/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.6544 - val_accuracy: 0.8533\n",
      "Epoch 594/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.6545 - val_accuracy: 0.8533\n",
      "Epoch 595/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.6547 - val_accuracy: 0.8533\n",
      "Epoch 596/1000\n",
      "700/700 [==============================] - 0s 191us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.6549 - val_accuracy: 0.8533\n",
      "Epoch 597/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.6550 - val_accuracy: 0.8533\n",
      "Epoch 598/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.6552 - val_accuracy: 0.8533\n",
      "Epoch 599/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.6553 - val_accuracy: 0.8533\n",
      "Epoch 600/1000\n",
      "700/700 [==============================] - 0s 187us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.6555 - val_accuracy: 0.8533\n",
      "Epoch 601/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.6556 - val_accuracy: 0.8533\n",
      "Epoch 602/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.6558 - val_accuracy: 0.8533\n",
      "Epoch 603/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.6559 - val_accuracy: 0.8533\n",
      "Epoch 604/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.6560 - val_accuracy: 0.8533\n",
      "Epoch 605/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.6561 - val_accuracy: 0.8533\n",
      "Epoch 606/1000\n",
      "700/700 [==============================] - 0s 185us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.6562 - val_accuracy: 0.8533\n",
      "Epoch 607/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.6563 - val_accuracy: 0.8533\n",
      "Epoch 608/1000\n",
      "700/700 [==============================] - 0s 187us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.6564 - val_accuracy: 0.8533\n",
      "Epoch 609/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.6567 - val_accuracy: 0.8533\n",
      "Epoch 610/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.6568 - val_accuracy: 0.8533\n",
      "Epoch 611/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.6570 - val_accuracy: 0.8533\n",
      "Epoch 612/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.6571 - val_accuracy: 0.8533\n",
      "Epoch 613/1000\n",
      "700/700 [==============================] - 0s 187us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.6572 - val_accuracy: 0.8533\n",
      "Epoch 614/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.6573 - val_accuracy: 0.8533\n",
      "Epoch 615/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.6574 - val_accuracy: 0.8533\n",
      "Epoch 616/1000\n",
      "700/700 [==============================] - 0s 194us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.6576 - val_accuracy: 0.8533\n",
      "Epoch 617/1000\n",
      "700/700 [==============================] - 0s 192us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.6578 - val_accuracy: 0.8533\n",
      "Epoch 618/1000\n",
      "700/700 [==============================] - 0s 191us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.6579 - val_accuracy: 0.8533\n",
      "Epoch 619/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.6580 - val_accuracy: 0.8533\n",
      "Epoch 620/1000\n",
      "700/700 [==============================] - 0s 197us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.6580 - val_accuracy: 0.8533\n",
      "Epoch 621/1000\n",
      "700/700 [==============================] - 0s 194us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.6583 - val_accuracy: 0.8533\n",
      "Epoch 622/1000\n",
      "700/700 [==============================] - 0s 185us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.6585 - val_accuracy: 0.8533\n",
      "Epoch 623/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.6585 - val_accuracy: 0.8533\n",
      "Epoch 624/1000\n",
      "700/700 [==============================] - 0s 204us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.6586 - val_accuracy: 0.8533\n",
      "Epoch 625/1000\n",
      "700/700 [==============================] - 0s 202us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.6587 - val_accuracy: 0.8533\n",
      "Epoch 626/1000\n",
      "700/700 [==============================] - 0s 185us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.6589 - val_accuracy: 0.8533\n",
      "Epoch 627/1000\n",
      "700/700 [==============================] - 0s 211us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.6590 - val_accuracy: 0.8533\n",
      "Epoch 628/1000\n",
      "700/700 [==============================] - 0s 198us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.6591 - val_accuracy: 0.8533\n",
      "Epoch 629/1000\n",
      "700/700 [==============================] - 0s 188us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.6593 - val_accuracy: 0.8533\n",
      "Epoch 630/1000\n",
      "700/700 [==============================] - 0s 192us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.6593 - val_accuracy: 0.8533\n",
      "Epoch 631/1000\n",
      "700/700 [==============================] - 0s 201us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.6595 - val_accuracy: 0.8533\n",
      "Epoch 632/1000\n",
      "700/700 [==============================] - 0s 194us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.6595 - val_accuracy: 0.8533\n",
      "Epoch 633/1000\n",
      "700/700 [==============================] - 0s 189us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.6596 - val_accuracy: 0.8533\n",
      "Epoch 634/1000\n",
      "700/700 [==============================] - 0s 189us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.6599 - val_accuracy: 0.8533\n",
      "Epoch 635/1000\n",
      "700/700 [==============================] - 0s 191us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.6599 - val_accuracy: 0.8533\n",
      "Epoch 636/1000\n",
      "700/700 [==============================] - 0s 187us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.6602 - val_accuracy: 0.8533\n",
      "Epoch 637/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.6603 - val_accuracy: 0.8533\n",
      "Epoch 638/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.6604 - val_accuracy: 0.8533\n",
      "Epoch 639/1000\n",
      "700/700 [==============================] - 0s 187us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.6605 - val_accuracy: 0.8533\n",
      "Epoch 640/1000\n",
      "700/700 [==============================] - 0s 189us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.6606 - val_accuracy: 0.8533\n",
      "Epoch 641/1000\n",
      "700/700 [==============================] - 0s 189us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.6608 - val_accuracy: 0.8533\n",
      "Epoch 642/1000\n",
      "700/700 [==============================] - 0s 188us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.6610 - val_accuracy: 0.8533\n",
      "Epoch 643/1000\n",
      "700/700 [==============================] - 0s 189us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.6611 - val_accuracy: 0.8533\n",
      "Epoch 644/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.6611 - val_accuracy: 0.8533\n",
      "Epoch 645/1000\n",
      "700/700 [==============================] - 0s 185us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.6612 - val_accuracy: 0.8533\n",
      "Epoch 646/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.6613 - val_accuracy: 0.8533\n",
      "Epoch 647/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.6615 - val_accuracy: 0.8533\n",
      "Epoch 648/1000\n",
      "700/700 [==============================] - 0s 187us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.6618 - val_accuracy: 0.8533\n",
      "Epoch 649/1000\n",
      "700/700 [==============================] - 0s 205us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.6618 - val_accuracy: 0.8533\n",
      "Epoch 650/1000\n",
      "700/700 [==============================] - 0s 199us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.6619 - val_accuracy: 0.8533\n",
      "Epoch 651/1000\n",
      "700/700 [==============================] - 0s 185us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.6620 - val_accuracy: 0.8533\n",
      "Epoch 652/1000\n",
      "700/700 [==============================] - 0s 189us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.6622 - val_accuracy: 0.8533\n",
      "Epoch 653/1000\n",
      "700/700 [==============================] - 0s 187us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.6622 - val_accuracy: 0.8533\n",
      "Epoch 654/1000\n",
      "700/700 [==============================] - 0s 201us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.6624 - val_accuracy: 0.8533\n",
      "Epoch 655/1000\n",
      "700/700 [==============================] - 0s 187us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.6625 - val_accuracy: 0.8533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 656/1000\n",
      "700/700 [==============================] - 0s 187us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.6626 - val_accuracy: 0.8533\n",
      "Epoch 657/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.6627 - val_accuracy: 0.8533\n",
      "Epoch 658/1000\n",
      "700/700 [==============================] - 0s 190us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.6628 - val_accuracy: 0.8533\n",
      "Epoch 659/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.6630 - val_accuracy: 0.8533\n",
      "Epoch 660/1000\n",
      "700/700 [==============================] - 0s 188us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.6631 - val_accuracy: 0.8533\n",
      "Epoch 661/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.6633 - val_accuracy: 0.8533\n",
      "Epoch 662/1000\n",
      "700/700 [==============================] - 0s 191us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.6633 - val_accuracy: 0.8533\n",
      "Epoch 663/1000\n",
      "700/700 [==============================] - 0s 198us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.6634 - val_accuracy: 0.8533\n",
      "Epoch 664/1000\n",
      "700/700 [==============================] - 0s 188us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.6636 - val_accuracy: 0.8533\n",
      "Epoch 665/1000\n",
      "700/700 [==============================] - 0s 189us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.6637 - val_accuracy: 0.8533\n",
      "Epoch 666/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.6638 - val_accuracy: 0.8533\n",
      "Epoch 667/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.6639 - val_accuracy: 0.8533\n",
      "Epoch 668/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.6640 - val_accuracy: 0.8533\n",
      "Epoch 669/1000\n",
      "700/700 [==============================] - 0s 185us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6643 - val_accuracy: 0.8533\n",
      "Epoch 670/1000\n",
      "700/700 [==============================] - 0s 189us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6643 - val_accuracy: 0.8533\n",
      "Epoch 671/1000\n",
      "700/700 [==============================] - 0s 188us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6645 - val_accuracy: 0.8533\n",
      "Epoch 672/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6646 - val_accuracy: 0.8533\n",
      "Epoch 673/1000\n",
      "700/700 [==============================] - 0s 187us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6647 - val_accuracy: 0.8533\n",
      "Epoch 674/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6648 - val_accuracy: 0.8533\n",
      "Epoch 675/1000\n",
      "700/700 [==============================] - 0s 188us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6650 - val_accuracy: 0.8533\n",
      "Epoch 676/1000\n",
      "700/700 [==============================] - 0s 198us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6651 - val_accuracy: 0.8533\n",
      "Epoch 677/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6652 - val_accuracy: 0.8533\n",
      "Epoch 678/1000\n",
      "700/700 [==============================] - 0s 192us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6653 - val_accuracy: 0.8533\n",
      "Epoch 679/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6653 - val_accuracy: 0.8533\n",
      "Epoch 680/1000\n",
      "700/700 [==============================] - 0s 189us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6654 - val_accuracy: 0.8533\n",
      "Epoch 681/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6657 - val_accuracy: 0.8533\n",
      "Epoch 682/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6657 - val_accuracy: 0.8533\n",
      "Epoch 683/1000\n",
      "700/700 [==============================] - 0s 192us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6659 - val_accuracy: 0.8533\n",
      "Epoch 684/1000\n",
      "700/700 [==============================] - 0s 199us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6661 - val_accuracy: 0.8533\n",
      "Epoch 685/1000\n",
      "700/700 [==============================] - 0s 207us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6661 - val_accuracy: 0.8533\n",
      "Epoch 686/1000\n",
      "700/700 [==============================] - 0s 224us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6662 - val_accuracy: 0.8533\n",
      "Epoch 687/1000\n",
      "700/700 [==============================] - 0s 192us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6664 - val_accuracy: 0.8533\n",
      "Epoch 688/1000\n",
      "700/700 [==============================] - 0s 197us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6665 - val_accuracy: 0.8533\n",
      "Epoch 689/1000\n",
      "700/700 [==============================] - 0s 188us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6667 - val_accuracy: 0.8533\n",
      "Epoch 690/1000\n",
      "700/700 [==============================] - 0s 191us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6668 - val_accuracy: 0.8533\n",
      "Epoch 691/1000\n",
      "700/700 [==============================] - 0s 197us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6670 - val_accuracy: 0.8533\n",
      "Epoch 692/1000\n",
      "700/700 [==============================] - 0s 215us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6670 - val_accuracy: 0.8533\n",
      "Epoch 693/1000\n",
      "700/700 [==============================] - 0s 205us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6671 - val_accuracy: 0.8533\n",
      "Epoch 694/1000\n",
      "700/700 [==============================] - 0s 204us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6673 - val_accuracy: 0.8533\n",
      "Epoch 695/1000\n",
      "700/700 [==============================] - 0s 189us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6674 - val_accuracy: 0.8533\n",
      "Epoch 696/1000\n",
      "700/700 [==============================] - 0s 191us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6676 - val_accuracy: 0.8533\n",
      "Epoch 697/1000\n",
      "700/700 [==============================] - 0s 189us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6677 - val_accuracy: 0.8533\n",
      "Epoch 698/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6678 - val_accuracy: 0.8533\n",
      "Epoch 699/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6680 - val_accuracy: 0.8533\n",
      "Epoch 700/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6681 - val_accuracy: 0.8533\n",
      "Epoch 701/1000\n",
      "700/700 [==============================] - 0s 191us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6682 - val_accuracy: 0.8533\n",
      "Epoch 702/1000\n",
      "700/700 [==============================] - 0s 189us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6682 - val_accuracy: 0.8533\n",
      "Epoch 703/1000\n",
      "700/700 [==============================] - 0s 185us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6684 - val_accuracy: 0.8533\n",
      "Epoch 704/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6685 - val_accuracy: 0.8533\n",
      "Epoch 705/1000\n",
      "700/700 [==============================] - 0s 187us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6687 - val_accuracy: 0.8533\n",
      "Epoch 706/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6687 - val_accuracy: 0.8533\n",
      "Epoch 707/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6688 - val_accuracy: 0.8533\n",
      "Epoch 708/1000\n",
      "700/700 [==============================] - 0s 199us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6689 - val_accuracy: 0.8533\n",
      "Epoch 709/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6691 - val_accuracy: 0.8533\n",
      "Epoch 710/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6692 - val_accuracy: 0.8533\n",
      "Epoch 711/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6693 - val_accuracy: 0.8533\n",
      "Epoch 712/1000\n",
      "700/700 [==============================] - 0s 187us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6694 - val_accuracy: 0.8533\n",
      "Epoch 713/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6695 - val_accuracy: 0.8533\n",
      "Epoch 714/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6696 - val_accuracy: 0.8533\n",
      "Epoch 715/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6698 - val_accuracy: 0.8533\n",
      "Epoch 716/1000\n",
      "700/700 [==============================] - 0s 191us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6699 - val_accuracy: 0.8533\n",
      "Epoch 717/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6700 - val_accuracy: 0.8533\n",
      "Epoch 718/1000\n",
      "700/700 [==============================] - 0s 185us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6701 - val_accuracy: 0.8533\n",
      "Epoch 719/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6702 - val_accuracy: 0.8533\n",
      "Epoch 720/1000\n",
      "700/700 [==============================] - 0s 189us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6704 - val_accuracy: 0.8533\n",
      "Epoch 721/1000\n",
      "700/700 [==============================] - 0s 194us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6705 - val_accuracy: 0.8533\n",
      "Epoch 722/1000\n",
      "700/700 [==============================] - 0s 185us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6707 - val_accuracy: 0.8533\n",
      "Epoch 723/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6708 - val_accuracy: 0.8533\n",
      "Epoch 724/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6708 - val_accuracy: 0.8533\n",
      "Epoch 725/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6709 - val_accuracy: 0.8533\n",
      "Epoch 726/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6709 - val_accuracy: 0.8533\n",
      "Epoch 727/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6711 - val_accuracy: 0.8533\n",
      "Epoch 728/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6712 - val_accuracy: 0.8533\n",
      "Epoch 729/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6714 - val_accuracy: 0.8533\n",
      "Epoch 730/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6715 - val_accuracy: 0.8533\n",
      "Epoch 731/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6717 - val_accuracy: 0.8533\n",
      "Epoch 732/1000\n",
      "700/700 [==============================] - 0s 188us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6718 - val_accuracy: 0.8533\n",
      "Epoch 733/1000\n",
      "700/700 [==============================] - 0s 199us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6719 - val_accuracy: 0.8533\n",
      "Epoch 734/1000\n",
      "700/700 [==============================] - 0s 194us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6719 - val_accuracy: 0.8533\n",
      "Epoch 735/1000\n",
      "700/700 [==============================] - 0s 188us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6722 - val_accuracy: 0.8533\n",
      "Epoch 736/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6722 - val_accuracy: 0.8533\n",
      "Epoch 737/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6723 - val_accuracy: 0.8533\n",
      "Epoch 738/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6724 - val_accuracy: 0.8533\n",
      "Epoch 739/1000\n",
      "700/700 [==============================] - 0s 217us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6724 - val_accuracy: 0.8533\n",
      "Epoch 740/1000\n",
      "700/700 [==============================] - 0s 191us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6726 - val_accuracy: 0.8533\n",
      "Epoch 741/1000\n",
      "700/700 [==============================] - 0s 177us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6727 - val_accuracy: 0.8533\n",
      "Epoch 742/1000\n",
      "700/700 [==============================] - 0s 187us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6729 - val_accuracy: 0.8533\n",
      "Epoch 743/1000\n",
      "700/700 [==============================] - 0s 192us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6730 - val_accuracy: 0.8533\n",
      "Epoch 744/1000\n",
      "700/700 [==============================] - 0s 198us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6731 - val_accuracy: 0.8533\n",
      "Epoch 745/1000\n",
      "700/700 [==============================] - 0s 185us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6732 - val_accuracy: 0.8533\n",
      "Epoch 746/1000\n",
      "700/700 [==============================] - 0s 188us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6732 - val_accuracy: 0.8533\n",
      "Epoch 747/1000\n",
      "700/700 [==============================] - 0s 194us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6734 - val_accuracy: 0.8533\n",
      "Epoch 748/1000\n",
      "700/700 [==============================] - 0s 192us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6735 - val_accuracy: 0.8533\n",
      "Epoch 749/1000\n",
      "700/700 [==============================] - 0s 188us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6736 - val_accuracy: 0.8533\n",
      "Epoch 750/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6738 - val_accuracy: 0.8533\n",
      "Epoch 751/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6739 - val_accuracy: 0.8533\n",
      "Epoch 752/1000\n",
      "700/700 [==============================] - 0s 185us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6740 - val_accuracy: 0.8533\n",
      "Epoch 753/1000\n",
      "700/700 [==============================] - 0s 188us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6741 - val_accuracy: 0.8533\n",
      "Epoch 754/1000\n",
      "700/700 [==============================] - 0s 187us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6742 - val_accuracy: 0.8533\n",
      "Epoch 755/1000\n",
      "700/700 [==============================] - 0s 199us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6744 - val_accuracy: 0.8533\n",
      "Epoch 756/1000\n",
      "700/700 [==============================] - 0s 201us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6744 - val_accuracy: 0.8533\n",
      "Epoch 757/1000\n",
      "700/700 [==============================] - 0s 185us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6745 - val_accuracy: 0.8533\n",
      "Epoch 758/1000\n",
      "700/700 [==============================] - 0s 189us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6746 - val_accuracy: 0.8533\n",
      "Epoch 759/1000\n",
      "700/700 [==============================] - 0s 191us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6747 - val_accuracy: 0.8533\n",
      "Epoch 760/1000\n",
      "700/700 [==============================] - 0s 191us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6748 - val_accuracy: 0.8533\n",
      "Epoch 761/1000\n",
      "700/700 [==============================] - 0s 195us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6749 - val_accuracy: 0.8533\n",
      "Epoch 762/1000\n",
      "700/700 [==============================] - 0s 204us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6750 - val_accuracy: 0.8533\n",
      "Epoch 763/1000\n",
      "700/700 [==============================] - 0s 198us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6751 - val_accuracy: 0.8533\n",
      "Epoch 764/1000\n",
      "700/700 [==============================] - 0s 199us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6752 - val_accuracy: 0.8533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 765/1000\n",
      "700/700 [==============================] - 0s 191us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6753 - val_accuracy: 0.8533\n",
      "Epoch 766/1000\n",
      "700/700 [==============================] - 0s 204us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6754 - val_accuracy: 0.8533\n",
      "Epoch 767/1000\n",
      "700/700 [==============================] - 0s 192us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6755 - val_accuracy: 0.8533\n",
      "Epoch 768/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6756 - val_accuracy: 0.8533\n",
      "Epoch 769/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6756 - val_accuracy: 0.8533\n",
      "Epoch 770/1000\n",
      "700/700 [==============================] - 0s 187us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6758 - val_accuracy: 0.8533\n",
      "Epoch 771/1000\n",
      "700/700 [==============================] - 0s 189us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6760 - val_accuracy: 0.8533\n",
      "Epoch 772/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6760 - val_accuracy: 0.8533\n",
      "Epoch 773/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6761 - val_accuracy: 0.8533\n",
      "Epoch 774/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6762 - val_accuracy: 0.8533\n",
      "Epoch 775/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6764 - val_accuracy: 0.8533\n",
      "Epoch 776/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6765 - val_accuracy: 0.8533\n",
      "Epoch 777/1000\n",
      "700/700 [==============================] - 0s 191us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6766 - val_accuracy: 0.8533\n",
      "Epoch 778/1000\n",
      "700/700 [==============================] - 0s 197us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6767 - val_accuracy: 0.8533\n",
      "Epoch 779/1000\n",
      "700/700 [==============================] - 0s 202us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6769 - val_accuracy: 0.8533\n",
      "Epoch 780/1000\n",
      "700/700 [==============================] - 0s 191us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6770 - val_accuracy: 0.8533\n",
      "Epoch 781/1000\n",
      "700/700 [==============================] - 0s 185us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6771 - val_accuracy: 0.8533\n",
      "Epoch 782/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6772 - val_accuracy: 0.8533\n",
      "Epoch 783/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6772 - val_accuracy: 0.8533\n",
      "Epoch 784/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6773 - val_accuracy: 0.8533\n",
      "Epoch 785/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6775 - val_accuracy: 0.8533\n",
      "Epoch 786/1000\n",
      "700/700 [==============================] - 0s 185us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6775 - val_accuracy: 0.8533\n",
      "Epoch 787/1000\n",
      "700/700 [==============================] - 0s 199us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6776 - val_accuracy: 0.8533\n",
      "Epoch 788/1000\n",
      "700/700 [==============================] - 0s 215us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6777 - val_accuracy: 0.8533\n",
      "Epoch 789/1000\n",
      "700/700 [==============================] - 0s 219us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6778 - val_accuracy: 0.8533\n",
      "Epoch 790/1000\n",
      "700/700 [==============================] - 0s 194us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6779 - val_accuracy: 0.8533\n",
      "Epoch 791/1000\n",
      "700/700 [==============================] - 0s 207us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6781 - val_accuracy: 0.8533\n",
      "Epoch 792/1000\n",
      "700/700 [==============================] - 0s 217us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6782 - val_accuracy: 0.8533\n",
      "Epoch 793/1000\n",
      "700/700 [==============================] - 0s 191us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6783 - val_accuracy: 0.8533\n",
      "Epoch 794/1000\n",
      "700/700 [==============================] - 0s 224us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6784 - val_accuracy: 0.8533\n",
      "Epoch 795/1000\n",
      "700/700 [==============================] - 0s 199us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6786 - val_accuracy: 0.8533\n",
      "Epoch 796/1000\n",
      "700/700 [==============================] - 0s 192us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6787 - val_accuracy: 0.8533\n",
      "Epoch 797/1000\n",
      "700/700 [==============================] - 0s 222us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6787 - val_accuracy: 0.8533\n",
      "Epoch 798/1000\n",
      "700/700 [==============================] - 0s 202us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6788 - val_accuracy: 0.8533\n",
      "Epoch 799/1000\n",
      "700/700 [==============================] - 0s 225us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6789 - val_accuracy: 0.8533\n",
      "Epoch 800/1000\n",
      "700/700 [==============================] - 0s 205us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6791 - val_accuracy: 0.8533\n",
      "Epoch 801/1000\n",
      "700/700 [==============================] - 0s 197us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6792 - val_accuracy: 0.8533\n",
      "Epoch 802/1000\n",
      "700/700 [==============================] - 0s 189us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6793 - val_accuracy: 0.8533\n",
      "Epoch 803/1000\n",
      "700/700 [==============================] - 0s 188us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6794 - val_accuracy: 0.8533\n",
      "Epoch 804/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6795 - val_accuracy: 0.8533\n",
      "Epoch 805/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6796 - val_accuracy: 0.8533\n",
      "Epoch 806/1000\n",
      "700/700 [==============================] - 0s 189us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6797 - val_accuracy: 0.8533\n",
      "Epoch 807/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6798 - val_accuracy: 0.8533\n",
      "Epoch 808/1000\n",
      "700/700 [==============================] - 0s 189us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6799 - val_accuracy: 0.8533\n",
      "Epoch 809/1000\n",
      "700/700 [==============================] - 0s 192us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6801 - val_accuracy: 0.8533\n",
      "Epoch 810/1000\n",
      "700/700 [==============================] - 0s 191us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6802 - val_accuracy: 0.8533\n",
      "Epoch 811/1000\n",
      "700/700 [==============================] - 0s 185us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6803 - val_accuracy: 0.8533\n",
      "Epoch 812/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6803 - val_accuracy: 0.8533\n",
      "Epoch 813/1000\n",
      "700/700 [==============================] - 0s 189us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6804 - val_accuracy: 0.8533\n",
      "Epoch 814/1000\n",
      "700/700 [==============================] - 0s 191us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6805 - val_accuracy: 0.8533\n",
      "Epoch 815/1000\n",
      "700/700 [==============================] - 0s 187us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6805 - val_accuracy: 0.8533\n",
      "Epoch 816/1000\n",
      "700/700 [==============================] - 0s 187us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6806 - val_accuracy: 0.8533\n",
      "Epoch 817/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6807 - val_accuracy: 0.8533\n",
      "Epoch 818/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6809 - val_accuracy: 0.8533\n",
      "Epoch 819/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6810 - val_accuracy: 0.8533\n",
      "Epoch 820/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6811 - val_accuracy: 0.8533\n",
      "Epoch 821/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6812 - val_accuracy: 0.8533\n",
      "Epoch 822/1000\n",
      "700/700 [==============================] - 0s 187us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6813 - val_accuracy: 0.8533\n",
      "Epoch 823/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6814 - val_accuracy: 0.8533\n",
      "Epoch 824/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6815 - val_accuracy: 0.8533\n",
      "Epoch 825/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6816 - val_accuracy: 0.8533\n",
      "Epoch 826/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6817 - val_accuracy: 0.8533\n",
      "Epoch 827/1000\n",
      "700/700 [==============================] - 0s 177us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6817 - val_accuracy: 0.8533\n",
      "Epoch 828/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6818 - val_accuracy: 0.8533\n",
      "Epoch 829/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6819 - val_accuracy: 0.8533\n",
      "Epoch 830/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6820 - val_accuracy: 0.8533\n",
      "Epoch 831/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6821 - val_accuracy: 0.8533\n",
      "Epoch 832/1000\n",
      "700/700 [==============================] - 0s 185us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6822 - val_accuracy: 0.8533\n",
      "Epoch 833/1000\n",
      "700/700 [==============================] - 0s 188us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6824 - val_accuracy: 0.8533\n",
      "Epoch 834/1000\n",
      "700/700 [==============================] - 0s 217us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6825 - val_accuracy: 0.8533\n",
      "Epoch 835/1000\n",
      "700/700 [==============================] - 0s 195us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6826 - val_accuracy: 0.8533\n",
      "Epoch 836/1000\n",
      "700/700 [==============================] - 0s 207us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6827 - val_accuracy: 0.8533\n",
      "Epoch 837/1000\n",
      "700/700 [==============================] - 0s 215us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6828 - val_accuracy: 0.8533\n",
      "Epoch 838/1000\n",
      "700/700 [==============================] - 0s 187us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6828 - val_accuracy: 0.8533\n",
      "Epoch 839/1000\n",
      "700/700 [==============================] - 0s 191us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6829 - val_accuracy: 0.8533\n",
      "Epoch 840/1000\n",
      "700/700 [==============================] - 0s 202us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6830 - val_accuracy: 0.8533\n",
      "Epoch 841/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6831 - val_accuracy: 0.8533\n",
      "Epoch 842/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6832 - val_accuracy: 0.8533\n",
      "Epoch 843/1000\n",
      "700/700 [==============================] - 0s 185us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6833 - val_accuracy: 0.8533\n",
      "Epoch 844/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6835 - val_accuracy: 0.8533\n",
      "Epoch 845/1000\n",
      "700/700 [==============================] - 0s 192us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6835 - val_accuracy: 0.8533\n",
      "Epoch 846/1000\n",
      "700/700 [==============================] - 0s 198us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6837 - val_accuracy: 0.8533\n",
      "Epoch 847/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6838 - val_accuracy: 0.8533\n",
      "Epoch 848/1000\n",
      "700/700 [==============================] - 0s 187us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6839 - val_accuracy: 0.8533\n",
      "Epoch 849/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6841 - val_accuracy: 0.8533\n",
      "Epoch 850/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6841 - val_accuracy: 0.8533\n",
      "Epoch 851/1000\n",
      "700/700 [==============================] - 0s 185us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6843 - val_accuracy: 0.8533\n",
      "Epoch 852/1000\n",
      "700/700 [==============================] - 0s 191us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6843 - val_accuracy: 0.8533\n",
      "Epoch 853/1000\n",
      "700/700 [==============================] - 0s 189us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6844 - val_accuracy: 0.8533\n",
      "Epoch 854/1000\n",
      "700/700 [==============================] - 0s 185us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6845 - val_accuracy: 0.8533\n",
      "Epoch 855/1000\n",
      "700/700 [==============================] - 0s 195us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6845 - val_accuracy: 0.8533\n",
      "Epoch 856/1000\n",
      "700/700 [==============================] - 0s 204us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6846 - val_accuracy: 0.8533\n",
      "Epoch 857/1000\n",
      "700/700 [==============================] - 0s 195us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6848 - val_accuracy: 0.8533\n",
      "Epoch 858/1000\n",
      "700/700 [==============================] - 0s 197us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6849 - val_accuracy: 0.8533\n",
      "Epoch 859/1000\n",
      "700/700 [==============================] - 0s 192us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6850 - val_accuracy: 0.8533\n",
      "Epoch 860/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6851 - val_accuracy: 0.8533\n",
      "Epoch 861/1000\n",
      "700/700 [==============================] - 0s 185us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6852 - val_accuracy: 0.8533\n",
      "Epoch 862/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6853 - val_accuracy: 0.8533\n",
      "Epoch 863/1000\n",
      "700/700 [==============================] - 0s 189us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6854 - val_accuracy: 0.8533\n",
      "Epoch 864/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6855 - val_accuracy: 0.8533\n",
      "Epoch 865/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6855 - val_accuracy: 0.8533\n",
      "Epoch 866/1000\n",
      "700/700 [==============================] - 0s 194us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6856 - val_accuracy: 0.8533\n",
      "Epoch 867/1000\n",
      "700/700 [==============================] - 0s 188us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6857 - val_accuracy: 0.8533\n",
      "Epoch 868/1000\n",
      "700/700 [==============================] - 0s 207us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6858 - val_accuracy: 0.8533\n",
      "Epoch 869/1000\n",
      "700/700 [==============================] - 0s 262us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6859 - val_accuracy: 0.8533\n",
      "Epoch 870/1000\n",
      "700/700 [==============================] - 0s 227us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6861 - val_accuracy: 0.8533\n",
      "Epoch 871/1000\n",
      "700/700 [==============================] - 0s 185us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6862 - val_accuracy: 0.8533\n",
      "Epoch 872/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6862 - val_accuracy: 0.8533\n",
      "Epoch 873/1000\n",
      "700/700 [==============================] - 0s 189us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6863 - val_accuracy: 0.8533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 874/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6865 - val_accuracy: 0.8533\n",
      "Epoch 875/1000\n",
      "700/700 [==============================] - 0s 177us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6866 - val_accuracy: 0.8533\n",
      "Epoch 876/1000\n",
      "700/700 [==============================] - 0s 174us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6866 - val_accuracy: 0.8533\n",
      "Epoch 877/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6868 - val_accuracy: 0.8533\n",
      "Epoch 878/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6868 - val_accuracy: 0.8533\n",
      "Epoch 879/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6869 - val_accuracy: 0.8533\n",
      "Epoch 880/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6870 - val_accuracy: 0.8533\n",
      "Epoch 881/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6871 - val_accuracy: 0.8533\n",
      "Epoch 882/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6872 - val_accuracy: 0.8533\n",
      "Epoch 883/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6873 - val_accuracy: 0.8533\n",
      "Epoch 884/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6874 - val_accuracy: 0.8533\n",
      "Epoch 885/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6875 - val_accuracy: 0.8533\n",
      "Epoch 886/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6876 - val_accuracy: 0.8533\n",
      "Epoch 887/1000\n",
      "700/700 [==============================] - 0s 174us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6877 - val_accuracy: 0.8533\n",
      "Epoch 888/1000\n",
      "700/700 [==============================] - 0s 175us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6877 - val_accuracy: 0.8533\n",
      "Epoch 889/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6879 - val_accuracy: 0.8533\n",
      "Epoch 890/1000\n",
      "700/700 [==============================] - 0s 174us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6879 - val_accuracy: 0.8533\n",
      "Epoch 891/1000\n",
      "700/700 [==============================] - 0s 187us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6880 - val_accuracy: 0.8533\n",
      "Epoch 892/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6881 - val_accuracy: 0.8533\n",
      "Epoch 893/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6882 - val_accuracy: 0.8533\n",
      "Epoch 894/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6883 - val_accuracy: 0.8533\n",
      "Epoch 895/1000\n",
      "700/700 [==============================] - 0s 177us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6884 - val_accuracy: 0.8533\n",
      "Epoch 896/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6885 - val_accuracy: 0.8533\n",
      "Epoch 897/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6887 - val_accuracy: 0.8533\n",
      "Epoch 898/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6887 - val_accuracy: 0.8533\n",
      "Epoch 899/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6888 - val_accuracy: 0.8533\n",
      "Epoch 900/1000\n",
      "700/700 [==============================] - 0s 175us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6889 - val_accuracy: 0.8533\n",
      "Epoch 901/1000\n",
      "700/700 [==============================] - 0s 175us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6890 - val_accuracy: 0.8533\n",
      "Epoch 902/1000\n",
      "700/700 [==============================] - 0s 177us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6891 - val_accuracy: 0.8533\n",
      "Epoch 903/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6892 - val_accuracy: 0.8533\n",
      "Epoch 904/1000\n",
      "700/700 [==============================] - 0s 191us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6893 - val_accuracy: 0.8533\n",
      "Epoch 905/1000\n",
      "700/700 [==============================] - 0s 189us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6893 - val_accuracy: 0.8533\n",
      "Epoch 906/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6894 - val_accuracy: 0.8533\n",
      "Epoch 907/1000\n",
      "700/700 [==============================] - 0s 174us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6895 - val_accuracy: 0.8533\n",
      "Epoch 908/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6896 - val_accuracy: 0.8533\n",
      "Epoch 909/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6897 - val_accuracy: 0.8533\n",
      "Epoch 910/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6898 - val_accuracy: 0.8533\n",
      "Epoch 911/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6899 - val_accuracy: 0.8533\n",
      "Epoch 912/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6899 - val_accuracy: 0.8533\n",
      "Epoch 913/1000\n",
      "700/700 [==============================] - 0s 175us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6901 - val_accuracy: 0.8533\n",
      "Epoch 914/1000\n",
      "700/700 [==============================] - 0s 185us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6902 - val_accuracy: 0.8533\n",
      "Epoch 915/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6902 - val_accuracy: 0.8533\n",
      "Epoch 916/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6904 - val_accuracy: 0.8533\n",
      "Epoch 917/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6905 - val_accuracy: 0.8533\n",
      "Epoch 918/1000\n",
      "700/700 [==============================] - 0s 177us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6906 - val_accuracy: 0.8533\n",
      "Epoch 919/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6906 - val_accuracy: 0.8533\n",
      "Epoch 920/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6907 - val_accuracy: 0.8533\n",
      "Epoch 921/1000\n",
      "700/700 [==============================] - 0s 175us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6908 - val_accuracy: 0.8533\n",
      "Epoch 922/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6908 - val_accuracy: 0.8533\n",
      "Epoch 923/1000\n",
      "700/700 [==============================] - 0s 175us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6909 - val_accuracy: 0.8533\n",
      "Epoch 924/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6911 - val_accuracy: 0.8533\n",
      "Epoch 925/1000\n",
      "700/700 [==============================] - 0s 175us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6910 - val_accuracy: 0.8533\n",
      "Epoch 926/1000\n",
      "700/700 [==============================] - 0s 177us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6912 - val_accuracy: 0.8533\n",
      "Epoch 927/1000\n",
      "700/700 [==============================] - 0s 187us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6914 - val_accuracy: 0.8533\n",
      "Epoch 928/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6915 - val_accuracy: 0.8533\n",
      "Epoch 929/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6916 - val_accuracy: 0.8533\n",
      "Epoch 930/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6916 - val_accuracy: 0.8533\n",
      "Epoch 931/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6917 - val_accuracy: 0.8533\n",
      "Epoch 932/1000\n",
      "700/700 [==============================] - 0s 175us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6918 - val_accuracy: 0.8533\n",
      "Epoch 933/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6919 - val_accuracy: 0.8533\n",
      "Epoch 934/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6919 - val_accuracy: 0.8533\n",
      "Epoch 935/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6920 - val_accuracy: 0.8533\n",
      "Epoch 936/1000\n",
      "700/700 [==============================] - 0s 175us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6921 - val_accuracy: 0.8533\n",
      "Epoch 937/1000\n",
      "700/700 [==============================] - 0s 177us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6921 - val_accuracy: 0.8533\n",
      "Epoch 938/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6923 - val_accuracy: 0.8533\n",
      "Epoch 939/1000\n",
      "700/700 [==============================] - 0s 195us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6924 - val_accuracy: 0.8533\n",
      "Epoch 940/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6925 - val_accuracy: 0.8533\n",
      "Epoch 941/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6925 - val_accuracy: 0.8533\n",
      "Epoch 942/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6926 - val_accuracy: 0.8533\n",
      "Epoch 943/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6927 - val_accuracy: 0.8533\n",
      "Epoch 944/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6928 - val_accuracy: 0.8533\n",
      "Epoch 945/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6929 - val_accuracy: 0.8533\n",
      "Epoch 946/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6930 - val_accuracy: 0.8533\n",
      "Epoch 947/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6931 - val_accuracy: 0.8533\n",
      "Epoch 948/1000\n",
      "700/700 [==============================] - 0s 185us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6932 - val_accuracy: 0.8533\n",
      "Epoch 949/1000\n",
      "700/700 [==============================] - 0s 177us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6933 - val_accuracy: 0.8533\n",
      "Epoch 950/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6933 - val_accuracy: 0.8533\n",
      "Epoch 951/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6934 - val_accuracy: 0.8533\n",
      "Epoch 952/1000\n",
      "700/700 [==============================] - 0s 177us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6934 - val_accuracy: 0.8533\n",
      "Epoch 953/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6935 - val_accuracy: 0.8533\n",
      "Epoch 954/1000\n",
      "700/700 [==============================] - 0s 177us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6937 - val_accuracy: 0.8533\n",
      "Epoch 955/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6938 - val_accuracy: 0.8533\n",
      "Epoch 956/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6938 - val_accuracy: 0.8533\n",
      "Epoch 957/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6939 - val_accuracy: 0.8533\n",
      "Epoch 958/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6940 - val_accuracy: 0.8533\n",
      "Epoch 959/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6941 - val_accuracy: 0.8533\n",
      "Epoch 960/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6942 - val_accuracy: 0.8533\n",
      "Epoch 961/1000\n",
      "700/700 [==============================] - 0s 175us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6943 - val_accuracy: 0.8533\n",
      "Epoch 962/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6943 - val_accuracy: 0.8533\n",
      "Epoch 963/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6945 - val_accuracy: 0.8533\n",
      "Epoch 964/1000\n",
      "700/700 [==============================] - 0s 177us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6946 - val_accuracy: 0.8533\n",
      "Epoch 965/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6946 - val_accuracy: 0.8533\n",
      "Epoch 966/1000\n",
      "700/700 [==============================] - 0s 177us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6947 - val_accuracy: 0.8533\n",
      "Epoch 967/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6948 - val_accuracy: 0.8533\n",
      "Epoch 968/1000\n",
      "700/700 [==============================] - 0s 188us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6949 - val_accuracy: 0.8533\n",
      "Epoch 969/1000\n",
      "700/700 [==============================] - 0s 177us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6949 - val_accuracy: 0.8533\n",
      "Epoch 970/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6950 - val_accuracy: 0.8533\n",
      "Epoch 971/1000\n",
      "700/700 [==============================] - 0s 175us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6952 - val_accuracy: 0.8533\n",
      "Epoch 972/1000\n",
      "700/700 [==============================] - 0s 177us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6953 - val_accuracy: 0.8533\n",
      "Epoch 973/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6954 - val_accuracy: 0.8533\n",
      "Epoch 974/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6954 - val_accuracy: 0.8533\n",
      "Epoch 975/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6955 - val_accuracy: 0.8533\n",
      "Epoch 976/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6956 - val_accuracy: 0.8533\n",
      "Epoch 977/1000\n",
      "700/700 [==============================] - 0s 177us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6957 - val_accuracy: 0.8533\n",
      "Epoch 978/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6958 - val_accuracy: 0.8533\n",
      "Epoch 979/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6959 - val_accuracy: 0.8533\n",
      "Epoch 980/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6959 - val_accuracy: 0.8533\n",
      "Epoch 981/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6960 - val_accuracy: 0.8533\n",
      "Epoch 982/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6961 - val_accuracy: 0.8533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 983/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6962 - val_accuracy: 0.8533\n",
      "Epoch 984/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6963 - val_accuracy: 0.8533\n",
      "Epoch 985/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6964 - val_accuracy: 0.8533\n",
      "Epoch 986/1000\n",
      "700/700 [==============================] - 0s 177us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6965 - val_accuracy: 0.8533\n",
      "Epoch 987/1000\n",
      "700/700 [==============================] - 0s 185us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6965 - val_accuracy: 0.8533\n",
      "Epoch 988/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6966 - val_accuracy: 0.8533\n",
      "Epoch 989/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6967 - val_accuracy: 0.8533\n",
      "Epoch 990/1000\n",
      "700/700 [==============================] - 0s 177us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6968 - val_accuracy: 0.8533\n",
      "Epoch 991/1000\n",
      "700/700 [==============================] - 0s 175us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6968 - val_accuracy: 0.8533\n",
      "Epoch 992/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6970 - val_accuracy: 0.8533\n",
      "Epoch 993/1000\n",
      "700/700 [==============================] - 0s 177us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6970 - val_accuracy: 0.8533\n",
      "Epoch 994/1000\n",
      "700/700 [==============================] - 0s 182us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6971 - val_accuracy: 0.8533\n",
      "Epoch 995/1000\n",
      "700/700 [==============================] - 0s 180us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6972 - val_accuracy: 0.8533\n",
      "Epoch 996/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6973 - val_accuracy: 0.8533\n",
      "Epoch 997/1000\n",
      "700/700 [==============================] - 0s 178us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6974 - val_accuracy: 0.8533\n",
      "Epoch 998/1000\n",
      "700/700 [==============================] - 0s 181us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6975 - val_accuracy: 0.8533\n",
      "Epoch 999/1000\n",
      "700/700 [==============================] - 0s 177us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6975 - val_accuracy: 0.8533\n",
      "Epoch 1000/1000\n",
      "700/700 [==============================] - 0s 184us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6976 - val_accuracy: 0.8533\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, Y_train, epochs=1000, batch_size=10, validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 학습과정 그래프로 확인 \n",
    "* 히스토리 객체 생성 \n",
    "    * 매 에포크 마다의 훈련 손실값 (loss)\n",
    "    * 매 에포크 마다의 훈련 정확도 (acc)\n",
    "    * 에포크 마다의 검증 손실값 (val_loss)\n",
    "    * 에포크 마다의 검증 정확도 (val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "\n",
    "acc_ax.plot(hist.history['accuracy'], 'b', label='train acc')\n",
    "acc_ax.plot(hist.history['val_accuracy'], 'g', label='val acc')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 학습과정 살펴보기\n",
    "* 모델 학습 시 훈련셋, 검증셋의 손실 및 정확도를 측정합니다.\n",
    "* 반복횟수에 따른 손실 및 정확도 추이를 보면서 학습 상황을 판단합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## training loss and accuracy ##\n",
      "[2.094333384718214, 1.6206669415746415, 1.265817721400942, 1.0268088792051588, 0.8637722487960543, 0.7518548714263099, 0.6639163249305317, 0.60365726181439, 0.548935664338725, 0.5093365945986339, 0.4701830217880862, 0.43842070017542156, 0.41534744181803296, 0.387991143230881, 0.36898505889943667, 0.34972150921821593, 0.3327591172818627, 0.31652836474989143, 0.30433943260993274, 0.289253520326955, 0.27648831659129686, 0.263886878320149, 0.2556346504815987, 0.2434970013265099, 0.23487781834389482, 0.22537463270127772, 0.2176638954452106, 0.20797166983996118, 0.20314245814723628, 0.1952360065387828, 0.18653059351657117, 0.18165873794683388, 0.17483686065035206, 0.168954823538661, 0.16274823030190808, 0.15773739692355906, 0.15287050024739335, 0.14771598439131464, 0.14335842435913426, 0.13936555510652918, 0.1345637387995209, 0.13140704073011875, 0.12674353854464634, 0.12235806531139783, 0.11950114624840873, 0.11538613749934094, 0.11156859134456941, 0.10948964261582919, 0.10549160929928933, 0.10259101523884705, 0.10054218090538468, 0.09724521929664272, 0.09439935806606498, 0.0925651176167386, 0.0896938119083643, 0.08710796888917685, 0.08457260161106075, 0.08306307787341731, 0.08050839262349264, 0.07868872151843138, 0.07658386307635477, 0.07485827053231853, 0.0731216347111123, 0.0711866742399122, 0.0697369336815817, 0.06768720515870623, 0.06639204984530807, 0.06509851938379663, 0.06348220604871001, 0.06185745203069278, 0.06070313477622611, 0.05949961439307247, 0.0579698842551027, 0.05697285280163799, 0.05570739978658301, 0.054603752114677, 0.053627154204462256, 0.052467483840882775, 0.051144190531756194, 0.050348814430513554, 0.04931588132333543, 0.048293650642569574, 0.0473426027556083, 0.04652264565229416, 0.04572194621099957, 0.044901605542483077, 0.04411223395062344, 0.04314244533888996, 0.0426402835175395, 0.04186885256453284, 0.04100544710776636, 0.04049465879797935, 0.03963872042617628, 0.038981643804748146, 0.03837340009797897, 0.037802692449518616, 0.036933259872187464, 0.03662264400294849, 0.03597770727106503, 0.03545266033948532, 0.03488738504903657, 0.03439482789752739, 0.033857590186276605, 0.03331682370044291, 0.03280397801260863, 0.032220795138606005, 0.03194526356777975, 0.031440651436735474, 0.030992273640419756, 0.030603803511309837, 0.030117179519895995, 0.02977582767073597, 0.02928910934632378, 0.028907224269849912, 0.028467279732493418, 0.028206039891977397, 0.027788556653207966, 0.027317567861505916, 0.02711176820365446, 0.02671589797163116, 0.02641764730880303, 0.026070711934672936, 0.02573975988530687, 0.02540171723147588, 0.025097214211044567, 0.02482794293069414, 0.024510311687897357, 0.024278365494683384, 0.02393633337425334, 0.02365862331852051, 0.023361714051238127, 0.023104648511590702, 0.022831790242344142, 0.02258758392584111, 0.022321376144619924, 0.0220649543750499, 0.021860498838525796, 0.021593183731394155, 0.021357850517545428, 0.021120829743865345, 0.020865686550470334, 0.0207068618586553, 0.020476785927478758, 0.02029288690204599, 0.020052030266794776, 0.01982391587724643, 0.01962802613686238, 0.01944741621014795, 0.019226914484586036, 0.019050476074750935, 0.018852623285991806, 0.018708029362772192, 0.01847678273251014, 0.018294224528861897, 0.018147527193650603, 0.01795474411919713, 0.017801727687141725, 0.01762682053127459, 0.017461765584136757, 0.017315754735110593, 0.017161615452330026, 0.016995564462350947, 0.016823256078974478, 0.01667109241576067, 0.01656139887802835, 0.016405054926872255, 0.016224135867586094, 0.016093723748677544, 0.015956723247654736, 0.01582427814802421, 0.0156802755713995, 0.015542461869439908, 0.01542373716365546, 0.015299969013514263, 0.015178247640973756, 0.015037455263414554, 0.01489691859377282, 0.014814278124166386, 0.014685733827562737, 0.014540423140195864, 0.014431725763383188, 0.014321355169106808, 0.01419126116338053, 0.014103510909314667, 0.01398400377947837, 0.013875300596867288, 0.013759608679850186, 0.013667670604107635, 0.013553900248371064, 0.013444141248640205, 0.013362759351730346, 0.013253683420563383, 0.013131180611838187, 0.013069543784617313, 0.012931788386777044, 0.012861297065059521, 0.012758877115058048, 0.012675258683572922, 0.012572565338840443, 0.012489966126824063, 0.012399280809664301, 0.01230192653269374, 0.01222853819240949, 0.012140338746498206, 0.01205862244990255, 0.011988880580091583, 0.011894011893309653, 0.011818029713218233, 0.0117261562130547, 0.011645638538591031, 0.011557100299147091, 0.011484033067245037, 0.01139627109680857, 0.011336316959932447, 0.011262919985789007, 0.01117133190356461, 0.011099192134237715, 0.011040654103271662, 0.010969423855255758, 0.010895978805742093, 0.010827001646560218, 0.01075049274201904, 0.010686140751931816, 0.01061322871329529, 0.010545731588665928, 0.010492825504791524, 0.010426492050256846, 0.01036253294441849, 0.01028657460618498, 0.010232739463182433, 0.010165327275171877, 0.01010489697468334, 0.010037730855401605, 0.00998367635932352, 0.009916165760452194, 0.009859767579473554, 0.009795985630314264, 0.00974639634867864, 0.009690877103379795, 0.009634542342142335, 0.009577861995369728, 0.009523079780462598, 0.00946153184798147, 0.009411228735864694, 0.00936329245617214, 0.009306167089380323, 0.009256008034572005, 0.009201940734471593, 0.009141157996574683, 0.00909062817393403, 0.009047682656507407, 0.008986162011777717, 0.008935486556895609, 0.008906149651323046, 0.008850538078695536, 0.008795561781153084, 0.00874928911216557, 0.008706151976782296, 0.008656401258693741, 0.008604597229610331, 0.008567739660585565, 0.008522509082519848, 0.008470386206837637, 0.008419357995236559, 0.008378145274972278, 0.008332610216790012, 0.00829130762389728, 0.008252023523008184, 0.008210591800577406, 0.008164760388068057, 0.008123086718842387, 0.00808481681119052, 0.008046978667178857, 0.008001479193834322, 0.00796939531906641, 0.00792036423393126, 0.00788016467621284, 0.007838240656669118, 0.007802251700611253, 0.007766660881627883, 0.00772901620616072, 0.007681006389403982, 0.007654741539486817, 0.0076131485435845594, 0.0075836960043359014, 0.007547158621517675, 0.007508439219756318, 0.007470234483480454, 0.007428870584616171, 0.007397112729293959, 0.007363464460442109, 0.007328330492600799, 0.00729029866966552, 0.00725957186659798, 0.007223602108258222, 0.007196190382819623, 0.007163360182728086, 0.007132463674393616, 0.007095370385130601, 0.007062700327618846, 0.007028358704909417, 0.006993964716093615, 0.00696826729690656, 0.006933356475617204, 0.006904400447716138, 0.00687025019599657, 0.006839784441815157, 0.00681437062864591, 0.006778524363679545, 0.006755338192618053, 0.006723864103800484, 0.006690319459552743, 0.006661319389240816, 0.00663385332029845, 0.006601829602316554, 0.006578351131507329, 0.006544344756652468, 0.006518796161149761, 0.00649470775055566, 0.006463913098975484, 0.006436694553121925, 0.006410547357518226, 0.006379007134403634, 0.006356079874759806, 0.006329551432281732, 0.006301546411123127, 0.006281181526303824, 0.006252312103086816, 0.006227526539337954, 0.006198398542723485, 0.006172175633089085, 0.006146104568948171, 0.006121487448191536, 0.006098824741119253, 0.0060749011147501215, 0.0060506429672906445, 0.0060241408163814675, 0.005999477691615799, 0.005975860026332417, 0.005955670423281845, 0.005929440780476268, 0.005906674927765769, 0.005886153524625115, 0.005859045639434564, 0.00583338944208143, 0.005812864946866674, 0.005792633879796735, 0.005766907141410879, 0.005745671149010637, 0.005724763351359538, 0.005701201028257076, 0.005679914847548519, 0.005656609180316861, 0.005638782133714163, 0.005614941889403521, 0.005597174784634262, 0.005575316858344844, 0.00554951197284806, 0.005531354579475841, 0.005509907304908016, 0.005489366654572742, 0.005467760280173804, 0.005448541015253536, 0.005430148547748104, 0.005410076874042196, 0.005388106562895701, 0.005369013044816841, 0.0053494502037730336, 0.0053303402648972615, 0.00530903028557077, 0.005291821479996932, 0.005271816972110953, 0.0052515548720423666, 0.005236146673061219, 0.0052158349268471025, 0.005197776230384729, 0.005180325472195234, 0.005159399951974462, 0.005144552493168573, 0.0051218411735525085, 0.005106597110196682, 0.005088119089071239, 0.005069935306008639, 0.005052383805325787, 0.00503516500133888, 0.0050190083981890765, 0.005000165720204158, 0.004984495575938906, 0.004966730359176706, 0.004951771426879401, 0.0049334376302015565, 0.004913746765149492, 0.004897463734128645, 0.004880711695295759, 0.0048657256993465126, 0.004851949717184263, 0.00483444561583123, 0.004817156391800382, 0.004800770271270137, 0.0047876890116770356, 0.004768853232131473, 0.004753534469221319, 0.004739398905907625, 0.004722856298238705, 0.004709087745452832, 0.004690171177831611, 0.004675779207276978, 0.004662462235345239, 0.004646304903352367, 0.0046316751944167275, 0.004616876346491544, 0.004599286302150826, 0.004587501363961824, 0.00457000465830788, 0.004556234971304158, 0.0045402961309134425, 0.004528288294594469, 0.004514839856087097, 0.00449892800118375, 0.004484221228631213, 0.004470084301595177, 0.0044563657363011905, 0.004441833176783153, 0.004429090657504275, 0.004415231166473989, 0.004400333713108141, 0.004387588361610791, 0.004374691008290808, 0.004360260731274528, 0.0043447735785905805, 0.004334641923820267, 0.004320295930041799, 0.0043085446182106225, 0.004295546855844025, 0.004280956390513373, 0.0042682204603417115, 0.004254588792433164, 0.0042423442080949565, 0.004229981255983668, 0.0042171260450101855, 0.004204103947683636, 0.004194338485415626, 0.004179303872764909, 0.004166445278263251, 0.004155247340843614, 0.004143663216382265, 0.0041294913539396865, 0.0041174327156373435, 0.004106070593531643, 0.0040934262377309745, 0.004082522456467684, 0.004070410598069429, 0.0040580970592730276, 0.00404668488772586, 0.004033587420625346, 0.004024372013684894, 0.004011942015495151, 0.004001361449315612, 0.003988076190164845, 0.003977541999691831, 0.003965144944543551, 0.003954721010190301, 0.003943185155679073, 0.00393096061556467, 0.003920423676858523, 0.003910029468741933, 0.0038999256998067723, 0.003887524371800412, 0.0038767987646029464, 0.0038654712960124018, 0.003855305696405204, 0.0038450065085531347, 0.003832247018414949, 0.0038228601687088875, 0.003812390858573573, 0.003804501363941069, 0.003791606839929175, 0.003782052598294935, 0.0037713436093846603, 0.003760090992104129, 0.0037513037956419535, 0.0037417333718622104, 0.003730865500568013, 0.0037197145001430596, 0.0037126860527288436, 0.0037006409398080515, 0.003691333973048521, 0.003680729282288147, 0.00367034170194529, 0.003660579604911618, 0.0036513509370187033, 0.0036413923413160126, 0.003631822659683946, 0.0036223380784836732, 0.0036136833235754498, 0.0036023953813128172, 0.0035933670105545647, 0.0035835634875443895, 0.00357408363405349, 0.003565863346115553, 0.0035566754888610116, 0.0035473724893693415, 0.0035383443780509487, 0.003528734120274229, 0.003520125267095864, 0.0035103106397270625, 0.0035012749830327394, 0.003493138112493658, 0.0034837350748213275, 0.0034739513133120324, 0.0034651934892670918, 0.003456579435649993, 0.00344904402487113, 0.0034395320765075407, 0.003429202411539986, 0.003424345838305141, 0.0034133532350616794, 0.0034056085893618207, 0.0033951001929900873, 0.00338779131998308, 0.0033802909489687796, 0.003370468969556636, 0.003361948922974989, 0.0033540410937608353, 0.003345729167423477, 0.0033373772665592177, 0.0033287372257161355, 0.003321691831557213, 0.00331279511696526, 0.003305404102762363, 0.0032974497905732796, 0.0032888083993124644, 0.0032805697938394066, 0.0032741158814003158, 0.0032653982293725545, 0.0032573635615075805, 0.003249413999063628, 0.0032419137182712024, 0.003234036508365534, 0.00322586157625275, 0.0032184817420784382, 0.0032108356373750473, 0.003202877577859908, 0.0031948949019092003, 0.0031881548830174976, 0.003179548225099487, 0.00317163132422138, 0.003163774053765727, 0.003157283296293047, 0.0031507008189302203, 0.0031426128043676727, 0.003134251302773399, 0.0031275330161276674, 0.0031206688727252185, 0.0031135964257243487, 0.0031052417953365617, 0.0030982714005014195, 0.0030922142792925503, 0.0030841902505406842, 0.003077670783802335, 0.0030705577760402644, 0.0030630134445215973, 0.0030557816631958954, 0.0030492027934607385, 0.0030429078615270555, 0.003034924283357603, 0.0030275781314620482, 0.003021845720858047, 0.003014073921700141, 0.0030070444618883942, 0.003000462628967528, 0.002993722021346912, 0.0029875212590143615, 0.00298149268907894, 0.0029741875511328023, 0.00296812122022467, 0.0029611130743952734, 0.0029545228570766213, 0.0029468500072003475, 0.0029405184164975904, 0.002935110800795623, 0.002927613803019215, 0.002921633020326096, 0.002915020560612902, 0.0029087800133441176, 0.002902584958688489, 0.0028962691322833834, 0.002889897734192865, 0.002883054380903819, 0.002876873568831278, 0.0028700522172065185, 0.002863991179037839, 0.0028584046746670667, 0.002851534091834245, 0.002845424026184316, 0.0028390155057422817, 0.0028323114541957952, 0.0028271118756882582, 0.0028210242503389185, 0.0028147585623498473, 0.0028091716027120127, 0.002802939118451572, 0.0027967010183991598, 0.0027906490406686708, 0.0027849642776085863, 0.002778441546251997, 0.002773233560479379, 0.0027662186484251703, 0.002761354949325323, 0.0027545632869337817, 0.00274975728825666, 0.002743761342052104, 0.002737758246283712, 0.00273214653965884, 0.002727851225063205, 0.00272014941105486, 0.00271535261043547, 0.002709111209592915, 0.0027035319296244, 0.0026978951433972854, 0.0026927426482351233, 0.002686542337843483, 0.002681620092958578, 0.0026760957893982, 0.002670809646951966, 0.002664519871385502, 0.002659347643410521, 0.002653317673996623, 0.0026481659463440466, 0.002643117944743218, 0.0026375381550419012, 0.002633781386040417, 0.002627326634579471, 0.0026217632569439176, 0.0026165462564677, 0.0026106936262554623, 0.0026051866832338937, 0.0026009344645509763, 0.002594342554636699, 0.00258961544604972, 0.002584059217146465, 0.0025801247044000774, 0.0025742043932301126, 0.0025695605378132313, 0.0025647693714875327, 0.0025591989525959695, 0.002554267618896639, 0.002549231567120712, 0.0025447216583415868, 0.002539831580361351, 0.0025343475730291434, 0.002528755655345906, 0.0025240945663037046, 0.002518857952340373, 0.0025148353886574374, 0.002510085692379757, 0.002504602274608, 0.002499130825162865, 0.0024947518723950324, 0.0024899227403303876, 0.0024847317890297357, 0.0024807647851827954, 0.002475354923184828, 0.0024708606169692106, 0.0024659447933247846, 0.0024614065170421133, 0.002456699135447187, 0.0024521365524768565, 0.0024470113269801784, 0.002441905801242683, 0.0024374816213302048, 0.0024327646026254765, 0.002429101864774046, 0.002423678428749554, 0.002419439924415201, 0.0024142541656536716, 0.0024098282621707766, 0.002405592782140177, 0.0024007758208816603, 0.002396700393208968, 0.0023919754736458085, 0.0023880142144792316, 0.002383355295751244, 0.0023787978837000474, 0.0023742939258227123, 0.0023697134755950953, 0.0023647849136198473, 0.0023609864858112166, 0.002357203287621295, 0.0023523033737936723, 0.0023479630297515543, 0.00234373062765891, 0.0023390043501941753, 0.0023347731018605244, 0.00233070363652327, 0.0023264145158464087, 0.0023222987573327763, 0.0023174882853969135, 0.0023137980184401385, 0.0023096962499299218, 0.0023054380726534873, 0.002300693791975001, 0.002297055093887528, 0.002293250392956127, 0.002288805962182648, 0.0022838726614801477, 0.002280301189914878, 0.002275766848366142, 0.002271869235223026, 0.0022679301793687044, 0.0022637665280074415, 0.0022594277181529573, 0.002256020846419103, 0.0022520081930062067, 0.0022477327139183347, 0.0022437337777643862, 0.0022410200391147685, 0.0022356117096413593, 0.0022319021971530413, 0.0022283695313879952, 0.0022243098039845272, 0.002219560094610123, 0.002216435710683332, 0.0022125034069176764, 0.0022088390309363604, 0.002204887255460822, 0.0022004840746896142, 0.002197113570374703, 0.002192782436447617, 0.0021895627270818556, 0.0021856413567937646, 0.0021815769332793676, 0.0021782254238912305, 0.0021742068339205747, 0.002170078896701203, 0.0021671783079260164, 0.002163262797486303, 0.002158865143636441, 0.0021557001226548372, 0.00215160101402684, 0.00214880416834993, 0.0021442724192248922, 0.0021412540077497917, 0.0021369712560304573, 0.0021335277889323024, 0.0021297063202447525, 0.0021261273409306472, 0.002122382717373382, 0.002119116434810816, 0.0021151811375083136, 0.0021118925522647, 0.0021082244730288428, 0.0021048150748746203, 0.002100767888727465, 0.002097829769731366, 0.0020941028313245626, 0.0020901460383486534, 0.0020867670555682187, 0.0020832974097824523, 0.002080175917529102, 0.0020769007420832555, 0.0020728863962826186, 0.002069695622776635, 0.0020663212144946944, 0.002062958587443323, 0.002059596381981724, 0.002055758214139912, 0.00205304605686771, 0.002049283164420298, 0.00204650732671975, 0.0020428444383599398, 0.0020392068345764917, 0.0020353342302509452, 0.002032552405060934, 0.002029610108002089, 0.0020255568237709147, 0.0020225553159044854, 0.002019452102415796, 0.0020159355007178547, 0.0020127301426587758, 0.0020088018984617, 0.002006075427302026, 0.002002543555240014, 0.0019996098602340293, 0.0019964145812472064, 0.0019934177843554477, 0.001990130865098243, 0.0019870033523537653, 0.0019839033912701, 0.0019806499788371313, 0.0019772980366334586, 0.0019742615795361675, 0.0019710604359196235, 0.0019677393986577436, 0.0019647989164306118, 0.001961716636599574, 0.001958611113617995, 0.001955193671996572, 0.0019529139124123114, 0.0019486634301886495, 0.0019465172397238868, 0.0019428449271280052, 0.0019400004746525415, 0.0019370201621703538, 0.0019342409076801102, 0.0019308597992806296, 0.0019281024196451263, 0.0019250521631745089, 0.0019223500623151528, 0.0019187941122384342, 0.0019165650471612546, 0.001913102765268247, 0.0019099788856692611, 0.0019072134263946542, 0.001903746982861776, 0.0019016528315010614, 0.0018988148558751812, 0.001895181620992454, 0.0018925794113394138, 0.0018896124205119642, 0.0018868435565049628, 0.0018839706941175141, 0.0018808278537887548, 0.0018782908720563034, 0.0018751992615372208, 0.0018721923888993582, 0.001869779031091769, 0.0018666778707743755, 0.001864069642864966, 0.001861346117220819, 0.001858462705942137, 0.0018556712922872976, 0.0018525468422532349, 0.0018499898553792653, 0.0018469579097914642, 0.0018442838365444914, 0.0018416918780920762, 0.0018389078538997897, 0.0018355679744023032, 0.0018325174601549017, 0.0018303472827288455, 0.001827190412274961, 0.001824702055767245, 0.0018221982289105653, 0.0018193234155270538, 0.0018168156089294436, 0.0018141019095699968, 0.0018112221325282008, 0.0018087733285418446, 0.0018059290546391692, 0.0018031531067598345, 0.0018007419579329767, 0.0017980636093333096, 0.0017954055009925338, 0.0017927030544212486, 0.0017900638685594977, 0.001787630998712432, 0.0017850177512238068, 0.001782331547708184, 0.0017796443933288434, 0.0017771826254569792, 0.0017742711817845703, 0.0017718857046150204, 0.001769377989278707, 0.0017667973698865223, 0.0017644767549687198, 0.0017618460252249082, 0.0017592143795419752, 0.001756631288195162, 0.0017540212741421004, 0.0017512414055610341, 0.0017491847567725927, 0.0017462581412733666, 0.001744127505142907, 0.0017415973973194403, 0.0017389740759556713, 0.001736431151013156, 0.00173383137527188, 0.0017311956276119288, 0.0017291042159610828, 0.0017265306735810425, 0.0017240801331354304, 0.0017218225381969074, 0.0017191557924629056, 0.00171646714401764, 0.001714315241510381, 0.0017120657251715394, 0.0017093290599794792, 0.001707491056211958, 0.0017044651962351055, 0.001702548359753564, 0.0016996824664862028, 0.001697382761215392, 0.0016951160222691084, 0.0016927827814860004, 0.0016902730702505714, 0.0016878908209037036, 0.0016858596363038356, 0.0016835764873706336, 0.0016809178300068847, 0.0016784819138203082, 0.001676144398100275, 0.0016739883825981192, 0.0016717264765507675, 0.001669392697346796, 0.001667118918183925, 0.0016645103672219973, 0.0016624818131926336, 0.0016602841114425765, 0.0016578456765273587, 0.0016556932383017349, 0.001653645834345038, 0.001650866012953754, 0.0016488007207434358, 0.001646405176558931, 0.0016442462847667879, 0.0016420772099601372, 0.0016398135464571948, 0.0016375612263800575, 0.0016354642600033133, 0.0016330322745488957, 0.0016309638382933501, 0.0016285031817720405, 0.001626547087549365, 0.0016239884272051443, 0.0016216937489973912, 0.0016197241110993282, 0.0016176843121814143, 0.001615582618147268, 0.0016134526054624335, 0.0016110758808541245, 0.0016089251339768192, 0.0016069445141641025, 0.001604724191981534, 0.0016026272068432133, 0.001600468367853734, 0.0015982604641716794, 0.0015964331650008847, 0.0015940549438320367, 0.0015919366348368514, 0.0015897469686543834, 0.0015878942749363238, 0.0015857522105631819, 0.001583499465985889, 0.001581401498489348, 0.0015795611389746358, 0.0015774204474707533, 0.0015752450113983027, 0.0015732636242838842, 0.001571000023562062, 0.0015688806082055505, 0.0015670154838257335, 0.0015648068361250418, 0.0015625204974120217, 0.0015607225725294224, 0.0015585578483296558, 0.0015566547721391545, 0.0015546102764866581, 0.0015527862519125587, 0.0015509222072848518, 0.0015488422446651383, 0.0015467202640138567, 0.0015448469304828905, 0.0015426588485882217, 0.001540690624304781, 0.0015385188819241843, 0.0015367940957990607, 0.00153482408038274, 0.0015330485798975653, 0.0015305727341910825, 0.0015287943903656144, 0.0015267710421799814, 0.001524979543838916, 0.0015228499949444085, 0.0015209505022669744, 0.001519078516970954, 0.0015171169012319296, 0.001515402180042916, 0.001513279941510908, 0.0015113060071598738, 0.0015095596883579025, 0.0015075166366711659, 0.0015056660897763711, 0.0015036578899266066, 0.0015018760696485906, 0.0015000647297711111, 0.0014979776930496363, 0.0014961994944314937, 0.0014942287604623873, 0.001492537626264883, 0.0014906240246740968, 0.0014886625410456742, 0.0014868094186697687, 0.0014849645412011471, 0.0014828285360376217, 0.001481069862867506, 0.0014794491788571967, 0.0014776626926115049, 0.0014756479179985555, 0.0014740086859092115]\n",
      "[0.32285714, 0.61142856, 0.71, 0.75714284, 0.7985714, 0.83428574, 0.8442857, 0.8585714, 0.8742857, 0.87857145, 0.8971428, 0.9057143, 0.91, 0.9242857, 0.9185714, 0.93285716, 0.9342857, 0.94142854, 0.93714285, 0.9442857, 0.9442857, 0.9514286, 0.95285714, 0.9514286, 0.95, 0.95857143, 0.9557143, 0.96, 0.96, 0.96428573, 0.9671429, 0.9671429, 0.9671429, 0.97, 0.97, 0.9742857, 0.9714286, 0.9771429, 0.9771429, 0.98, 0.98142856, 0.98, 0.9842857, 0.98142856, 0.9842857, 0.98571426, 0.99, 0.98571426, 0.9885714, 0.99285716, 0.9885714, 0.99142855, 0.9942857, 0.9942857, 0.99285716, 0.9942857, 0.9957143, 0.99714285, 0.99857146, 0.99857146, 0.99714285, 0.99714285, 0.99857146, 0.99857146, 0.99857146, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print('## training loss and accuracy ##')\n",
    "print(hist.history['loss'])\n",
    "print(hist.history['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 모델 평가하기\n",
    "* 준비된 시험셋으로 학습한 모델을 평가합니다.\n",
    "* 케라스에서는 evaluate() 함수를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 45us/sample - loss: 0.5471 - accuracy: 0.8798\n",
      "## evaluation loss and_metrics ##\n",
      "[0.5470691438039764, 0.8798]\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = model.evaluate(X_test, Y_test, batch_size=32)\n",
    "print('## evaluation loss and_metrics ##')\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. 모델 사용하기\n",
    "* 임의의 입력으로 모델의 출력을 얻습니다.\n",
    "* 케라스에서는 predict() 함수를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## yhat ##\n",
      "[[3.7283603e-09 5.7813845e-13 2.7963407e-09 7.2410611e-09 2.8661476e-11\n",
      "  4.2531459e-10 6.6161357e-14 9.9999976e-01 5.0808435e-10 2.5218134e-07]]\n"
     ]
    }
   ],
   "source": [
    "xhat = X_test[0:1]\n",
    "yhat = model.predict(xhat)\n",
    "print('## yhat ##')\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. 러닝 모델 가시화 기능 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"295pt\" viewBox=\"0.00 0.00 284.00 221.00\" width=\"379pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1.33333 1.33333) rotate(0) translate(4 217)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-217 280,-217 280,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 2053171781256 -->\n",
       "<g class=\"node\" id=\"node1\"><title>2053171781256</title>\n",
       "<polygon fill=\"none\" points=\"0,-166.5 0,-212.5 276,-212.5 276,-166.5 0,-166.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"76\" y=\"-185.8\">dense_input: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"152,-166.5 152,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"180\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"152,-189.5 208,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"180\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"208,-166.5 208,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"242\" y=\"-197.3\">[(?, 784)]</text>\n",
       "<polyline fill=\"none\" points=\"208,-189.5 276,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"242\" y=\"-174.3\">[(?, 784)]</text>\n",
       "</g>\n",
       "<!-- 2053463192584 -->\n",
       "<g class=\"node\" id=\"node2\"><title>2053463192584</title>\n",
       "<polygon fill=\"none\" points=\"35.5,-83.5 35.5,-129.5 240.5,-129.5 240.5,-83.5 35.5,-83.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"80.5\" y=\"-102.8\">dense: Dense</text>\n",
       "<polyline fill=\"none\" points=\"125.5,-83.5 125.5,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"153.5\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"125.5,-106.5 181.5,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"153.5\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"181.5,-83.5 181.5,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"211\" y=\"-114.3\">(?, 784)</text>\n",
       "<polyline fill=\"none\" points=\"181.5,-106.5 240.5,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"211\" y=\"-91.3\">(?, 64)</text>\n",
       "</g>\n",
       "<!-- 2053171781256&#45;&gt;2053463192584 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>2053171781256-&gt;2053463192584</title>\n",
       "<path d=\"M138,-166.366C138,-158.152 138,-148.658 138,-139.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"141.5,-139.607 138,-129.607 134.5,-139.607 141.5,-139.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2053463195400 -->\n",
       "<g class=\"node\" id=\"node3\"><title>2053463195400</title>\n",
       "<polygon fill=\"none\" points=\"31.5,-0.5 31.5,-46.5 244.5,-46.5 244.5,-0.5 31.5,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"83.5\" y=\"-19.8\">dense_1: Dense</text>\n",
       "<polyline fill=\"none\" points=\"135.5,-0.5 135.5,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"163.5\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"135.5,-23.5 191.5,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"163.5\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"191.5,-0.5 191.5,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"218\" y=\"-31.3\">(?, 64)</text>\n",
       "<polyline fill=\"none\" points=\"191.5,-23.5 244.5,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"218\" y=\"-8.3\">(?, 10)</text>\n",
       "</g>\n",
       "<!-- 2053463192584&#45;&gt;2053463195400 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>2053463192584-&gt;2053463195400</title>\n",
       "<path d=\"M138,-83.3664C138,-75.1516 138,-65.6579 138,-56.7252\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"141.5,-56.6068 138,-46.6068 134.5,-56.6069 141.5,-56.6068\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pydot\n",
    "import graphviz\n",
    "from IPython.display import SVG\n",
    "from tensorflow.keras.utils import model_to_dot\n",
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + \"C:/Program Files (x86)/Graphviz2.38/bin\"\n",
    "\n",
    "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. 모델 저장과 모델 로딩 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model.save('mnist_mlp_model.h5')\n",
    "model = load_model('mnist_mlp_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
