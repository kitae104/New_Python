{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 기본 케라스와 텐서보드 연동하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. 사용할 패키지 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "np.random.seed(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 데이터셋 생성하기\n",
    "* 원본 데이터를 불러오거나 시뮬레이션을 통해 데이터를 생성합니다.\n",
    "* 데이터로부터 훈련셋, 검증셋, 시험셋을 생성합니다.\n",
    "* 이 때 딥러닝 모델의 학습 및 평가를 할 수 있도록 포맷 변환을 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 훈련셋과 시험셋 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (50000, 28, 28)\n",
      "X_train (50000,)\n",
      "X_train (10000, 28, 28)\n",
      "X_train (10000,)\n"
     ]
    }
   ],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "# 훈련셋과 검증셋 분리\n",
    "X_val = X_train[50000:]        \n",
    "Y_val = Y_train[50000:]\n",
    "X_train = X_train[:50000]\n",
    "Y_train = Y_train[:50000]\n",
    "print('X_train', X_train.shape)\n",
    "print('X_train', Y_train.shape)\n",
    "print('X_train', X_val.shape)\n",
    "print('X_train', Y_val.shape)\n",
    "\n",
    "X_train = X_train.reshape(50000, 784).astype('float32') / 255.0\n",
    "X_val = X_val.reshape(10000, 784).astype('float32') / 255.0\n",
    "X_test = X_test.reshape(10000, 784).astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 훈련셋, 검증셋 고르기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rand_idxs = np.random.choice(50000, 700)\n",
    "val_rand_idxs = np.random.choice(10000, 300)\n",
    "\n",
    "X_train = X_train[train_rand_idxs]\n",
    "Y_train = Y_train[train_rand_idxs]\n",
    "X_val = X_val[val_rand_idxs]\n",
    "Y_val = Y_val[val_rand_idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 라벨 데이터 원핫인코딩 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = to_categorical(Y_train)\n",
    "Y_val = to_categorical(Y_val)\n",
    "Y_test = to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 모델 구성하기\n",
    "* 시퀀스 모델을 생성한 뒤 필요한 레이어를 추가하여 구성합니다.\n",
    "* 좀 더 복잡한 모델이 필요할 때는 케라스 함수 API를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 50,890\n",
      "Trainable params: 50,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=64, input_dim=28*28, activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 모델 학습과정 설정하기\n",
    "* 학습하기 전에 학습에 대한 설정을 수행합니다.\n",
    "* 손실 함수 및 최적화 방법을 정의합니다.\n",
    "* 케라스에서는 compile() 함수를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 모델 학습시키기\n",
    "* 훈련셋을 이용하여 구성한 모델로 학습시킵니다.\n",
    "* 케라스에서는 fit() 함수를 사용합니다.\n",
    "#### 4.1 배치사이즈\n",
    "* 몇 개를  처리하고 해답을 맞추는지를 의미함 \n",
    "    * 100 : 100개를 처리하고 해답을 맞춤\n",
    "    * 1: 1개를 처리하고 해답을 맞춤\n",
    "* 배치사이즈가 작을수록 갱신이 자주 발생함 \n",
    "#### 4.2 에폭\n",
    "* 같은 데이터셋으로 반복적으로 가중치를 갱신하면서 학습\n",
    "* 서로 다른 20문제를 1번 푸는 경우보다 같은 1문제를 20번 푸는 경우 정확도가 높다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1000\n",
      "700/700 [==============================] - 1s 1ms/sample - loss: 2.0382 - accuracy: 0.3729 - val_loss: 1.7526 - val_accuracy: 0.5900\n",
      "Epoch 2/1000\n",
      "700/700 [==============================] - 0s 245us/sample - loss: 1.5489 - accuracy: 0.6429 - val_loss: 1.3525 - val_accuracy: 0.7367\n",
      "Epoch 3/1000\n",
      "700/700 [==============================] - 0s 245us/sample - loss: 1.2098 - accuracy: 0.7343 - val_loss: 1.0962 - val_accuracy: 0.7700\n",
      "Epoch 4/1000\n",
      "700/700 [==============================] - 0s 279us/sample - loss: 0.9877 - accuracy: 0.7957 - val_loss: 0.9333 - val_accuracy: 0.8333\n",
      "Epoch 5/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.8346 - accuracy: 0.8286 - val_loss: 0.8323 - val_accuracy: 0.8367\n",
      "Epoch 6/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.7306 - accuracy: 0.8414 - val_loss: 0.7548 - val_accuracy: 0.8200\n",
      "Epoch 7/1000\n",
      "700/700 [==============================] - 0s 245us/sample - loss: 0.6495 - accuracy: 0.8686 - val_loss: 0.6885 - val_accuracy: 0.8333\n",
      "Epoch 8/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.5883 - accuracy: 0.8729 - val_loss: 0.6498 - val_accuracy: 0.8300\n",
      "Epoch 9/1000\n",
      "700/700 [==============================] - 0s 254us/sample - loss: 0.5396 - accuracy: 0.8843 - val_loss: 0.6102 - val_accuracy: 0.8467\n",
      "Epoch 10/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.4953 - accuracy: 0.8971 - val_loss: 0.5938 - val_accuracy: 0.8533\n",
      "Epoch 11/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.4644 - accuracy: 0.9000 - val_loss: 0.5627 - val_accuracy: 0.8667\n",
      "Epoch 12/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.4341 - accuracy: 0.9029 - val_loss: 0.5448 - val_accuracy: 0.8567\n",
      "Epoch 13/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.4080 - accuracy: 0.9171 - val_loss: 0.5312 - val_accuracy: 0.8567\n",
      "Epoch 14/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.3830 - accuracy: 0.9214 - val_loss: 0.5293 - val_accuracy: 0.8500\n",
      "Epoch 15/1000\n",
      "700/700 [==============================] - 0s 245us/sample - loss: 0.3619 - accuracy: 0.9271 - val_loss: 0.5092 - val_accuracy: 0.8600\n",
      "Epoch 16/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.3419 - accuracy: 0.9314 - val_loss: 0.5139 - val_accuracy: 0.8500\n",
      "Epoch 17/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.3278 - accuracy: 0.9314 - val_loss: 0.4955 - val_accuracy: 0.8567\n",
      "Epoch 18/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.3098 - accuracy: 0.9371 - val_loss: 0.4839 - val_accuracy: 0.8533\n",
      "Epoch 19/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.2936 - accuracy: 0.9500 - val_loss: 0.4819 - val_accuracy: 0.8600\n",
      "Epoch 20/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.2833 - accuracy: 0.9429 - val_loss: 0.4818 - val_accuracy: 0.8567\n",
      "Epoch 21/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.2704 - accuracy: 0.9486 - val_loss: 0.4689 - val_accuracy: 0.8600\n",
      "Epoch 22/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.2603 - accuracy: 0.9514 - val_loss: 0.4712 - val_accuracy: 0.8567\n",
      "Epoch 23/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.2487 - accuracy: 0.9529 - val_loss: 0.4681 - val_accuracy: 0.8600\n",
      "Epoch 24/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.2392 - accuracy: 0.9529 - val_loss: 0.4623 - val_accuracy: 0.8667\n",
      "Epoch 25/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.2290 - accuracy: 0.9571 - val_loss: 0.4648 - val_accuracy: 0.8667\n",
      "Epoch 26/1000\n",
      "700/700 [==============================] - 0s 252us/sample - loss: 0.2212 - accuracy: 0.9600 - val_loss: 0.4685 - val_accuracy: 0.8567\n",
      "Epoch 27/1000\n",
      "700/700 [==============================] - 0s 245us/sample - loss: 0.2117 - accuracy: 0.9614 - val_loss: 0.4633 - val_accuracy: 0.8633\n",
      "Epoch 28/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.2061 - accuracy: 0.9629 - val_loss: 0.4593 - val_accuracy: 0.8667\n",
      "Epoch 29/1000\n",
      "700/700 [==============================] - 0s 240us/sample - loss: 0.1968 - accuracy: 0.9643 - val_loss: 0.4558 - val_accuracy: 0.8667\n",
      "Epoch 30/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.1910 - accuracy: 0.9629 - val_loss: 0.4587 - val_accuracy: 0.8667\n",
      "Epoch 31/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.1836 - accuracy: 0.9714 - val_loss: 0.4592 - val_accuracy: 0.8633\n",
      "Epoch 32/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.1773 - accuracy: 0.9743 - val_loss: 0.4565 - val_accuracy: 0.8667\n",
      "Epoch 33/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.1712 - accuracy: 0.9700 - val_loss: 0.4526 - val_accuracy: 0.8733\n",
      "Epoch 34/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.1657 - accuracy: 0.9714 - val_loss: 0.4591 - val_accuracy: 0.8700\n",
      "Epoch 35/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.1604 - accuracy: 0.9729 - val_loss: 0.4627 - val_accuracy: 0.8600\n",
      "Epoch 36/1000\n",
      "700/700 [==============================] - 0s 245us/sample - loss: 0.1537 - accuracy: 0.9786 - val_loss: 0.4596 - val_accuracy: 0.8600\n",
      "Epoch 37/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.1501 - accuracy: 0.9743 - val_loss: 0.4570 - val_accuracy: 0.8667\n",
      "Epoch 38/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.1455 - accuracy: 0.9757 - val_loss: 0.4577 - val_accuracy: 0.8733\n",
      "Epoch 39/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.1415 - accuracy: 0.9786 - val_loss: 0.4558 - val_accuracy: 0.8733\n",
      "Epoch 40/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.1368 - accuracy: 0.9786 - val_loss: 0.4559 - val_accuracy: 0.8733\n",
      "Epoch 41/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.1315 - accuracy: 0.9814 - val_loss: 0.4647 - val_accuracy: 0.8667\n",
      "Epoch 42/1000\n",
      "700/700 [==============================] - 0s 245us/sample - loss: 0.1294 - accuracy: 0.9829 - val_loss: 0.4581 - val_accuracy: 0.8767\n",
      "Epoch 43/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.1243 - accuracy: 0.9814 - val_loss: 0.4587 - val_accuracy: 0.8767\n",
      "Epoch 44/1000\n",
      "700/700 [==============================] - 0s 247us/sample - loss: 0.1215 - accuracy: 0.9857 - val_loss: 0.4589 - val_accuracy: 0.8767\n",
      "Epoch 45/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.1177 - accuracy: 0.9871 - val_loss: 0.4572 - val_accuracy: 0.8733\n",
      "Epoch 46/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.1145 - accuracy: 0.9871 - val_loss: 0.4656 - val_accuracy: 0.8633\n",
      "Epoch 47/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.1108 - accuracy: 0.9886 - val_loss: 0.4580 - val_accuracy: 0.8767\n",
      "Epoch 48/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.1081 - accuracy: 0.9871 - val_loss: 0.4602 - val_accuracy: 0.8767\n",
      "Epoch 49/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.1044 - accuracy: 0.9871 - val_loss: 0.4693 - val_accuracy: 0.8633\n",
      "Epoch 50/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.1023 - accuracy: 0.9900 - val_loss: 0.4589 - val_accuracy: 0.8767\n",
      "Epoch 51/1000\n",
      "700/700 [==============================] - 0s 246us/sample - loss: 0.0989 - accuracy: 0.9900 - val_loss: 0.4630 - val_accuracy: 0.8700\n",
      "Epoch 52/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0965 - accuracy: 0.9900 - val_loss: 0.4627 - val_accuracy: 0.8700\n",
      "Epoch 53/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0939 - accuracy: 0.9900 - val_loss: 0.4625 - val_accuracy: 0.8767\n",
      "Epoch 54/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0916 - accuracy: 0.9886 - val_loss: 0.4645 - val_accuracy: 0.8700\n",
      "Epoch 55/1000\n",
      "700/700 [==============================] - 0s 248us/sample - loss: 0.0891 - accuracy: 0.9929 - val_loss: 0.4642 - val_accuracy: 0.8733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0861 - accuracy: 0.9929 - val_loss: 0.4686 - val_accuracy: 0.8667\n",
      "Epoch 57/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0846 - accuracy: 0.9943 - val_loss: 0.4672 - val_accuracy: 0.8700\n",
      "Epoch 58/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0823 - accuracy: 0.9943 - val_loss: 0.4719 - val_accuracy: 0.8667\n",
      "Epoch 59/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0805 - accuracy: 0.9957 - val_loss: 0.4678 - val_accuracy: 0.8700\n",
      "Epoch 60/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0785 - accuracy: 0.9957 - val_loss: 0.4716 - val_accuracy: 0.8633\n",
      "Epoch 61/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0766 - accuracy: 0.9971 - val_loss: 0.4686 - val_accuracy: 0.8700\n",
      "Epoch 62/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0749 - accuracy: 0.9957 - val_loss: 0.4701 - val_accuracy: 0.8700\n",
      "Epoch 63/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0730 - accuracy: 0.9971 - val_loss: 0.4727 - val_accuracy: 0.8700\n",
      "Epoch 64/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0715 - accuracy: 0.9971 - val_loss: 0.4682 - val_accuracy: 0.8733\n",
      "Epoch 65/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0698 - accuracy: 0.9971 - val_loss: 0.4709 - val_accuracy: 0.8733\n",
      "Epoch 66/1000\n",
      "700/700 [==============================] - 0s 256us/sample - loss: 0.0680 - accuracy: 0.9971 - val_loss: 0.4776 - val_accuracy: 0.8667\n",
      "Epoch 67/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0665 - accuracy: 0.9971 - val_loss: 0.4772 - val_accuracy: 0.8667\n",
      "Epoch 68/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0654 - accuracy: 0.9986 - val_loss: 0.4762 - val_accuracy: 0.8667\n",
      "Epoch 69/1000\n",
      "700/700 [==============================] - 0s 245us/sample - loss: 0.0638 - accuracy: 0.9986 - val_loss: 0.4729 - val_accuracy: 0.8700\n",
      "Epoch 70/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0623 - accuracy: 0.9986 - val_loss: 0.4775 - val_accuracy: 0.8667\n",
      "Epoch 71/1000\n",
      "700/700 [==============================] - 0s 248us/sample - loss: 0.0611 - accuracy: 0.9986 - val_loss: 0.4764 - val_accuracy: 0.8700\n",
      "Epoch 72/1000\n",
      "700/700 [==============================] - 0s 236us/sample - loss: 0.0597 - accuracy: 0.9971 - val_loss: 0.4785 - val_accuracy: 0.8633\n",
      "Epoch 73/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0586 - accuracy: 0.9986 - val_loss: 0.4838 - val_accuracy: 0.8667\n",
      "Epoch 74/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0576 - accuracy: 0.9986 - val_loss: 0.4810 - val_accuracy: 0.8667\n",
      "Epoch 75/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0563 - accuracy: 0.9986 - val_loss: 0.4815 - val_accuracy: 0.8667\n",
      "Epoch 76/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0551 - accuracy: 1.0000 - val_loss: 0.4799 - val_accuracy: 0.8700\n",
      "Epoch 77/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0541 - accuracy: 0.9986 - val_loss: 0.4784 - val_accuracy: 0.8700\n",
      "Epoch 78/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0528 - accuracy: 1.0000 - val_loss: 0.4828 - val_accuracy: 0.8733\n",
      "Epoch 79/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0521 - accuracy: 0.9986 - val_loss: 0.4832 - val_accuracy: 0.8667\n",
      "Epoch 80/1000\n",
      "700/700 [==============================] - 0s 254us/sample - loss: 0.0510 - accuracy: 1.0000 - val_loss: 0.4840 - val_accuracy: 0.8700\n",
      "Epoch 81/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0498 - accuracy: 1.0000 - val_loss: 0.4818 - val_accuracy: 0.8700\n",
      "Epoch 82/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0491 - accuracy: 1.0000 - val_loss: 0.4851 - val_accuracy: 0.8700\n",
      "Epoch 83/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0482 - accuracy: 1.0000 - val_loss: 0.4863 - val_accuracy: 0.8700\n",
      "Epoch 84/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0473 - accuracy: 1.0000 - val_loss: 0.4874 - val_accuracy: 0.8700\n",
      "Epoch 85/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0466 - accuracy: 1.0000 - val_loss: 0.4872 - val_accuracy: 0.8700\n",
      "Epoch 86/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0454 - accuracy: 1.0000 - val_loss: 0.4918 - val_accuracy: 0.8667\n",
      "Epoch 87/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0450 - accuracy: 1.0000 - val_loss: 0.4906 - val_accuracy: 0.8667\n",
      "Epoch 88/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0441 - accuracy: 1.0000 - val_loss: 0.4909 - val_accuracy: 0.8667\n",
      "Epoch 89/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0433 - accuracy: 1.0000 - val_loss: 0.4908 - val_accuracy: 0.8700\n",
      "Epoch 90/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0426 - accuracy: 1.0000 - val_loss: 0.4917 - val_accuracy: 0.8700\n",
      "Epoch 91/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0418 - accuracy: 1.0000 - val_loss: 0.4925 - val_accuracy: 0.8700\n",
      "Epoch 92/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0412 - accuracy: 1.0000 - val_loss: 0.4923 - val_accuracy: 0.8667\n",
      "Epoch 93/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0404 - accuracy: 1.0000 - val_loss: 0.4910 - val_accuracy: 0.8700\n",
      "Epoch 94/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0398 - accuracy: 1.0000 - val_loss: 0.4941 - val_accuracy: 0.8700\n",
      "Epoch 95/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0391 - accuracy: 1.0000 - val_loss: 0.4945 - val_accuracy: 0.8700\n",
      "Epoch 96/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0384 - accuracy: 1.0000 - val_loss: 0.4966 - val_accuracy: 0.8667\n",
      "Epoch 97/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0380 - accuracy: 1.0000 - val_loss: 0.4975 - val_accuracy: 0.8700\n",
      "Epoch 98/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0373 - accuracy: 1.0000 - val_loss: 0.4970 - val_accuracy: 0.8700\n",
      "Epoch 99/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0367 - accuracy: 1.0000 - val_loss: 0.4992 - val_accuracy: 0.8667\n",
      "Epoch 100/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0361 - accuracy: 1.0000 - val_loss: 0.4989 - val_accuracy: 0.8667\n",
      "Epoch 101/1000\n",
      "700/700 [==============================] - 0s 245us/sample - loss: 0.0357 - accuracy: 1.0000 - val_loss: 0.4992 - val_accuracy: 0.8700\n",
      "Epoch 102/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0350 - accuracy: 1.0000 - val_loss: 0.5002 - val_accuracy: 0.8667\n",
      "Epoch 103/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0345 - accuracy: 1.0000 - val_loss: 0.5002 - val_accuracy: 0.8700\n",
      "Epoch 104/1000\n",
      "700/700 [==============================] - 0s 245us/sample - loss: 0.0340 - accuracy: 1.0000 - val_loss: 0.5024 - val_accuracy: 0.8667\n",
      "Epoch 105/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0335 - accuracy: 1.0000 - val_loss: 0.5007 - val_accuracy: 0.8700\n",
      "Epoch 106/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0330 - accuracy: 1.0000 - val_loss: 0.5039 - val_accuracy: 0.8667\n",
      "Epoch 107/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0326 - accuracy: 1.0000 - val_loss: 0.5038 - val_accuracy: 0.8667\n",
      "Epoch 108/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0321 - accuracy: 1.0000 - val_loss: 0.5037 - val_accuracy: 0.8667\n",
      "Epoch 109/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0316 - accuracy: 1.0000 - val_loss: 0.5042 - val_accuracy: 0.8700\n",
      "Epoch 110/1000\n",
      "700/700 [==============================] - 0s 245us/sample - loss: 0.0311 - accuracy: 1.0000 - val_loss: 0.5060 - val_accuracy: 0.8700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0308 - accuracy: 1.0000 - val_loss: 0.5052 - val_accuracy: 0.8733\n",
      "Epoch 112/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0304 - accuracy: 1.0000 - val_loss: 0.5075 - val_accuracy: 0.8700\n",
      "Epoch 113/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0299 - accuracy: 1.0000 - val_loss: 0.5101 - val_accuracy: 0.8700\n",
      "Epoch 114/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0295 - accuracy: 1.0000 - val_loss: 0.5107 - val_accuracy: 0.8700\n",
      "Epoch 115/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0292 - accuracy: 1.0000 - val_loss: 0.5097 - val_accuracy: 0.8700\n",
      "Epoch 116/1000\n",
      "700/700 [==============================] - 0s 246us/sample - loss: 0.0287 - accuracy: 1.0000 - val_loss: 0.5092 - val_accuracy: 0.8667\n",
      "Epoch 117/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0283 - accuracy: 1.0000 - val_loss: 0.5094 - val_accuracy: 0.8700\n",
      "Epoch 118/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0279 - accuracy: 1.0000 - val_loss: 0.5110 - val_accuracy: 0.8700\n",
      "Epoch 119/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0277 - accuracy: 1.0000 - val_loss: 0.5107 - val_accuracy: 0.8700\n",
      "Epoch 120/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0273 - accuracy: 1.0000 - val_loss: 0.5121 - val_accuracy: 0.8700\n",
      "Epoch 121/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0269 - accuracy: 1.0000 - val_loss: 0.5129 - val_accuracy: 0.8700\n",
      "Epoch 122/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0266 - accuracy: 1.0000 - val_loss: 0.5113 - val_accuracy: 0.8733\n",
      "Epoch 123/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0262 - accuracy: 1.0000 - val_loss: 0.5130 - val_accuracy: 0.8667\n",
      "Epoch 124/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0261 - accuracy: 1.0000 - val_loss: 0.5145 - val_accuracy: 0.8700\n",
      "Epoch 125/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0256 - accuracy: 1.0000 - val_loss: 0.5149 - val_accuracy: 0.8700\n",
      "Epoch 126/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0253 - accuracy: 1.0000 - val_loss: 0.5154 - val_accuracy: 0.8700\n",
      "Epoch 127/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0250 - accuracy: 1.0000 - val_loss: 0.5158 - val_accuracy: 0.8700\n",
      "Epoch 128/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0247 - accuracy: 1.0000 - val_loss: 0.5170 - val_accuracy: 0.8700\n",
      "Epoch 129/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0244 - accuracy: 1.0000 - val_loss: 0.5164 - val_accuracy: 0.8733\n",
      "Epoch 130/1000\n",
      "700/700 [==============================] - 0s 245us/sample - loss: 0.0242 - accuracy: 1.0000 - val_loss: 0.5177 - val_accuracy: 0.8700\n",
      "Epoch 131/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0239 - accuracy: 1.0000 - val_loss: 0.5178 - val_accuracy: 0.8733\n",
      "Epoch 132/1000\n",
      "700/700 [==============================] - 0s 245us/sample - loss: 0.0236 - accuracy: 1.0000 - val_loss: 0.5181 - val_accuracy: 0.8733\n",
      "Epoch 133/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0234 - accuracy: 1.0000 - val_loss: 0.5198 - val_accuracy: 0.8700\n",
      "Epoch 134/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0231 - accuracy: 1.0000 - val_loss: 0.5204 - val_accuracy: 0.8700\n",
      "Epoch 135/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0228 - accuracy: 1.0000 - val_loss: 0.5200 - val_accuracy: 0.8733\n",
      "Epoch 136/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0226 - accuracy: 1.0000 - val_loss: 0.5208 - val_accuracy: 0.8700\n",
      "Epoch 137/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0223 - accuracy: 1.0000 - val_loss: 0.5208 - val_accuracy: 0.8700\n",
      "Epoch 138/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0221 - accuracy: 1.0000 - val_loss: 0.5212 - val_accuracy: 0.8733\n",
      "Epoch 139/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0218 - accuracy: 1.0000 - val_loss: 0.5226 - val_accuracy: 0.8733\n",
      "Epoch 140/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0216 - accuracy: 1.0000 - val_loss: 0.5233 - val_accuracy: 0.8700\n",
      "Epoch 141/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0214 - accuracy: 1.0000 - val_loss: 0.5251 - val_accuracy: 0.8700\n",
      "Epoch 142/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0212 - accuracy: 1.0000 - val_loss: 0.5247 - val_accuracy: 0.8700\n",
      "Epoch 143/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0210 - accuracy: 1.0000 - val_loss: 0.5244 - val_accuracy: 0.8667\n",
      "Epoch 144/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0207 - accuracy: 1.0000 - val_loss: 0.5247 - val_accuracy: 0.8700\n",
      "Epoch 145/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0205 - accuracy: 1.0000 - val_loss: 0.5254 - val_accuracy: 0.8733\n",
      "Epoch 146/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0203 - accuracy: 1.0000 - val_loss: 0.5264 - val_accuracy: 0.8667\n",
      "Epoch 147/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0201 - accuracy: 1.0000 - val_loss: 0.5278 - val_accuracy: 0.8700\n",
      "Epoch 148/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.5280 - val_accuracy: 0.8700\n",
      "Epoch 149/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0197 - accuracy: 1.0000 - val_loss: 0.5280 - val_accuracy: 0.8667\n",
      "Epoch 150/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0195 - accuracy: 1.0000 - val_loss: 0.5275 - val_accuracy: 0.8700\n",
      "Epoch 151/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0193 - accuracy: 1.0000 - val_loss: 0.5288 - val_accuracy: 0.8667\n",
      "Epoch 152/1000\n",
      "700/700 [==============================] - 0s 246us/sample - loss: 0.0191 - accuracy: 1.0000 - val_loss: 0.5296 - val_accuracy: 0.8700\n",
      "Epoch 153/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.5291 - val_accuracy: 0.8700\n",
      "Epoch 154/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0187 - accuracy: 1.0000 - val_loss: 0.5302 - val_accuracy: 0.8667\n",
      "Epoch 155/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0185 - accuracy: 1.0000 - val_loss: 0.5323 - val_accuracy: 0.8700\n",
      "Epoch 156/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.5324 - val_accuracy: 0.8700\n",
      "Epoch 157/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0182 - accuracy: 1.0000 - val_loss: 0.5324 - val_accuracy: 0.8700\n",
      "Epoch 158/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.5326 - val_accuracy: 0.8700\n",
      "Epoch 159/1000\n",
      "700/700 [==============================] - 0s 235us/sample - loss: 0.0179 - accuracy: 1.0000 - val_loss: 0.5337 - val_accuracy: 0.8700\n",
      "Epoch 160/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0177 - accuracy: 1.0000 - val_loss: 0.5337 - val_accuracy: 0.8667\n",
      "Epoch 161/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0175 - accuracy: 1.0000 - val_loss: 0.5346 - val_accuracy: 0.8700\n",
      "Epoch 162/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.5344 - val_accuracy: 0.8667\n",
      "Epoch 163/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0172 - accuracy: 1.0000 - val_loss: 0.5358 - val_accuracy: 0.8700\n",
      "Epoch 164/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.5370 - val_accuracy: 0.8700\n",
      "Epoch 165/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.5370 - val_accuracy: 0.8700\n",
      "Epoch 166/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.5372 - val_accuracy: 0.8700\n",
      "Epoch 167/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.5382 - val_accuracy: 0.8667\n",
      "Epoch 168/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.5382 - val_accuracy: 0.8667\n",
      "Epoch 169/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.5391 - val_accuracy: 0.8667\n",
      "Epoch 170/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.5401 - val_accuracy: 0.8667\n",
      "Epoch 171/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.5400 - val_accuracy: 0.8667\n",
      "Epoch 172/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.5404 - val_accuracy: 0.8667\n",
      "Epoch 173/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.5403 - val_accuracy: 0.8667\n",
      "Epoch 174/1000\n",
      "700/700 [==============================] - 0s 255us/sample - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.5406 - val_accuracy: 0.8667\n",
      "Epoch 175/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.5403 - val_accuracy: 0.8700\n",
      "Epoch 176/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.5407 - val_accuracy: 0.8700\n",
      "Epoch 177/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.5412 - val_accuracy: 0.8700\n",
      "Epoch 178/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.5425 - val_accuracy: 0.8667\n",
      "Epoch 179/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.5433 - val_accuracy: 0.8667\n",
      "Epoch 180/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.5434 - val_accuracy: 0.8667\n",
      "Epoch 181/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.5434 - val_accuracy: 0.8667\n",
      "Epoch 182/1000\n",
      "700/700 [==============================] - 0s 251us/sample - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.5444 - val_accuracy: 0.8667\n",
      "Epoch 183/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.5443 - val_accuracy: 0.8667\n",
      "Epoch 184/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.5450 - val_accuracy: 0.8700\n",
      "Epoch 185/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.5446 - val_accuracy: 0.8667\n",
      "Epoch 186/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.5461 - val_accuracy: 0.8667\n",
      "Epoch 187/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.5452 - val_accuracy: 0.8700\n",
      "Epoch 188/1000\n",
      "700/700 [==============================] - 0s 249us/sample - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.5461 - val_accuracy: 0.8667\n",
      "Epoch 189/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.5469 - val_accuracy: 0.8667\n",
      "Epoch 190/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.5479 - val_accuracy: 0.8667\n",
      "Epoch 191/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.5475 - val_accuracy: 0.8667\n",
      "Epoch 192/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.5486 - val_accuracy: 0.8667\n",
      "Epoch 193/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.5489 - val_accuracy: 0.8667\n",
      "Epoch 194/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.5495 - val_accuracy: 0.8667\n",
      "Epoch 195/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.5500 - val_accuracy: 0.8667\n",
      "Epoch 196/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.5503 - val_accuracy: 0.8667\n",
      "Epoch 197/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.5502 - val_accuracy: 0.8667\n",
      "Epoch 198/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.5507 - val_accuracy: 0.8667\n",
      "Epoch 199/1000\n",
      "700/700 [==============================] - 0s 245us/sample - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.5510 - val_accuracy: 0.8667\n",
      "Epoch 200/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.5519 - val_accuracy: 0.8667\n",
      "Epoch 201/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.5520 - val_accuracy: 0.8667\n",
      "Epoch 202/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.5530 - val_accuracy: 0.8667\n",
      "Epoch 203/1000\n",
      "700/700 [==============================] - 0s 256us/sample - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.5530 - val_accuracy: 0.8667\n",
      "Epoch 204/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.5538 - val_accuracy: 0.8667\n",
      "Epoch 205/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.5541 - val_accuracy: 0.8667\n",
      "Epoch 206/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.5545 - val_accuracy: 0.8667\n",
      "Epoch 207/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.5543 - val_accuracy: 0.8667\n",
      "Epoch 208/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.5549 - val_accuracy: 0.8667\n",
      "Epoch 209/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.5555 - val_accuracy: 0.8667\n",
      "Epoch 210/1000\n",
      "700/700 [==============================] - 0s 245us/sample - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.5561 - val_accuracy: 0.8667\n",
      "Epoch 211/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.5551 - val_accuracy: 0.8667\n",
      "Epoch 212/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.5559 - val_accuracy: 0.8667\n",
      "Epoch 213/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.5565 - val_accuracy: 0.8667\n",
      "Epoch 214/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.5568 - val_accuracy: 0.8667\n",
      "Epoch 215/1000\n",
      "700/700 [==============================] - 0s 245us/sample - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.5578 - val_accuracy: 0.8667\n",
      "Epoch 216/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.5575 - val_accuracy: 0.8667\n",
      "Epoch 217/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.5588 - val_accuracy: 0.8667\n",
      "Epoch 218/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.5590 - val_accuracy: 0.8667\n",
      "Epoch 219/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.5592 - val_accuracy: 0.8667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 220/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.5595 - val_accuracy: 0.8667\n",
      "Epoch 221/1000\n",
      "700/700 [==============================] - 0s 245us/sample - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.5598 - val_accuracy: 0.8667\n",
      "Epoch 222/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.5602 - val_accuracy: 0.8667\n",
      "Epoch 223/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.5608 - val_accuracy: 0.8667\n",
      "Epoch 224/1000\n",
      "700/700 [==============================] - 0s 246us/sample - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.5615 - val_accuracy: 0.8667\n",
      "Epoch 225/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.5619 - val_accuracy: 0.8667\n",
      "Epoch 226/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.5617 - val_accuracy: 0.8667\n",
      "Epoch 227/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.5626 - val_accuracy: 0.8667\n",
      "Epoch 228/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.5626 - val_accuracy: 0.8667\n",
      "Epoch 229/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.5627 - val_accuracy: 0.8667\n",
      "Epoch 230/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.5631 - val_accuracy: 0.8667\n",
      "Epoch 231/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.5634 - val_accuracy: 0.8667\n",
      "Epoch 232/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.5638 - val_accuracy: 0.8667\n",
      "Epoch 233/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.5648 - val_accuracy: 0.8667\n",
      "Epoch 234/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.5648 - val_accuracy: 0.8667\n",
      "Epoch 235/1000\n",
      "700/700 [==============================] - 0s 235us/sample - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.5653 - val_accuracy: 0.8667\n",
      "Epoch 236/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.5653 - val_accuracy: 0.8667\n",
      "Epoch 237/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.5658 - val_accuracy: 0.8667\n",
      "Epoch 238/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.5663 - val_accuracy: 0.8667\n",
      "Epoch 239/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.5665 - val_accuracy: 0.8667\n",
      "Epoch 240/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.5668 - val_accuracy: 0.8667\n",
      "Epoch 241/1000\n",
      "700/700 [==============================] - 0s 245us/sample - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.5669 - val_accuracy: 0.8667\n",
      "Epoch 242/1000\n",
      "700/700 [==============================] - 0s 245us/sample - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.5676 - val_accuracy: 0.8667\n",
      "Epoch 243/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.5675 - val_accuracy: 0.8667\n",
      "Epoch 244/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.5677 - val_accuracy: 0.8667\n",
      "Epoch 245/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.5682 - val_accuracy: 0.8667\n",
      "Epoch 246/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.5682 - val_accuracy: 0.8667\n",
      "Epoch 247/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.5689 - val_accuracy: 0.8667\n",
      "Epoch 248/1000\n",
      "700/700 [==============================] - 0s 245us/sample - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.5695 - val_accuracy: 0.8667\n",
      "Epoch 249/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.5703 - val_accuracy: 0.8667\n",
      "Epoch 250/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.5704 - val_accuracy: 0.8667\n",
      "Epoch 251/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.5706 - val_accuracy: 0.8667\n",
      "Epoch 252/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.5707 - val_accuracy: 0.8667\n",
      "Epoch 253/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.5714 - val_accuracy: 0.8667\n",
      "Epoch 254/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.5715 - val_accuracy: 0.8667\n",
      "Epoch 255/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.5714 - val_accuracy: 0.8667\n",
      "Epoch 256/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.5720 - val_accuracy: 0.8667\n",
      "Epoch 257/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.5724 - val_accuracy: 0.8667\n",
      "Epoch 258/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.5727 - val_accuracy: 0.8667\n",
      "Epoch 259/1000\n",
      "700/700 [==============================] - 0s 235us/sample - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.5725 - val_accuracy: 0.8667\n",
      "Epoch 260/1000\n",
      "700/700 [==============================] - 0s 249us/sample - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.5733 - val_accuracy: 0.8667\n",
      "Epoch 261/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.5734 - val_accuracy: 0.8667\n",
      "Epoch 262/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.5735 - val_accuracy: 0.8667\n",
      "Epoch 263/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.5739 - val_accuracy: 0.8667\n",
      "Epoch 264/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.5739 - val_accuracy: 0.8667\n",
      "Epoch 265/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.5745 - val_accuracy: 0.8667\n",
      "Epoch 266/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.5748 - val_accuracy: 0.8667\n",
      "Epoch 267/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.5753 - val_accuracy: 0.8667\n",
      "Epoch 268/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.5757 - val_accuracy: 0.8667\n",
      "Epoch 269/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.5758 - val_accuracy: 0.8667\n",
      "Epoch 270/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.5763 - val_accuracy: 0.8667\n",
      "Epoch 271/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.5767 - val_accuracy: 0.8667\n",
      "Epoch 272/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.5771 - val_accuracy: 0.8667\n",
      "Epoch 273/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.5771 - val_accuracy: 0.8667\n",
      "Epoch 274/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.5771 - val_accuracy: 0.8667\n",
      "Epoch 275/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.5777 - val_accuracy: 0.8667\n",
      "Epoch 276/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.5778 - val_accuracy: 0.8667\n",
      "Epoch 277/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.5782 - val_accuracy: 0.8667\n",
      "Epoch 278/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.5781 - val_accuracy: 0.8667\n",
      "Epoch 279/1000\n",
      "700/700 [==============================] - 0s 235us/sample - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.5790 - val_accuracy: 0.8667\n",
      "Epoch 280/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.5791 - val_accuracy: 0.8667\n",
      "Epoch 281/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.5795 - val_accuracy: 0.8667\n",
      "Epoch 282/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.5800 - val_accuracy: 0.8667\n",
      "Epoch 283/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.5797 - val_accuracy: 0.8667\n",
      "Epoch 284/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.5803 - val_accuracy: 0.8667\n",
      "Epoch 285/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.5807 - val_accuracy: 0.8667\n",
      "Epoch 286/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.5812 - val_accuracy: 0.8667\n",
      "Epoch 287/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.5812 - val_accuracy: 0.8667\n",
      "Epoch 288/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.5814 - val_accuracy: 0.8667\n",
      "Epoch 289/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.5819 - val_accuracy: 0.8667\n",
      "Epoch 290/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.5822 - val_accuracy: 0.8667\n",
      "Epoch 291/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.5826 - val_accuracy: 0.8667\n",
      "Epoch 292/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.5829 - val_accuracy: 0.8667\n",
      "Epoch 293/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.5830 - val_accuracy: 0.8667\n",
      "Epoch 294/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.5830 - val_accuracy: 0.8667\n",
      "Epoch 295/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.5834 - val_accuracy: 0.8667\n",
      "Epoch 296/1000\n",
      "700/700 [==============================] - 0s 247us/sample - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.5838 - val_accuracy: 0.8667\n",
      "Epoch 297/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.5844 - val_accuracy: 0.8667\n",
      "Epoch 298/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.5848 - val_accuracy: 0.8667\n",
      "Epoch 299/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.5849 - val_accuracy: 0.8667\n",
      "Epoch 300/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.5850 - val_accuracy: 0.8667\n",
      "Epoch 301/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.5852 - val_accuracy: 0.8667\n",
      "Epoch 302/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.5857 - val_accuracy: 0.8667\n",
      "Epoch 303/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.5859 - val_accuracy: 0.8667\n",
      "Epoch 304/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.5861 - val_accuracy: 0.8667\n",
      "Epoch 305/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.5864 - val_accuracy: 0.8667\n",
      "Epoch 306/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.5870 - val_accuracy: 0.8667\n",
      "Epoch 307/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.5871 - val_accuracy: 0.8667\n",
      "Epoch 308/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.5875 - val_accuracy: 0.8667\n",
      "Epoch 309/1000\n",
      "700/700 [==============================] - 0s 246us/sample - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.5876 - val_accuracy: 0.8667\n",
      "Epoch 310/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.5877 - val_accuracy: 0.8667\n",
      "Epoch 311/1000\n",
      "700/700 [==============================] - 0s 254us/sample - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.5882 - val_accuracy: 0.8667\n",
      "Epoch 312/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.5885 - val_accuracy: 0.8667\n",
      "Epoch 313/1000\n",
      "700/700 [==============================] - 0s 251us/sample - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.5886 - val_accuracy: 0.8667\n",
      "Epoch 314/1000\n",
      "700/700 [==============================] - 0s 234us/sample - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.5888 - val_accuracy: 0.8667\n",
      "Epoch 315/1000\n",
      "700/700 [==============================] - 0s 248us/sample - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.5894 - val_accuracy: 0.8667\n",
      "Epoch 316/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.5892 - val_accuracy: 0.8667\n",
      "Epoch 317/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.5894 - val_accuracy: 0.8667\n",
      "Epoch 318/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.5899 - val_accuracy: 0.8667\n",
      "Epoch 319/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.5901 - val_accuracy: 0.8667\n",
      "Epoch 320/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.5905 - val_accuracy: 0.8667\n",
      "Epoch 321/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.5905 - val_accuracy: 0.8667\n",
      "Epoch 322/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.5907 - val_accuracy: 0.8667\n",
      "Epoch 323/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.5913 - val_accuracy: 0.8667\n",
      "Epoch 324/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.5917 - val_accuracy: 0.8667\n",
      "Epoch 325/1000\n",
      "700/700 [==============================] - 0s 246us/sample - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.5915 - val_accuracy: 0.8667\n",
      "Epoch 326/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.5917 - val_accuracy: 0.8667\n",
      "Epoch 327/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.5921 - val_accuracy: 0.8667\n",
      "Epoch 328/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.5925 - val_accuracy: 0.8667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329/1000\n",
      "700/700 [==============================] - 0s 246us/sample - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.5931 - val_accuracy: 0.8667\n",
      "Epoch 330/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.5929 - val_accuracy: 0.8667\n",
      "Epoch 331/1000\n",
      "700/700 [==============================] - 0s 249us/sample - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.5935 - val_accuracy: 0.8667\n",
      "Epoch 332/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.5938 - val_accuracy: 0.8667\n",
      "Epoch 333/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.5936 - val_accuracy: 0.8667\n",
      "Epoch 334/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.5940 - val_accuracy: 0.8667\n",
      "Epoch 335/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.5943 - val_accuracy: 0.8667\n",
      "Epoch 336/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.5945 - val_accuracy: 0.8667\n",
      "Epoch 337/1000\n",
      "700/700 [==============================] - 0s 246us/sample - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.5947 - val_accuracy: 0.8667\n",
      "Epoch 338/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.5949 - val_accuracy: 0.8667\n",
      "Epoch 339/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.5952 - val_accuracy: 0.8667\n",
      "Epoch 340/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.5956 - val_accuracy: 0.8667\n",
      "Epoch 341/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.5955 - val_accuracy: 0.8667\n",
      "Epoch 342/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.5958 - val_accuracy: 0.8667\n",
      "Epoch 343/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.5960 - val_accuracy: 0.8667\n",
      "Epoch 344/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.5963 - val_accuracy: 0.8667\n",
      "Epoch 345/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.5965 - val_accuracy: 0.8667\n",
      "Epoch 346/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.5966 - val_accuracy: 0.8667\n",
      "Epoch 347/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.5966 - val_accuracy: 0.8667\n",
      "Epoch 348/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.5969 - val_accuracy: 0.8667\n",
      "Epoch 349/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.5973 - val_accuracy: 0.8667\n",
      "Epoch 350/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.5977 - val_accuracy: 0.8667\n",
      "Epoch 351/1000\n",
      "700/700 [==============================] - 0s 245us/sample - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.5981 - val_accuracy: 0.8667\n",
      "Epoch 352/1000\n",
      "700/700 [==============================] - 0s 247us/sample - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.5984 - val_accuracy: 0.8667\n",
      "Epoch 353/1000\n",
      "700/700 [==============================] - 0s 245us/sample - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.5986 - val_accuracy: 0.8667\n",
      "Epoch 354/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.5988 - val_accuracy: 0.8667\n",
      "Epoch 355/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.5991 - val_accuracy: 0.8667\n",
      "Epoch 356/1000\n",
      "700/700 [==============================] - 0s 251us/sample - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.5993 - val_accuracy: 0.8667\n",
      "Epoch 357/1000\n",
      "700/700 [==============================] - 0s 236us/sample - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.5994 - val_accuracy: 0.8667\n",
      "Epoch 358/1000\n",
      "700/700 [==============================] - 0s 245us/sample - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.5994 - val_accuracy: 0.8667\n",
      "Epoch 359/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.5996 - val_accuracy: 0.8667\n",
      "Epoch 360/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.6002 - val_accuracy: 0.8667\n",
      "Epoch 361/1000\n",
      "700/700 [==============================] - 0s 246us/sample - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.6004 - val_accuracy: 0.8667\n",
      "Epoch 362/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.6006 - val_accuracy: 0.8667\n",
      "Epoch 363/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.6010 - val_accuracy: 0.8667\n",
      "Epoch 364/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.6013 - val_accuracy: 0.8667\n",
      "Epoch 365/1000\n",
      "700/700 [==============================] - 0s 246us/sample - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.6012 - val_accuracy: 0.8667\n",
      "Epoch 366/1000\n",
      "700/700 [==============================] - 0s 276us/sample - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.6015 - val_accuracy: 0.8667\n",
      "Epoch 367/1000\n",
      "700/700 [==============================] - 0s 248us/sample - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.6017 - val_accuracy: 0.8667\n",
      "Epoch 368/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.6020 - val_accuracy: 0.8667\n",
      "Epoch 369/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.6023 - val_accuracy: 0.8667\n",
      "Epoch 370/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.6025 - val_accuracy: 0.8667\n",
      "Epoch 371/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.6027 - val_accuracy: 0.8667\n",
      "Epoch 372/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.6029 - val_accuracy: 0.8667\n",
      "Epoch 373/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.6032 - val_accuracy: 0.8667\n",
      "Epoch 374/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.6033 - val_accuracy: 0.8667\n",
      "Epoch 375/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.6033 - val_accuracy: 0.8667\n",
      "Epoch 376/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.6037 - val_accuracy: 0.8667\n",
      "Epoch 377/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.6039 - val_accuracy: 0.8667\n",
      "Epoch 378/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.6040 - val_accuracy: 0.8667\n",
      "Epoch 379/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.6043 - val_accuracy: 0.8667\n",
      "Epoch 380/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.6047 - val_accuracy: 0.8667\n",
      "Epoch 381/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.6050 - val_accuracy: 0.8667\n",
      "Epoch 382/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.6050 - val_accuracy: 0.8667\n",
      "Epoch 383/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.6052 - val_accuracy: 0.8667\n",
      "Epoch 384/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.6053 - val_accuracy: 0.8667\n",
      "Epoch 385/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.6056 - val_accuracy: 0.8667\n",
      "Epoch 386/1000\n",
      "700/700 [==============================] - 0s 251us/sample - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.6058 - val_accuracy: 0.8667\n",
      "Epoch 387/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.6060 - val_accuracy: 0.8667\n",
      "Epoch 388/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.6061 - val_accuracy: 0.8667\n",
      "Epoch 389/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.6063 - val_accuracy: 0.8667\n",
      "Epoch 390/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.6070 - val_accuracy: 0.8667\n",
      "Epoch 391/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.6072 - val_accuracy: 0.8667\n",
      "Epoch 392/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.6074 - val_accuracy: 0.8667\n",
      "Epoch 393/1000\n",
      "700/700 [==============================] - 0s 235us/sample - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.6075 - val_accuracy: 0.8667\n",
      "Epoch 394/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.6077 - val_accuracy: 0.8667\n",
      "Epoch 395/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.6079 - val_accuracy: 0.8633\n",
      "Epoch 396/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.6081 - val_accuracy: 0.8667\n",
      "Epoch 397/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.6084 - val_accuracy: 0.8667\n",
      "Epoch 398/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.6085 - val_accuracy: 0.8667\n",
      "Epoch 399/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.6088 - val_accuracy: 0.8667\n",
      "Epoch 400/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.6090 - val_accuracy: 0.8667\n",
      "Epoch 401/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.6093 - val_accuracy: 0.8667\n",
      "Epoch 402/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.6094 - val_accuracy: 0.8667\n",
      "Epoch 403/1000\n",
      "700/700 [==============================] - 0s 248us/sample - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.6098 - val_accuracy: 0.8667\n",
      "Epoch 404/1000\n",
      "700/700 [==============================] - 0s 235us/sample - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.6098 - val_accuracy: 0.8667\n",
      "Epoch 405/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.6100 - val_accuracy: 0.8667\n",
      "Epoch 406/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.6103 - val_accuracy: 0.8667\n",
      "Epoch 407/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.6105 - val_accuracy: 0.8667\n",
      "Epoch 408/1000\n",
      "700/700 [==============================] - 0s 245us/sample - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.6107 - val_accuracy: 0.8667\n",
      "Epoch 409/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.6109 - val_accuracy: 0.8667\n",
      "Epoch 410/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.6109 - val_accuracy: 0.8667\n",
      "Epoch 411/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.6113 - val_accuracy: 0.8667\n",
      "Epoch 412/1000\n",
      "700/700 [==============================] - 0s 245us/sample - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.6115 - val_accuracy: 0.8667\n",
      "Epoch 413/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.6116 - val_accuracy: 0.8667\n",
      "Epoch 414/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.6119 - val_accuracy: 0.8667\n",
      "Epoch 415/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.6122 - val_accuracy: 0.8667\n",
      "Epoch 416/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.6125 - val_accuracy: 0.8667\n",
      "Epoch 417/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.6124 - val_accuracy: 0.8667\n",
      "Epoch 418/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.6127 - val_accuracy: 0.8667\n",
      "Epoch 419/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.6129 - val_accuracy: 0.8667\n",
      "Epoch 420/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.6128 - val_accuracy: 0.8633\n",
      "Epoch 421/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.6131 - val_accuracy: 0.8667\n",
      "Epoch 422/1000\n",
      "700/700 [==============================] - 0s 235us/sample - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.6133 - val_accuracy: 0.8667\n",
      "Epoch 423/1000\n",
      "700/700 [==============================] - 0s 235us/sample - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.6135 - val_accuracy: 0.8667\n",
      "Epoch 424/1000\n",
      "700/700 [==============================] - 0s 245us/sample - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.6136 - val_accuracy: 0.8667\n",
      "Epoch 425/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.6140 - val_accuracy: 0.8667\n",
      "Epoch 426/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.6142 - val_accuracy: 0.8667\n",
      "Epoch 427/1000\n",
      "700/700 [==============================] - 0s 269us/sample - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.6144 - val_accuracy: 0.8667\n",
      "Epoch 428/1000\n",
      "700/700 [==============================] - 0s 248us/sample - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.6147 - val_accuracy: 0.8667\n",
      "Epoch 429/1000\n",
      "700/700 [==============================] - 0s 249us/sample - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.6149 - val_accuracy: 0.8667\n",
      "Epoch 430/1000\n",
      "700/700 [==============================] - 0s 249us/sample - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.6149 - val_accuracy: 0.8667\n",
      "Epoch 431/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.6151 - val_accuracy: 0.8667\n",
      "Epoch 432/1000\n",
      "700/700 [==============================] - 0s 246us/sample - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.6155 - val_accuracy: 0.8667\n",
      "Epoch 433/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.6156 - val_accuracy: 0.8633\n",
      "Epoch 434/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.6158 - val_accuracy: 0.8633\n",
      "Epoch 435/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.6159 - val_accuracy: 0.8633\n",
      "Epoch 436/1000\n",
      "700/700 [==============================] - 0s 248us/sample - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.6161 - val_accuracy: 0.8667\n",
      "Epoch 437/1000\n",
      "700/700 [==============================] - 0s 245us/sample - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.6162 - val_accuracy: 0.8633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 438/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.6163 - val_accuracy: 0.8633\n",
      "Epoch 439/1000\n",
      "700/700 [==============================] - 0s 259us/sample - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.6166 - val_accuracy: 0.8633\n",
      "Epoch 440/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.6167 - val_accuracy: 0.8633\n",
      "Epoch 441/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.6170 - val_accuracy: 0.8633\n",
      "Epoch 442/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.6172 - val_accuracy: 0.8633\n",
      "Epoch 443/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.6174 - val_accuracy: 0.8633\n",
      "Epoch 444/1000\n",
      "700/700 [==============================] - 0s 246us/sample - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.6178 - val_accuracy: 0.8633\n",
      "Epoch 445/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.6177 - val_accuracy: 0.8633\n",
      "Epoch 446/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.6179 - val_accuracy: 0.8633\n",
      "Epoch 447/1000\n",
      "700/700 [==============================] - 0s 245us/sample - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.6182 - val_accuracy: 0.8633\n",
      "Epoch 448/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.6184 - val_accuracy: 0.8633\n",
      "Epoch 449/1000\n",
      "700/700 [==============================] - 0s 245us/sample - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.6184 - val_accuracy: 0.8633\n",
      "Epoch 450/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.6186 - val_accuracy: 0.8633\n",
      "Epoch 451/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.6189 - val_accuracy: 0.8633\n",
      "Epoch 452/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.6193 - val_accuracy: 0.8633\n",
      "Epoch 453/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.6194 - val_accuracy: 0.8633\n",
      "Epoch 454/1000\n",
      "700/700 [==============================] - 0s 245us/sample - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.6196 - val_accuracy: 0.8633\n",
      "Epoch 455/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.6198 - val_accuracy: 0.8633\n",
      "Epoch 456/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.6201 - val_accuracy: 0.8633\n",
      "Epoch 457/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.6201 - val_accuracy: 0.8633\n",
      "Epoch 458/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.6203 - val_accuracy: 0.8633\n",
      "Epoch 459/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.6207 - val_accuracy: 0.8633\n",
      "Epoch 460/1000\n",
      "700/700 [==============================] - 0s 245us/sample - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.6205 - val_accuracy: 0.8633\n",
      "Epoch 461/1000\n",
      "700/700 [==============================] - 0s 254us/sample - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.6208 - val_accuracy: 0.8633\n",
      "Epoch 462/1000\n",
      "700/700 [==============================] - 0s 248us/sample - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.6210 - val_accuracy: 0.8633\n",
      "Epoch 463/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.6212 - val_accuracy: 0.8633\n",
      "Epoch 464/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.6214 - val_accuracy: 0.8633\n",
      "Epoch 465/1000\n",
      "700/700 [==============================] - 0s 245us/sample - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.6214 - val_accuracy: 0.8633\n",
      "Epoch 466/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.6216 - val_accuracy: 0.8633\n",
      "Epoch 467/1000\n",
      "700/700 [==============================] - 0s 249us/sample - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.6218 - val_accuracy: 0.8633\n",
      "Epoch 468/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.6220 - val_accuracy: 0.8633\n",
      "Epoch 469/1000\n",
      "700/700 [==============================] - 0s 245us/sample - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.6221 - val_accuracy: 0.8633\n",
      "Epoch 470/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.6223 - val_accuracy: 0.8633\n",
      "Epoch 471/1000\n",
      "700/700 [==============================] - 0s 245us/sample - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.6224 - val_accuracy: 0.8633\n",
      "Epoch 472/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.6226 - val_accuracy: 0.8633\n",
      "Epoch 473/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.6229 - val_accuracy: 0.8633\n",
      "Epoch 474/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.6231 - val_accuracy: 0.8633\n",
      "Epoch 475/1000\n",
      "700/700 [==============================] - 0s 252us/sample - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.6232 - val_accuracy: 0.8633\n",
      "Epoch 476/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.6233 - val_accuracy: 0.8633\n",
      "Epoch 477/1000\n",
      "700/700 [==============================] - 0s 245us/sample - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.6234 - val_accuracy: 0.8633\n",
      "Epoch 478/1000\n",
      "700/700 [==============================] - 0s 245us/sample - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.6236 - val_accuracy: 0.8633\n",
      "Epoch 479/1000\n",
      "700/700 [==============================] - 0s 249us/sample - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.6239 - val_accuracy: 0.8633\n",
      "Epoch 480/1000\n",
      "700/700 [==============================] - 0s 245us/sample - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.6239 - val_accuracy: 0.8633\n",
      "Epoch 481/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.6242 - val_accuracy: 0.8633\n",
      "Epoch 482/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.6243 - val_accuracy: 0.8633\n",
      "Epoch 483/1000\n",
      "700/700 [==============================] - 0s 252us/sample - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.6245 - val_accuracy: 0.8633\n",
      "Epoch 484/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.6245 - val_accuracy: 0.8633\n",
      "Epoch 485/1000\n",
      "700/700 [==============================] - 0s 246us/sample - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.6248 - val_accuracy: 0.8633\n",
      "Epoch 486/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.6250 - val_accuracy: 0.8633\n",
      "Epoch 487/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.6253 - val_accuracy: 0.8633\n",
      "Epoch 488/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.6254 - val_accuracy: 0.8633\n",
      "Epoch 489/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.6257 - val_accuracy: 0.8633\n",
      "Epoch 490/1000\n",
      "700/700 [==============================] - 0s 245us/sample - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.6259 - val_accuracy: 0.8633\n",
      "Epoch 491/1000\n",
      "700/700 [==============================] - 0s 249us/sample - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.6260 - val_accuracy: 0.8633\n",
      "Epoch 492/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.6263 - val_accuracy: 0.8633\n",
      "Epoch 493/1000\n",
      "700/700 [==============================] - 0s 245us/sample - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.6264 - val_accuracy: 0.8633\n",
      "Epoch 494/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.6266 - val_accuracy: 0.8633\n",
      "Epoch 495/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.6267 - val_accuracy: 0.8633\n",
      "Epoch 496/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.6269 - val_accuracy: 0.8633\n",
      "Epoch 497/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.6270 - val_accuracy: 0.8633\n",
      "Epoch 498/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.6272 - val_accuracy: 0.8633\n",
      "Epoch 499/1000\n",
      "700/700 [==============================] - 0s 258us/sample - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.6274 - val_accuracy: 0.8633\n",
      "Epoch 500/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.6276 - val_accuracy: 0.8633\n",
      "Epoch 501/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.6278 - val_accuracy: 0.8633\n",
      "Epoch 502/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.6279 - val_accuracy: 0.8633\n",
      "Epoch 503/1000\n",
      "700/700 [==============================] - 0s 248us/sample - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.6280 - val_accuracy: 0.8633\n",
      "Epoch 504/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.6282 - val_accuracy: 0.8633\n",
      "Epoch 505/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.6283 - val_accuracy: 0.8633\n",
      "Epoch 506/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.6285 - val_accuracy: 0.8633\n",
      "Epoch 507/1000\n",
      "700/700 [==============================] - 0s 245us/sample - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.6286 - val_accuracy: 0.8633\n",
      "Epoch 508/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.6289 - val_accuracy: 0.8633\n",
      "Epoch 509/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.6290 - val_accuracy: 0.8633\n",
      "Epoch 510/1000\n",
      "700/700 [==============================] - 0s 262us/sample - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.6292 - val_accuracy: 0.8633\n",
      "Epoch 511/1000\n",
      "700/700 [==============================] - 0s 261us/sample - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.6293 - val_accuracy: 0.8633\n",
      "Epoch 512/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.6295 - val_accuracy: 0.8633\n",
      "Epoch 513/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.6296 - val_accuracy: 0.8633\n",
      "Epoch 514/1000\n",
      "700/700 [==============================] - 0s 271us/sample - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.6299 - val_accuracy: 0.8633\n",
      "Epoch 515/1000\n",
      "700/700 [==============================] - 0s 261us/sample - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.6301 - val_accuracy: 0.8633\n",
      "Epoch 516/1000\n",
      "700/700 [==============================] - 0s 279us/sample - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.6302 - val_accuracy: 0.8633\n",
      "Epoch 517/1000\n",
      "700/700 [==============================] - 0s 262us/sample - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.6303 - val_accuracy: 0.8633\n",
      "Epoch 518/1000\n",
      "700/700 [==============================] - 0s 248us/sample - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.6304 - val_accuracy: 0.8633\n",
      "Epoch 519/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.6306 - val_accuracy: 0.8633\n",
      "Epoch 520/1000\n",
      "700/700 [==============================] - 0s 245us/sample - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.6308 - val_accuracy: 0.8633\n",
      "Epoch 521/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.6309 - val_accuracy: 0.8633\n",
      "Epoch 522/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.6310 - val_accuracy: 0.8633\n",
      "Epoch 523/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.6313 - val_accuracy: 0.8633\n",
      "Epoch 524/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.6316 - val_accuracy: 0.8633\n",
      "Epoch 525/1000\n",
      "700/700 [==============================] - 0s 248us/sample - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.6317 - val_accuracy: 0.8633\n",
      "Epoch 526/1000\n",
      "700/700 [==============================] - 0s 251us/sample - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.6318 - val_accuracy: 0.8633\n",
      "Epoch 527/1000\n",
      "700/700 [==============================] - 0s 245us/sample - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.6318 - val_accuracy: 0.8633\n",
      "Epoch 528/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.6320 - val_accuracy: 0.8633\n",
      "Epoch 529/1000\n",
      "700/700 [==============================] - 0s 245us/sample - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.6322 - val_accuracy: 0.8633\n",
      "Epoch 530/1000\n",
      "700/700 [==============================] - 0s 245us/sample - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.6324 - val_accuracy: 0.8633\n",
      "Epoch 531/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.6326 - val_accuracy: 0.8633\n",
      "Epoch 532/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.6328 - val_accuracy: 0.8633\n",
      "Epoch 533/1000\n",
      "700/700 [==============================] - 0s 254us/sample - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.6330 - val_accuracy: 0.8633\n",
      "Epoch 534/1000\n",
      "700/700 [==============================] - 0s 250us/sample - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.6329 - val_accuracy: 0.8633\n",
      "Epoch 535/1000\n",
      "700/700 [==============================] - 0s 251us/sample - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.6331 - val_accuracy: 0.8633\n",
      "Epoch 536/1000\n",
      "700/700 [==============================] - 0s 254us/sample - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.6332 - val_accuracy: 0.8633\n",
      "Epoch 537/1000\n",
      "700/700 [==============================] - 0s 258us/sample - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.6335 - val_accuracy: 0.8633\n",
      "Epoch 538/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.6336 - val_accuracy: 0.8633\n",
      "Epoch 539/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.6338 - val_accuracy: 0.8633\n",
      "Epoch 540/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.6339 - val_accuracy: 0.8633\n",
      "Epoch 541/1000\n",
      "700/700 [==============================] - 0s 249us/sample - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.6341 - val_accuracy: 0.8633\n",
      "Epoch 542/1000\n",
      "700/700 [==============================] - 0s 245us/sample - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.6343 - val_accuracy: 0.8633\n",
      "Epoch 543/1000\n",
      "700/700 [==============================] - 0s 248us/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.6345 - val_accuracy: 0.8633\n",
      "Epoch 544/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.6347 - val_accuracy: 0.8633\n",
      "Epoch 545/1000\n",
      "700/700 [==============================] - 0s 255us/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.6347 - val_accuracy: 0.8633\n",
      "Epoch 546/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.6348 - val_accuracy: 0.8633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 547/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.6350 - val_accuracy: 0.8633\n",
      "Epoch 548/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.6350 - val_accuracy: 0.8633\n",
      "Epoch 549/1000\n",
      "700/700 [==============================] - 0s 246us/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.6352 - val_accuracy: 0.8633\n",
      "Epoch 550/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.6354 - val_accuracy: 0.8633\n",
      "Epoch 551/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.6357 - val_accuracy: 0.8633\n",
      "Epoch 552/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.6358 - val_accuracy: 0.8633\n",
      "Epoch 553/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.6360 - val_accuracy: 0.8633\n",
      "Epoch 554/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.6362 - val_accuracy: 0.8633\n",
      "Epoch 555/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.6363 - val_accuracy: 0.8633\n",
      "Epoch 556/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.6365 - val_accuracy: 0.8633\n",
      "Epoch 557/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.6366 - val_accuracy: 0.8633\n",
      "Epoch 558/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.6368 - val_accuracy: 0.8633\n",
      "Epoch 559/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.6369 - val_accuracy: 0.8633\n",
      "Epoch 560/1000\n",
      "700/700 [==============================] - 0s 259us/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.6370 - val_accuracy: 0.8633\n",
      "Epoch 561/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.6371 - val_accuracy: 0.8633\n",
      "Epoch 562/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.6372 - val_accuracy: 0.8633\n",
      "Epoch 563/1000\n",
      "700/700 [==============================] - 0s 246us/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.6374 - val_accuracy: 0.8633\n",
      "Epoch 564/1000\n",
      "700/700 [==============================] - 0s 245us/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.6376 - val_accuracy: 0.8633\n",
      "Epoch 565/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.6377 - val_accuracy: 0.8633\n",
      "Epoch 566/1000\n",
      "700/700 [==============================] - 0s 252us/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.6380 - val_accuracy: 0.8633\n",
      "Epoch 567/1000\n",
      "700/700 [==============================] - 0s 252us/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.6382 - val_accuracy: 0.8633\n",
      "Epoch 568/1000\n",
      "700/700 [==============================] - 0s 252us/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.6383 - val_accuracy: 0.8633\n",
      "Epoch 569/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.6383 - val_accuracy: 0.8633\n",
      "Epoch 570/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.6383 - val_accuracy: 0.8633\n",
      "Epoch 571/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.6386 - val_accuracy: 0.8633\n",
      "Epoch 572/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.6388 - val_accuracy: 0.8633\n",
      "Epoch 573/1000\n",
      "700/700 [==============================] - 0s 248us/sample - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.6390 - val_accuracy: 0.8633\n",
      "Epoch 574/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.6390 - val_accuracy: 0.8633\n",
      "Epoch 575/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.6392 - val_accuracy: 0.8633\n",
      "Epoch 576/1000\n",
      "700/700 [==============================] - 0s 245us/sample - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.6393 - val_accuracy: 0.8633\n",
      "Epoch 577/1000\n",
      "700/700 [==============================] - 0s 245us/sample - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.6395 - val_accuracy: 0.8633\n",
      "Epoch 578/1000\n",
      "700/700 [==============================] - 0s 246us/sample - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.6397 - val_accuracy: 0.8633\n",
      "Epoch 579/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.6396 - val_accuracy: 0.8633\n",
      "Epoch 580/1000\n",
      "700/700 [==============================] - 0s 252us/sample - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.6398 - val_accuracy: 0.8633\n",
      "Epoch 581/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.6400 - val_accuracy: 0.8633\n",
      "Epoch 582/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.6402 - val_accuracy: 0.8633\n",
      "Epoch 583/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.6403 - val_accuracy: 0.8633\n",
      "Epoch 584/1000\n",
      "700/700 [==============================] - 0s 246us/sample - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.6405 - val_accuracy: 0.8633\n",
      "Epoch 585/1000\n",
      "700/700 [==============================] - 0s 245us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.6407 - val_accuracy: 0.8633\n",
      "Epoch 586/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.6408 - val_accuracy: 0.8633\n",
      "Epoch 587/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.6409 - val_accuracy: 0.8633\n",
      "Epoch 588/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.6412 - val_accuracy: 0.8633\n",
      "Epoch 589/1000\n",
      "700/700 [==============================] - 0s 245us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.6413 - val_accuracy: 0.8633\n",
      "Epoch 590/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.6414 - val_accuracy: 0.8633\n",
      "Epoch 591/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.6416 - val_accuracy: 0.8633\n",
      "Epoch 592/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.6418 - val_accuracy: 0.8633\n",
      "Epoch 593/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.6419 - val_accuracy: 0.8633\n",
      "Epoch 594/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.6420 - val_accuracy: 0.8633\n",
      "Epoch 595/1000\n",
      "700/700 [==============================] - 0s 249us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.6422 - val_accuracy: 0.8633\n",
      "Epoch 596/1000\n",
      "700/700 [==============================] - 0s 249us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.6423 - val_accuracy: 0.8633\n",
      "Epoch 597/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.6424 - val_accuracy: 0.8633\n",
      "Epoch 598/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.6426 - val_accuracy: 0.8633\n",
      "Epoch 599/1000\n",
      "700/700 [==============================] - 0s 245us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.6427 - val_accuracy: 0.8633\n",
      "Epoch 600/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.6428 - val_accuracy: 0.8633\n",
      "Epoch 601/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 246us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.6429 - val_accuracy: 0.8633\n",
      "Epoch 602/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.6431 - val_accuracy: 0.8633\n",
      "Epoch 603/1000\n",
      "700/700 [==============================] - 0s 234us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.6434 - val_accuracy: 0.8633\n",
      "Epoch 604/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.6434 - val_accuracy: 0.8633\n",
      "Epoch 605/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.6434 - val_accuracy: 0.8633\n",
      "Epoch 606/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.6436 - val_accuracy: 0.8633\n",
      "Epoch 607/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.6438 - val_accuracy: 0.8633\n",
      "Epoch 608/1000\n",
      "700/700 [==============================] - 0s 245us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.6439 - val_accuracy: 0.8633\n",
      "Epoch 609/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.6440 - val_accuracy: 0.8633\n",
      "Epoch 610/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.6442 - val_accuracy: 0.8633\n",
      "Epoch 611/1000\n",
      "700/700 [==============================] - 0s 245us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.6443 - val_accuracy: 0.8633\n",
      "Epoch 612/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.6445 - val_accuracy: 0.8633\n",
      "Epoch 613/1000\n",
      "700/700 [==============================] - 0s 245us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.6447 - val_accuracy: 0.8633\n",
      "Epoch 614/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.6448 - val_accuracy: 0.8633\n",
      "Epoch 615/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.6449 - val_accuracy: 0.8633\n",
      "Epoch 616/1000\n",
      "700/700 [==============================] - 0s 251us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.6450 - val_accuracy: 0.8633\n",
      "Epoch 617/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.6452 - val_accuracy: 0.8633\n",
      "Epoch 618/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.6454 - val_accuracy: 0.8633\n",
      "Epoch 619/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.6455 - val_accuracy: 0.8633\n",
      "Epoch 620/1000\n",
      "700/700 [==============================] - 0s 245us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.6456 - val_accuracy: 0.8633\n",
      "Epoch 621/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.6457 - val_accuracy: 0.8633\n",
      "Epoch 622/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.6458 - val_accuracy: 0.8633\n",
      "Epoch 623/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.6461 - val_accuracy: 0.8633\n",
      "Epoch 624/1000\n",
      "700/700 [==============================] - 0s 246us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.6462 - val_accuracy: 0.8633\n",
      "Epoch 625/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.6463 - val_accuracy: 0.8633\n",
      "Epoch 626/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.6465 - val_accuracy: 0.8633\n",
      "Epoch 627/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.6466 - val_accuracy: 0.8633\n",
      "Epoch 628/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.6467 - val_accuracy: 0.8633\n",
      "Epoch 629/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.6468 - val_accuracy: 0.8633\n",
      "Epoch 630/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.6470 - val_accuracy: 0.8633\n",
      "Epoch 631/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.6471 - val_accuracy: 0.8633\n",
      "Epoch 632/1000\n",
      "700/700 [==============================] - 0s 248us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.6472 - val_accuracy: 0.8633\n",
      "Epoch 633/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.6473 - val_accuracy: 0.8633\n",
      "Epoch 634/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.6474 - val_accuracy: 0.8633\n",
      "Epoch 635/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.6475 - val_accuracy: 0.8633\n",
      "Epoch 636/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.6476 - val_accuracy: 0.8633\n",
      "Epoch 637/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.6477 - val_accuracy: 0.8633\n",
      "Epoch 638/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.6479 - val_accuracy: 0.8633\n",
      "Epoch 639/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.6481 - val_accuracy: 0.8633\n",
      "Epoch 640/1000\n",
      "700/700 [==============================] - 0s 235us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.6482 - val_accuracy: 0.8633\n",
      "Epoch 641/1000\n",
      "700/700 [==============================] - 0s 235us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.6482 - val_accuracy: 0.8633\n",
      "Epoch 642/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.6484 - val_accuracy: 0.8633\n",
      "Epoch 643/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.6486 - val_accuracy: 0.8633\n",
      "Epoch 644/1000\n",
      "700/700 [==============================] - 0s 246us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.6487 - val_accuracy: 0.8633\n",
      "Epoch 645/1000\n",
      "700/700 [==============================] - 0s 235us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.6489 - val_accuracy: 0.8633\n",
      "Epoch 646/1000\n",
      "700/700 [==============================] - 0s 235us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.6491 - val_accuracy: 0.8633\n",
      "Epoch 647/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.6492 - val_accuracy: 0.8633\n",
      "Epoch 648/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.6493 - val_accuracy: 0.8633\n",
      "Epoch 649/1000\n",
      "700/700 [==============================] - 0s 235us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.6493 - val_accuracy: 0.8633\n",
      "Epoch 650/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.6495 - val_accuracy: 0.8633\n",
      "Epoch 651/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.6497 - val_accuracy: 0.8633\n",
      "Epoch 652/1000\n",
      "700/700 [==============================] - 0s 259us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.6498 - val_accuracy: 0.8633\n",
      "Epoch 653/1000\n",
      "700/700 [==============================] - 0s 256us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.6501 - val_accuracy: 0.8633\n",
      "Epoch 654/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.6503 - val_accuracy: 0.8633\n",
      "Epoch 655/1000\n",
      "700/700 [==============================] - 0s 246us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.6502 - val_accuracy: 0.8633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 656/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.6504 - val_accuracy: 0.8633\n",
      "Epoch 657/1000\n",
      "700/700 [==============================] - 0s 235us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.6505 - val_accuracy: 0.8633\n",
      "Epoch 658/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.6507 - val_accuracy: 0.8633\n",
      "Epoch 659/1000\n",
      "700/700 [==============================] - 0s 231us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.6508 - val_accuracy: 0.8633\n",
      "Epoch 660/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.6508 - val_accuracy: 0.8633\n",
      "Epoch 661/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.6511 - val_accuracy: 0.8633\n",
      "Epoch 662/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.6511 - val_accuracy: 0.8633\n",
      "Epoch 663/1000\n",
      "700/700 [==============================] - 0s 235us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.6513 - val_accuracy: 0.8633\n",
      "Epoch 664/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.6514 - val_accuracy: 0.8633\n",
      "Epoch 665/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.6515 - val_accuracy: 0.8633\n",
      "Epoch 666/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.6516 - val_accuracy: 0.8633\n",
      "Epoch 667/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.6517 - val_accuracy: 0.8633\n",
      "Epoch 668/1000\n",
      "700/700 [==============================] - 0s 245us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.6518 - val_accuracy: 0.8633\n",
      "Epoch 669/1000\n",
      "700/700 [==============================] - 0s 232us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.6519 - val_accuracy: 0.8633\n",
      "Epoch 670/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.6521 - val_accuracy: 0.8633\n",
      "Epoch 671/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.6521 - val_accuracy: 0.8633\n",
      "Epoch 672/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.6523 - val_accuracy: 0.8633\n",
      "Epoch 673/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.6524 - val_accuracy: 0.8633\n",
      "Epoch 674/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.6526 - val_accuracy: 0.8633\n",
      "Epoch 675/1000\n",
      "700/700 [==============================] - 0s 234us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.6528 - val_accuracy: 0.8633\n",
      "Epoch 676/1000\n",
      "700/700 [==============================] - 0s 235us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6528 - val_accuracy: 0.8633\n",
      "Epoch 677/1000\n",
      "700/700 [==============================] - 0s 235us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6529 - val_accuracy: 0.8633\n",
      "Epoch 678/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6530 - val_accuracy: 0.8633\n",
      "Epoch 679/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6532 - val_accuracy: 0.8633\n",
      "Epoch 680/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6534 - val_accuracy: 0.8633\n",
      "Epoch 681/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6534 - val_accuracy: 0.8633\n",
      "Epoch 682/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6537 - val_accuracy: 0.8633\n",
      "Epoch 683/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6538 - val_accuracy: 0.8633\n",
      "Epoch 684/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6539 - val_accuracy: 0.8633\n",
      "Epoch 685/1000\n",
      "700/700 [==============================] - 0s 235us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6540 - val_accuracy: 0.8633\n",
      "Epoch 686/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6540 - val_accuracy: 0.8633\n",
      "Epoch 687/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6543 - val_accuracy: 0.8633\n",
      "Epoch 688/1000\n",
      "700/700 [==============================] - 0s 251us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6544 - val_accuracy: 0.8633\n",
      "Epoch 689/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6546 - val_accuracy: 0.8633\n",
      "Epoch 690/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6546 - val_accuracy: 0.8633\n",
      "Epoch 691/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6546 - val_accuracy: 0.8633\n",
      "Epoch 692/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6548 - val_accuracy: 0.8633\n",
      "Epoch 693/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6549 - val_accuracy: 0.8633\n",
      "Epoch 694/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6551 - val_accuracy: 0.8633\n",
      "Epoch 695/1000\n",
      "700/700 [==============================] - 0s 234us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6552 - val_accuracy: 0.8633\n",
      "Epoch 696/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6552 - val_accuracy: 0.8633\n",
      "Epoch 697/1000\n",
      "700/700 [==============================] - 0s 235us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6554 - val_accuracy: 0.8633\n",
      "Epoch 698/1000\n",
      "700/700 [==============================] - 0s 235us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6555 - val_accuracy: 0.8633\n",
      "Epoch 699/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6557 - val_accuracy: 0.8633\n",
      "Epoch 700/1000\n",
      "700/700 [==============================] - 0s 235us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6559 - val_accuracy: 0.8633\n",
      "Epoch 701/1000\n",
      "700/700 [==============================] - 0s 235us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6559 - val_accuracy: 0.8633\n",
      "Epoch 702/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6560 - val_accuracy: 0.8633\n",
      "Epoch 703/1000\n",
      "700/700 [==============================] - 0s 246us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6561 - val_accuracy: 0.8633\n",
      "Epoch 704/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6563 - val_accuracy: 0.8633\n",
      "Epoch 705/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6564 - val_accuracy: 0.8633\n",
      "Epoch 706/1000\n",
      "700/700 [==============================] - 0s 251us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6565 - val_accuracy: 0.8633\n",
      "Epoch 707/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6567 - val_accuracy: 0.8633\n",
      "Epoch 708/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6568 - val_accuracy: 0.8633\n",
      "Epoch 709/1000\n",
      "700/700 [==============================] - 0s 235us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6569 - val_accuracy: 0.8633\n",
      "Epoch 710/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6570 - val_accuracy: 0.8633\n",
      "Epoch 711/1000\n",
      "700/700 [==============================] - 0s 235us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6572 - val_accuracy: 0.8633\n",
      "Epoch 712/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6573 - val_accuracy: 0.8633\n",
      "Epoch 713/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6573 - val_accuracy: 0.8633\n",
      "Epoch 714/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6574 - val_accuracy: 0.8633\n",
      "Epoch 715/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6575 - val_accuracy: 0.8633\n",
      "Epoch 716/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6577 - val_accuracy: 0.8633\n",
      "Epoch 717/1000\n",
      "700/700 [==============================] - 0s 235us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6578 - val_accuracy: 0.8633\n",
      "Epoch 718/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6579 - val_accuracy: 0.8633\n",
      "Epoch 719/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6580 - val_accuracy: 0.8633\n",
      "Epoch 720/1000\n",
      "700/700 [==============================] - 0s 286us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6582 - val_accuracy: 0.8633\n",
      "Epoch 721/1000\n",
      "700/700 [==============================] - 0s 231us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6582 - val_accuracy: 0.8633\n",
      "Epoch 722/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6584 - val_accuracy: 0.8633\n",
      "Epoch 723/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6585 - val_accuracy: 0.8633\n",
      "Epoch 724/1000\n",
      "700/700 [==============================] - 0s 246us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6586 - val_accuracy: 0.8633\n",
      "Epoch 725/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6587 - val_accuracy: 0.8633\n",
      "Epoch 726/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6588 - val_accuracy: 0.8633\n",
      "Epoch 727/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6590 - val_accuracy: 0.8633\n",
      "Epoch 728/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6591 - val_accuracy: 0.8633\n",
      "Epoch 729/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6591 - val_accuracy: 0.8633\n",
      "Epoch 730/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6593 - val_accuracy: 0.8633\n",
      "Epoch 731/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6594 - val_accuracy: 0.8633\n",
      "Epoch 732/1000\n",
      "700/700 [==============================] - 0s 235us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6595 - val_accuracy: 0.8633\n",
      "Epoch 733/1000\n",
      "700/700 [==============================] - 0s 235us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6597 - val_accuracy: 0.8633\n",
      "Epoch 734/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6598 - val_accuracy: 0.8633\n",
      "Epoch 735/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6599 - val_accuracy: 0.8633\n",
      "Epoch 736/1000\n",
      "700/700 [==============================] - 0s 235us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6600 - val_accuracy: 0.8633\n",
      "Epoch 737/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6601 - val_accuracy: 0.8633\n",
      "Epoch 738/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6602 - val_accuracy: 0.8633\n",
      "Epoch 739/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6603 - val_accuracy: 0.8633\n",
      "Epoch 740/1000\n",
      "700/700 [==============================] - 0s 245us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6605 - val_accuracy: 0.8633\n",
      "Epoch 741/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6606 - val_accuracy: 0.8633\n",
      "Epoch 742/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6607 - val_accuracy: 0.8633\n",
      "Epoch 743/1000\n",
      "700/700 [==============================] - 0s 252us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6608 - val_accuracy: 0.8633\n",
      "Epoch 744/1000\n",
      "700/700 [==============================] - 0s 232us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6608 - val_accuracy: 0.8633\n",
      "Epoch 745/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6609 - val_accuracy: 0.8633\n",
      "Epoch 746/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6611 - val_accuracy: 0.8633\n",
      "Epoch 747/1000\n",
      "700/700 [==============================] - 0s 235us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6612 - val_accuracy: 0.8633\n",
      "Epoch 748/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6613 - val_accuracy: 0.8633\n",
      "Epoch 749/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6614 - val_accuracy: 0.8633\n",
      "Epoch 750/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6615 - val_accuracy: 0.8633\n",
      "Epoch 751/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6616 - val_accuracy: 0.8633\n",
      "Epoch 752/1000\n",
      "700/700 [==============================] - 0s 245us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6617 - val_accuracy: 0.8633\n",
      "Epoch 753/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6619 - val_accuracy: 0.8633\n",
      "Epoch 754/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6619 - val_accuracy: 0.8633\n",
      "Epoch 755/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6621 - val_accuracy: 0.8633\n",
      "Epoch 756/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6623 - val_accuracy: 0.8633\n",
      "Epoch 757/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6623 - val_accuracy: 0.8633\n",
      "Epoch 758/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6624 - val_accuracy: 0.8633\n",
      "Epoch 759/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6626 - val_accuracy: 0.8633\n",
      "Epoch 760/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6627 - val_accuracy: 0.8633\n",
      "Epoch 761/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6628 - val_accuracy: 0.8633\n",
      "Epoch 762/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6629 - val_accuracy: 0.8633\n",
      "Epoch 763/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6630 - val_accuracy: 0.8633\n",
      "Epoch 764/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6632 - val_accuracy: 0.8633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 765/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6632 - val_accuracy: 0.8633\n",
      "Epoch 766/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6634 - val_accuracy: 0.8633\n",
      "Epoch 767/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6635 - val_accuracy: 0.8633\n",
      "Epoch 768/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6635 - val_accuracy: 0.8633\n",
      "Epoch 769/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6636 - val_accuracy: 0.8633\n",
      "Epoch 770/1000\n",
      "700/700 [==============================] - 0s 235us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6637 - val_accuracy: 0.8633\n",
      "Epoch 771/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6638 - val_accuracy: 0.8633\n",
      "Epoch 772/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6640 - val_accuracy: 0.8633\n",
      "Epoch 773/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6641 - val_accuracy: 0.8633\n",
      "Epoch 774/1000\n",
      "700/700 [==============================] - 0s 235us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6642 - val_accuracy: 0.8633\n",
      "Epoch 775/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6643 - val_accuracy: 0.8633\n",
      "Epoch 776/1000\n",
      "700/700 [==============================] - 0s 246us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6644 - val_accuracy: 0.8633\n",
      "Epoch 777/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6644 - val_accuracy: 0.8633\n",
      "Epoch 778/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6645 - val_accuracy: 0.8633\n",
      "Epoch 779/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6647 - val_accuracy: 0.8633\n",
      "Epoch 780/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6648 - val_accuracy: 0.8633\n",
      "Epoch 781/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6649 - val_accuracy: 0.8633\n",
      "Epoch 782/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6650 - val_accuracy: 0.8633\n",
      "Epoch 783/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6652 - val_accuracy: 0.8633\n",
      "Epoch 784/1000\n",
      "700/700 [==============================] - 0s 235us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6652 - val_accuracy: 0.8633\n",
      "Epoch 785/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6653 - val_accuracy: 0.8633\n",
      "Epoch 786/1000\n",
      "700/700 [==============================] - 0s 235us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6655 - val_accuracy: 0.8633\n",
      "Epoch 787/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6655 - val_accuracy: 0.8633\n",
      "Epoch 788/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6656 - val_accuracy: 0.8633\n",
      "Epoch 789/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6657 - val_accuracy: 0.8633\n",
      "Epoch 790/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6659 - val_accuracy: 0.8633\n",
      "Epoch 791/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6660 - val_accuracy: 0.8633\n",
      "Epoch 792/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6661 - val_accuracy: 0.8633\n",
      "Epoch 793/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6662 - val_accuracy: 0.8633\n",
      "Epoch 794/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6663 - val_accuracy: 0.8633\n",
      "Epoch 795/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6664 - val_accuracy: 0.8633\n",
      "Epoch 796/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6665 - val_accuracy: 0.8633\n",
      "Epoch 797/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6666 - val_accuracy: 0.8633\n",
      "Epoch 798/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6667 - val_accuracy: 0.8633\n",
      "Epoch 799/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6668 - val_accuracy: 0.8633\n",
      "Epoch 800/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6669 - val_accuracy: 0.8633\n",
      "Epoch 801/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6670 - val_accuracy: 0.8633\n",
      "Epoch 802/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6672 - val_accuracy: 0.8633\n",
      "Epoch 803/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6672 - val_accuracy: 0.8633\n",
      "Epoch 804/1000\n",
      "700/700 [==============================] - 0s 235us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6673 - val_accuracy: 0.8633\n",
      "Epoch 805/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6674 - val_accuracy: 0.8633\n",
      "Epoch 806/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6675 - val_accuracy: 0.8633\n",
      "Epoch 807/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6677 - val_accuracy: 0.8633\n",
      "Epoch 808/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6678 - val_accuracy: 0.8633\n",
      "Epoch 809/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6678 - val_accuracy: 0.8633\n",
      "Epoch 810/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6680 - val_accuracy: 0.8633\n",
      "Epoch 811/1000\n",
      "700/700 [==============================] - 0s 234us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6681 - val_accuracy: 0.8633\n",
      "Epoch 812/1000\n",
      "700/700 [==============================] - 0s 245us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6682 - val_accuracy: 0.8633\n",
      "Epoch 813/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6683 - val_accuracy: 0.8633\n",
      "Epoch 814/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6684 - val_accuracy: 0.8633\n",
      "Epoch 815/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6685 - val_accuracy: 0.8633\n",
      "Epoch 816/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6686 - val_accuracy: 0.8633\n",
      "Epoch 817/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6687 - val_accuracy: 0.8633\n",
      "Epoch 818/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6688 - val_accuracy: 0.8633\n",
      "Epoch 819/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 235us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6688 - val_accuracy: 0.8633\n",
      "Epoch 820/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6690 - val_accuracy: 0.8633\n",
      "Epoch 821/1000\n",
      "700/700 [==============================] - 0s 235us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6691 - val_accuracy: 0.8633\n",
      "Epoch 822/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6692 - val_accuracy: 0.8633\n",
      "Epoch 823/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6693 - val_accuracy: 0.8633\n",
      "Epoch 824/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6694 - val_accuracy: 0.8633\n",
      "Epoch 825/1000\n",
      "700/700 [==============================] - 0s 234us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6695 - val_accuracy: 0.8633\n",
      "Epoch 826/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6696 - val_accuracy: 0.8633\n",
      "Epoch 827/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6697 - val_accuracy: 0.8633\n",
      "Epoch 828/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6698 - val_accuracy: 0.8633\n",
      "Epoch 829/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6700 - val_accuracy: 0.8633\n",
      "Epoch 830/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6700 - val_accuracy: 0.8633\n",
      "Epoch 831/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6702 - val_accuracy: 0.8633\n",
      "Epoch 832/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6703 - val_accuracy: 0.8633\n",
      "Epoch 833/1000\n",
      "700/700 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.00 - 0s 245us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6704 - val_accuracy: 0.8633\n",
      "Epoch 834/1000\n",
      "700/700 [==============================] - 0s 235us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6704 - val_accuracy: 0.8633\n",
      "Epoch 835/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6705 - val_accuracy: 0.8633\n",
      "Epoch 836/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6707 - val_accuracy: 0.8633\n",
      "Epoch 837/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6708 - val_accuracy: 0.8633\n",
      "Epoch 838/1000\n",
      "700/700 [==============================] - 0s 246us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6709 - val_accuracy: 0.8633\n",
      "Epoch 839/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6710 - val_accuracy: 0.8633\n",
      "Epoch 840/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6710 - val_accuracy: 0.8633\n",
      "Epoch 841/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6711 - val_accuracy: 0.8633\n",
      "Epoch 842/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6712 - val_accuracy: 0.8633\n",
      "Epoch 843/1000\n",
      "700/700 [==============================] - 0s 235us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6712 - val_accuracy: 0.8633\n",
      "Epoch 844/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6714 - val_accuracy: 0.8633\n",
      "Epoch 845/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6714 - val_accuracy: 0.8633\n",
      "Epoch 846/1000\n",
      "700/700 [==============================] - 0s 234us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6716 - val_accuracy: 0.8633\n",
      "Epoch 847/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6717 - val_accuracy: 0.8633\n",
      "Epoch 848/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6718 - val_accuracy: 0.8633\n",
      "Epoch 849/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6719 - val_accuracy: 0.8633\n",
      "Epoch 850/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6720 - val_accuracy: 0.8633\n",
      "Epoch 851/1000\n",
      "700/700 [==============================] - 0s 235us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6722 - val_accuracy: 0.8633\n",
      "Epoch 852/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6723 - val_accuracy: 0.8633\n",
      "Epoch 853/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6724 - val_accuracy: 0.8633\n",
      "Epoch 854/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6725 - val_accuracy: 0.8633\n",
      "Epoch 855/1000\n",
      "700/700 [==============================] - 0s 235us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6725 - val_accuracy: 0.8633\n",
      "Epoch 856/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6727 - val_accuracy: 0.8633\n",
      "Epoch 857/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6727 - val_accuracy: 0.8633\n",
      "Epoch 858/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6728 - val_accuracy: 0.8633\n",
      "Epoch 859/1000\n",
      "700/700 [==============================] - 0s 245us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6729 - val_accuracy: 0.8633\n",
      "Epoch 860/1000\n",
      "700/700 [==============================] - 0s 246us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6730 - val_accuracy: 0.8633\n",
      "Epoch 861/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6731 - val_accuracy: 0.8633\n",
      "Epoch 862/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6732 - val_accuracy: 0.8633\n",
      "Epoch 863/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6732 - val_accuracy: 0.8633\n",
      "Epoch 864/1000\n",
      "700/700 [==============================] - 0s 235us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6733 - val_accuracy: 0.8633\n",
      "Epoch 865/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6734 - val_accuracy: 0.8633\n",
      "Epoch 866/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6735 - val_accuracy: 0.8633\n",
      "Epoch 867/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6737 - val_accuracy: 0.8633\n",
      "Epoch 868/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6738 - val_accuracy: 0.8633\n",
      "Epoch 869/1000\n",
      "700/700 [==============================] - 0s 246us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6739 - val_accuracy: 0.8633\n",
      "Epoch 870/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6740 - val_accuracy: 0.8633\n",
      "Epoch 871/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6741 - val_accuracy: 0.8633\n",
      "Epoch 872/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6742 - val_accuracy: 0.8633\n",
      "Epoch 873/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6743 - val_accuracy: 0.8633\n",
      "Epoch 874/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6744 - val_accuracy: 0.8633\n",
      "Epoch 875/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6745 - val_accuracy: 0.8633\n",
      "Epoch 876/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6746 - val_accuracy: 0.8633\n",
      "Epoch 877/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6747 - val_accuracy: 0.8633\n",
      "Epoch 878/1000\n",
      "700/700 [==============================] - 0s 234us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6748 - val_accuracy: 0.8633\n",
      "Epoch 879/1000\n",
      "700/700 [==============================] - 0s 235us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6748 - val_accuracy: 0.8633\n",
      "Epoch 880/1000\n",
      "700/700 [==============================] - 0s 235us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6749 - val_accuracy: 0.8633\n",
      "Epoch 881/1000\n",
      "700/700 [==============================] - 0s 235us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6750 - val_accuracy: 0.8633\n",
      "Epoch 882/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6752 - val_accuracy: 0.8633\n",
      "Epoch 883/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6753 - val_accuracy: 0.8633\n",
      "Epoch 884/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6753 - val_accuracy: 0.8633\n",
      "Epoch 885/1000\n",
      "700/700 [==============================] - 0s 234us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6754 - val_accuracy: 0.8633\n",
      "Epoch 886/1000\n",
      "700/700 [==============================] - 0s 249us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6755 - val_accuracy: 0.8633\n",
      "Epoch 887/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6756 - val_accuracy: 0.8633\n",
      "Epoch 888/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6757 - val_accuracy: 0.8633\n",
      "Epoch 889/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6758 - val_accuracy: 0.8633\n",
      "Epoch 890/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6759 - val_accuracy: 0.8633\n",
      "Epoch 891/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6760 - val_accuracy: 0.8633\n",
      "Epoch 892/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6761 - val_accuracy: 0.8633\n",
      "Epoch 893/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6762 - val_accuracy: 0.8633\n",
      "Epoch 894/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6763 - val_accuracy: 0.8633\n",
      "Epoch 895/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6764 - val_accuracy: 0.8633\n",
      "Epoch 896/1000\n",
      "700/700 [==============================] - 0s 245us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6764 - val_accuracy: 0.8633\n",
      "Epoch 897/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6766 - val_accuracy: 0.8633\n",
      "Epoch 898/1000\n",
      "700/700 [==============================] - 0s 248us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6767 - val_accuracy: 0.8633\n",
      "Epoch 899/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6768 - val_accuracy: 0.8633\n",
      "Epoch 900/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6768 - val_accuracy: 0.8633\n",
      "Epoch 901/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6770 - val_accuracy: 0.8633\n",
      "Epoch 902/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6770 - val_accuracy: 0.8633\n",
      "Epoch 903/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6771 - val_accuracy: 0.8633\n",
      "Epoch 904/1000\n",
      "700/700 [==============================] - 0s 249us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6772 - val_accuracy: 0.8633\n",
      "Epoch 905/1000\n",
      "700/700 [==============================] - 0s 246us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6773 - val_accuracy: 0.8633\n",
      "Epoch 906/1000\n",
      "700/700 [==============================] - 0s 235us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6773 - val_accuracy: 0.8633\n",
      "Epoch 907/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6775 - val_accuracy: 0.8633\n",
      "Epoch 908/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6775 - val_accuracy: 0.8633\n",
      "Epoch 909/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6777 - val_accuracy: 0.8633\n",
      "Epoch 910/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6777 - val_accuracy: 0.8633\n",
      "Epoch 911/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6778 - val_accuracy: 0.8633\n",
      "Epoch 912/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6779 - val_accuracy: 0.8633\n",
      "Epoch 913/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6780 - val_accuracy: 0.8633\n",
      "Epoch 914/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6782 - val_accuracy: 0.8633\n",
      "Epoch 915/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6782 - val_accuracy: 0.8633\n",
      "Epoch 916/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6783 - val_accuracy: 0.8633\n",
      "Epoch 917/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6784 - val_accuracy: 0.8633\n",
      "Epoch 918/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6785 - val_accuracy: 0.8633\n",
      "Epoch 919/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6785 - val_accuracy: 0.8633\n",
      "Epoch 920/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6786 - val_accuracy: 0.8633\n",
      "Epoch 921/1000\n",
      "700/700 [==============================] - 0s 258us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6787 - val_accuracy: 0.8633\n",
      "Epoch 922/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6788 - val_accuracy: 0.8633\n",
      "Epoch 923/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6789 - val_accuracy: 0.8633\n",
      "Epoch 924/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6790 - val_accuracy: 0.8633\n",
      "Epoch 925/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6791 - val_accuracy: 0.8633\n",
      "Epoch 926/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6792 - val_accuracy: 0.8633\n",
      "Epoch 927/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6793 - val_accuracy: 0.8633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 928/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6793 - val_accuracy: 0.8633\n",
      "Epoch 929/1000\n",
      "700/700 [==============================] - 0s 234us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6795 - val_accuracy: 0.8633\n",
      "Epoch 930/1000\n",
      "700/700 [==============================] - 0s 235us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6795 - val_accuracy: 0.8633\n",
      "Epoch 931/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6796 - val_accuracy: 0.8633\n",
      "Epoch 932/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6797 - val_accuracy: 0.8633\n",
      "Epoch 933/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6799 - val_accuracy: 0.8633\n",
      "Epoch 934/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6800 - val_accuracy: 0.8633\n",
      "Epoch 935/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6800 - val_accuracy: 0.8633\n",
      "Epoch 936/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6801 - val_accuracy: 0.8633\n",
      "Epoch 937/1000\n",
      "700/700 [==============================] - 0s 235us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6801 - val_accuracy: 0.8633\n",
      "Epoch 938/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6802 - val_accuracy: 0.8633\n",
      "Epoch 939/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6803 - val_accuracy: 0.8633\n",
      "Epoch 940/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6805 - val_accuracy: 0.8667\n",
      "Epoch 941/1000\n",
      "700/700 [==============================] - 0s 248us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6805 - val_accuracy: 0.8667\n",
      "Epoch 942/1000\n",
      "700/700 [==============================] - 0s 234us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6806 - val_accuracy: 0.8633\n",
      "Epoch 943/1000\n",
      "700/700 [==============================] - 0s 235us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6807 - val_accuracy: 0.8667\n",
      "Epoch 944/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6808 - val_accuracy: 0.8667\n",
      "Epoch 945/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6809 - val_accuracy: 0.8667\n",
      "Epoch 946/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6810 - val_accuracy: 0.8667\n",
      "Epoch 947/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6810 - val_accuracy: 0.8667\n",
      "Epoch 948/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6811 - val_accuracy: 0.8667\n",
      "Epoch 949/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6812 - val_accuracy: 0.8667\n",
      "Epoch 950/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6814 - val_accuracy: 0.8667\n",
      "Epoch 951/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6815 - val_accuracy: 0.8667\n",
      "Epoch 952/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6815 - val_accuracy: 0.8667\n",
      "Epoch 953/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6816 - val_accuracy: 0.8667\n",
      "Epoch 954/1000\n",
      "700/700 [==============================] - 0s 235us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6817 - val_accuracy: 0.8667\n",
      "Epoch 955/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6817 - val_accuracy: 0.8667\n",
      "Epoch 956/1000\n",
      "700/700 [==============================] - 0s 246us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6818 - val_accuracy: 0.8667\n",
      "Epoch 957/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6819 - val_accuracy: 0.8667\n",
      "Epoch 958/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6820 - val_accuracy: 0.8667\n",
      "Epoch 959/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6821 - val_accuracy: 0.8667\n",
      "Epoch 960/1000\n",
      "700/700 [==============================] - 0s 234us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6821 - val_accuracy: 0.8667\n",
      "Epoch 961/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6822 - val_accuracy: 0.8667\n",
      "Epoch 962/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6823 - val_accuracy: 0.8667\n",
      "Epoch 963/1000\n",
      "700/700 [==============================] - 0s 235us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6824 - val_accuracy: 0.8667\n",
      "Epoch 964/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6825 - val_accuracy: 0.8667\n",
      "Epoch 965/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6826 - val_accuracy: 0.8667\n",
      "Epoch 966/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6827 - val_accuracy: 0.8667\n",
      "Epoch 967/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6828 - val_accuracy: 0.8667\n",
      "Epoch 968/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6829 - val_accuracy: 0.8667\n",
      "Epoch 969/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6830 - val_accuracy: 0.8667\n",
      "Epoch 970/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6831 - val_accuracy: 0.8667\n",
      "Epoch 971/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6832 - val_accuracy: 0.8667\n",
      "Epoch 972/1000\n",
      "700/700 [==============================] - 0s 235us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6833 - val_accuracy: 0.8667\n",
      "Epoch 973/1000\n",
      "700/700 [==============================] - 0s 241us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6834 - val_accuracy: 0.8667\n",
      "Epoch 974/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6834 - val_accuracy: 0.8667\n",
      "Epoch 975/1000\n",
      "700/700 [==============================] - 0s 264us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6835 - val_accuracy: 0.8667\n",
      "Epoch 976/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6835 - val_accuracy: 0.8667\n",
      "Epoch 977/1000\n",
      "700/700 [==============================] - 0s 246us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6836 - val_accuracy: 0.8667\n",
      "Epoch 978/1000\n",
      "700/700 [==============================] - 0s 234us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6838 - val_accuracy: 0.8667\n",
      "Epoch 979/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6838 - val_accuracy: 0.8667\n",
      "Epoch 980/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6839 - val_accuracy: 0.8667\n",
      "Epoch 981/1000\n",
      "700/700 [==============================] - 0s 244us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6840 - val_accuracy: 0.8667\n",
      "Epoch 982/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6840 - val_accuracy: 0.8667\n",
      "Epoch 983/1000\n",
      "700/700 [==============================] - 0s 235us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6841 - val_accuracy: 0.8667\n",
      "Epoch 984/1000\n",
      "700/700 [==============================] - 0s 234us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6842 - val_accuracy: 0.8667\n",
      "Epoch 985/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6844 - val_accuracy: 0.8667\n",
      "Epoch 986/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6844 - val_accuracy: 0.8667\n",
      "Epoch 987/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6845 - val_accuracy: 0.8667\n",
      "Epoch 988/1000\n",
      "700/700 [==============================] - 0s 235us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6846 - val_accuracy: 0.8667\n",
      "Epoch 989/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6847 - val_accuracy: 0.8667\n",
      "Epoch 990/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6847 - val_accuracy: 0.8667\n",
      "Epoch 991/1000\n",
      "700/700 [==============================] - 0s 242us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6849 - val_accuracy: 0.8667\n",
      "Epoch 992/1000\n",
      "700/700 [==============================] - 0s 239us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6850 - val_accuracy: 0.8667\n",
      "Epoch 993/1000\n",
      "700/700 [==============================] - 0s 246us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6850 - val_accuracy: 0.8667\n",
      "Epoch 994/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6851 - val_accuracy: 0.8667\n",
      "Epoch 995/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6852 - val_accuracy: 0.8667\n",
      "Epoch 996/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6853 - val_accuracy: 0.8667\n",
      "Epoch 997/1000\n",
      "700/700 [==============================] - 0s 235us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6853 - val_accuracy: 0.8667\n",
      "Epoch 998/1000\n",
      "700/700 [==============================] - 0s 238us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6854 - val_accuracy: 0.8667\n",
      "Epoch 999/1000\n",
      "700/700 [==============================] - 0s 235us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6855 - val_accuracy: 0.8667\n",
      "Epoch 1000/1000\n",
      "700/700 [==============================] - 0s 237us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6856 - val_accuracy: 0.8667\n"
     ]
    }
   ],
   "source": [
    "tb_hist = tf.keras.callbacks.TensorBoard(log_dir='.\\\\graph', histogram_freq=0, write_graph=True, write_images=True)\n",
    "hist = model.fit(X_train, Y_train, epochs=1000, batch_size=10, validation_data=(X_val, Y_val), callbacks=[tb_hist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 6212), started 0:01:01 ago. (Use '!kill 6212' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-acd54c5391a856ff\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-acd54c5391a856ff\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir .\\\\graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 학습과정 그래프로 확인 \n",
    "* 히스토리 객체 생성 \n",
    "    * 매 에포크 마다의 훈련 손실값 (loss)\n",
    "    * 매 에포크 마다의 훈련 정확도 (acc)\n",
    "    * 에포크 마다의 검증 손실값 (val_loss)\n",
    "    * 에포크 마다의 검증 정확도 (val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "\n",
    "acc_ax.plot(hist.history['accuracy'], 'b', label='train acc')\n",
    "acc_ax.plot(hist.history['val_accuracy'], 'g', label='val acc')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 학습과정 살펴보기\n",
    "* 모델 학습 시 훈련셋, 검증셋의 손실 및 정확도를 측정합니다.\n",
    "* 반복횟수에 따른 손실 및 정확도 추이를 보면서 학습 상황을 판단합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## training loss and accuracy ##\n",
      "[2.03818267754146, 1.5489052363804408, 1.2097517166818892, 0.9876985013484955, 0.8346464255026409, 0.7306362705571311, 0.649454750759261, 0.5883402628558022, 0.5395576932600566, 0.4953461738569396, 0.46439115958554406, 0.43410255781241824, 0.40803000756672453, 0.3829620763659477, 0.3618579643113273, 0.3419353233916419, 0.32777290216514043, 0.3098486550152302, 0.2936378632272993, 0.28331324697605204, 0.27035166333828653, 0.2602737506585462, 0.24866899640432427, 0.23922041931322643, 0.22897353736417633, 0.22121576903653997, 0.21165531112679414, 0.20607501433363984, 0.19675255875502315, 0.19103170920695578, 0.183606531098485, 0.17729923187622001, 0.1711532304861716, 0.16572551519743034, 0.1603626889841897, 0.1536906375948872, 0.15013648377997535, 0.1455330090863364, 0.14148797432758978, 0.13677361889609269, 0.13147228067474706, 0.12942335358155624, 0.12426540303443159, 0.12145758688982045, 0.1176586862653494, 0.11450629283541015, 0.11078862925725323, 0.10807110592722893, 0.10440685749053955, 0.10233423691242934, 0.09892306797472494, 0.09646583007914679, 0.09388767991747175, 0.09163001552224159, 0.0891498925164342, 0.08614512107201985, 0.08457783048174211, 0.0822813062928617, 0.08046267023310065, 0.07848673164844513, 0.0765901008354766, 0.07487871263708387, 0.07299646748495954, 0.07145988708361983, 0.06977913918505822, 0.06795737465311374, 0.06652784740020122, 0.0654086285935981, 0.06381780783246671, 0.06227777952860509, 0.06107098955128874, 0.059730348563087836, 0.05863103903830051, 0.05763546034161534, 0.05627746153622866, 0.055116906136806525, 0.05413740680419973, 0.052797851166022675, 0.0520588797783213, 0.050983061934156075, 0.04982607424525278, 0.049054927046277695, 0.04816142085141369, 0.04730768221031342, 0.04655703202422176, 0.04544897201870169, 0.04495577881378787, 0.04405801562326295, 0.04327603083636079, 0.04259647164227707, 0.04184706485165017, 0.04117033871422921, 0.040411178568112, 0.039831786775695426, 0.03910746020930154, 0.03835612800238388, 0.03798457704085324, 0.03728376845163958, 0.036732503984655655, 0.03606443371889847, 0.03565797498449683, 0.03501157673474933, 0.03448662022128701, 0.03396150642739875, 0.03349800858247493, 0.033014225786817925, 0.03256584915465542, 0.032143364860011, 0.03164320000713425, 0.031115983143847968, 0.030841040704399348, 0.030352440063974688, 0.02989897598911609, 0.02952072457410395, 0.029180532304703126, 0.02870665952962424, 0.028309244742350918, 0.027886725795854415, 0.027679733925365976, 0.027300524531996676, 0.026893382951883333, 0.026613811988915714, 0.026238257717341184, 0.026058230445986347, 0.02564730455965868, 0.025347493861668877, 0.02504100326581725, 0.024739040840151053, 0.02443811074398192, 0.024165419143225467, 0.02389117647627635, 0.023614558351359196, 0.023430219339206814, 0.023116386056478533, 0.02283154655514019, 0.02257658648304641, 0.02232355885207653, 0.02210132109134325, 0.021819156135565468, 0.02159350674732455, 0.021352925687097013, 0.02115039014523583, 0.020954201566720648, 0.020734266018761056, 0.0204881226776966, 0.020267453553554204, 0.02009247588326356, 0.01986705537419766, 0.01965485752028014, 0.01947190613885011, 0.019266929055031922, 0.01906550018715539, 0.018900727347603865, 0.01873306312398719, 0.01854385677059846, 0.018363010763589826, 0.018150322551706007, 0.018036953479583773, 0.017862294567748904, 0.017671459311220262, 0.017525328589337214, 0.01733941766766033, 0.01716903773402529, 0.017066837358288466, 0.016898746761892524, 0.016744507696213468, 0.01658651075059814, 0.01644812247250229, 0.01630438964015671, 0.01617731848049776, 0.016047846705519727, 0.015898407689694846, 0.015757856514704016, 0.015605896112642117, 0.01548798473086208, 0.015361133676820567, 0.015242637071891555, 0.015095207464349057, 0.014979590538756124, 0.014855103414239628, 0.014739990094676613, 0.014601123800301659, 0.01451821246716593, 0.014385383453087083, 0.014285360968538692, 0.014178457147707896, 0.014034127167958235, 0.013930613046146132, 0.013822212943341582, 0.013726081333256193, 0.01363512802137328, 0.013514480493696673, 0.013423462711008532, 0.013323975131580873, 0.013227975940597908, 0.013120744859666697, 0.013025126030801663, 0.012933305409803454, 0.012834985645687474, 0.012739177264406213, 0.0126439997261124, 0.012558923375659755, 0.012470048972006355, 0.012381906424915151, 0.01229395310594035, 0.012200490717909166, 0.012113129310975117, 0.01204914809204638, 0.01196322145738772, 0.011865816805844328, 0.011789064877666533, 0.01172724382153579, 0.011631830109815512, 0.011563717756819513, 0.011487141547591558, 0.011401038152897464, 0.011338171316310763, 0.011265840002202562, 0.011189340919788395, 0.011107974818774633, 0.011030699901415834, 0.010973478559338088, 0.010892775847709604, 0.010820682486519217, 0.01076824044409607, 0.010677895798081798, 0.010634711334880973, 0.010549498367722013, 0.01049165033868381, 0.010428024269640446, 0.010364130829527442, 0.010291138447688095, 0.010238371525026326, 0.010178807261399924, 0.010103075187985918, 0.010049456404522062, 0.009998110320884735, 0.00993278164948736, 0.009868370430610542, 0.009819054137915373, 0.009759843246346073, 0.00970128940950547, 0.009641953610948153, 0.009589048546539353, 0.009526451291250331, 0.009473907553391265, 0.009426573836909874, 0.009375776307258223, 0.009315242595870845, 0.009264342495173748, 0.009213088472772921, 0.00915305949082332, 0.009110211923585406, 0.00905374149193189, 0.009009826170014484, 0.008972266695595213, 0.008908723753743937, 0.008864831625084791, 0.00881406909486811, 0.0087709137870531, 0.008721035249930406, 0.008673520236542182, 0.008631507987489125, 0.008584199932270817, 0.008544811237204289, 0.008493383210485003, 0.00845071663581101, 0.008406970240840955, 0.008355958222611141, 0.008318438662016498, 0.008270702484462942, 0.008228067919013224, 0.008185377566509748, 0.008144009461310426, 0.008102823185202267, 0.008068505614729864, 0.00802063701474773, 0.007987422564266516, 0.007947331281112774, 0.007902131282857485, 0.007868341482909663, 0.007836376715983664, 0.007788361510860601, 0.007754829411195325, 0.007711674470920115, 0.007673530589922198, 0.007637517705526469, 0.007602345384657383, 0.007565375161357224, 0.007530143343111766, 0.007491262882415737, 0.007456553546113095, 0.007423887020974819, 0.007390759018848517, 0.007356040188044842, 0.007313770860699671, 0.0072892807291022365, 0.007250771290689175, 0.007217311935632357, 0.0071810578628044045, 0.00715174254811635, 0.007118183931535376, 0.007084991056139448, 0.007054731758710529, 0.0070216175700937, 0.006991615301064615, 0.006953377545661559, 0.00692641687471353, 0.006898069358430803, 0.006869527543728639, 0.006836009381472, 0.0068091364702143305, 0.006773408768432481, 0.0067517341181103675, 0.006715739318834884, 0.006685830350033939, 0.00665621082963688, 0.006635034219029227, 0.006602530889878316, 0.006570106041285076, 0.0065462557765256085, 0.0065175163393308005, 0.006483148869925312, 0.006465955875215253, 0.006431649750032063, 0.006408768654468336, 0.006378886988386512, 0.006357899057080171, 0.006330485893080809, 0.006303395656868815, 0.006279572328951742, 0.0062518222648317795, 0.006224502620586593, 0.006202279992534646, 0.006177393687955503, 0.006148687039967626, 0.00612734317297249, 0.006100687604962981, 0.0060757752674232635, 0.006054739278208997, 0.006028110936417111, 0.006003461206897295, 0.005985242976540965, 0.005954911413469485, 0.0059346838172392126, 0.00591027524621625, 0.005886241150022085, 0.005867501331626304, 0.005836560609584142, 0.005819938230394785, 0.0057953822991943784, 0.005777445410993616, 0.005751015561898904, 0.005730351372455646, 0.005706628555032824, 0.005686028341629675, 0.005663683076064834, 0.005642022039475185, 0.005621555358603863, 0.0055981791079310434, 0.005579177559619504, 0.005554441819965307, 0.005536236218176782, 0.005518528997033302, 0.005494915451189237, 0.005473254004859232, 0.0054551871659766354, 0.005439067808245974, 0.005419489503505507, 0.005398841252151345, 0.005380088275498045, 0.005357374309096485, 0.005337886768393219, 0.005317787875953529, 0.005300972695528929, 0.0052802800733063905, 0.005264583133560206, 0.00524232963216491, 0.005224628250912897, 0.005208564892278186, 0.005187742250771927, 0.00516993334999175, 0.005150813351584864, 0.005136276259768887, 0.005114313297339582, 0.005096833910127835, 0.005081298120785505, 0.0050633458728303335, 0.0050469331451625165, 0.0050235670675257485, 0.005012965724537415, 0.004993021486526621, 0.0049742006638552995, 0.004961199005733111, 0.004939803010451474, 0.004927027543141906, 0.004910354430155296, 0.00489254089604531, 0.004879491695984533, 0.0048614120410223095, 0.004843914703399475, 0.004829969834203699, 0.0048124058205368265, 0.004797188438741224, 0.004780534693522246, 0.00476656119031499, 0.0047501040655853494, 0.004732962639536709, 0.004718053952923843, 0.00470071512141398, 0.004687519933629249, 0.004672587730289836, 0.00465809016105985, 0.004641847500378, 0.0046275864272112294, 0.004613733938146782, 0.00459800317434461, 0.00458341666297721, 0.004568256160044777, 0.004553727196928646, 0.004540418548276648, 0.004526599305349269, 0.0045121795198481, 0.0044965078538682845, 0.004482705990916916, 0.004468708940216207, 0.004457111148596076, 0.004443413864854457, 0.004427691889993314, 0.004412714524992875, 0.004402465095543968, 0.004385818233380892, 0.004373936924717522, 0.004359401433196451, 0.004346934552138139, 0.004333819294281836, 0.0043204644761447395, 0.004307774883844624, 0.004292545068476881, 0.004280205752833614, 0.004270085094529869, 0.004254831490938419, 0.004244122941911753, 0.004229779977218381, 0.004217899562874144, 0.0042059287927778705, 0.004194503551116213, 0.004181449120681334, 0.004168072440162567, 0.004156060520991949, 0.004144039028324187, 0.004129733209265396, 0.004120212489007307, 0.004107946532479088, 0.004095343825507111, 0.004083365407339962, 0.004071950160765222, 0.004059751404981528, 0.004048362497373351, 0.004037628746092586, 0.004025507063904245, 0.0040127672072100854, 0.004003048886079341, 0.003991723399043881, 0.003978385038707139, 0.003968021956305685, 0.003958366567634844, 0.003946695116714441, 0.003934104581795899, 0.003922593246014522, 0.003913317016226107, 0.0039012999440144213, 0.003891003636610029, 0.0038808246359362136, 0.0038707238156348465, 0.003859040589304641, 0.003848601846922455, 0.0038392159339439656, 0.003826701987002577, 0.003817558754235506, 0.0038068050497843484, 0.003795874072238803, 0.0037853277280061903, 0.003775653865471083, 0.0037650019188211967, 0.0037546253630093168, 0.0037463945461370584, 0.0037340879997438087, 0.003727766716786261, 0.0037157688822065083, 0.003705211595765182, 0.0036950276233255865, 0.003685168774349482, 0.003673612424505076, 0.0036652718712243118, 0.0036557496957747, 0.0036458491593033874, 0.0036357071159207927, 0.0036279813078830816, 0.0036176420058057243, 0.003607929072209767, 0.0035985638071516796, 0.0035908762286583494, 0.0035806479672568716, 0.0035708149186185825, 0.0035611786813076053, 0.003553481838233503, 0.003544583750356521, 0.0035348636796697975, 0.0035252997452127083, 0.003515583127903353, 0.003505998527232025, 0.0034977216389961542, 0.003489674343394914, 0.003479411715774664, 0.003472295627995793, 0.003462141245004854, 0.0034537411660754253, 0.003445458656226817, 0.0034372804071088987, 0.0034286949958186597, 0.003420686981241618, 0.003411422807922853, 0.003402792618310611, 0.0033940038519046666, 0.0033861369393499833, 0.0033777696512905615, 0.0033696826065092215, 0.0033607709005341996, 0.0033524084254167976, 0.0033456601884349116, 0.003335089999849775, 0.0033276024873235394, 0.0033199351172827716, 0.0033118684485089036, 0.003304782834103597, 0.003296494276894789, 0.0032884952213082996, 0.003278824793440955, 0.0032718613128443915, 0.003263122511063037, 0.0032553146759580287, 0.0032486082744851174, 0.0032406963150216532, 0.003233087171767173, 0.0032254170260525177, 0.0032181397296621333, 0.0032103431527502834, 0.003201918737197827, 0.0031942168716341257, 0.003186157440567123, 0.003178389512634437, 0.0031733766131635224, 0.003164721143964146, 0.003156978493331865, 0.0031495966682476657, 0.0031418702265779887, 0.00313497089997067, 0.0031279445293226414, 0.0031222964616193036, 0.0031131532658556743, 0.003106521922329973, 0.003099264791983712, 0.003092121781082824, 0.003084742888625312, 0.0030783613112622074, 0.0030717198695388755, 0.0030638624323598507, 0.0030578345829521173, 0.003050082713681539, 0.003043307749820607, 0.003035388028781329, 0.0030291310058341227, 0.003021732993823077, 0.003015698176126794, 0.0030090706597547976, 0.003001443142836381, 0.0029963788060870552, 0.002989461717827778, 0.0029825450162336764, 0.00297632795575607, 0.002968356882255258, 0.0029611562129243144, 0.0029561706901794034, 0.002948773087700829, 0.0029432541906966696, 0.0029363168291248647, 0.002929877601231315, 0.0029237775560302126, 0.0029169252957217395, 0.002911120848979668, 0.002903268758174298, 0.002898127264260048, 0.0028915542701724918, 0.0028856936927435786, 0.002878993863539238, 0.002873771289263719, 0.0028663255623541774, 0.002860522640029168, 0.0028539676817932297, 0.002848524780711159, 0.002842435737589507, 0.002836421784845048, 0.002829407640300425, 0.002824020435634468, 0.0028176884724026813, 0.002812364237615839, 0.0028059256329600302, 0.0028000389196677134, 0.0027947504547358093, 0.002788618248554745, 0.00278259815864398, 0.002776181631322418, 0.002770055692443358, 0.002764969885382535, 0.0027595581399509684, 0.0027532483895941237, 0.002747648556916309, 0.0027417233342670703, 0.0027356395256772103, 0.002730543356821207, 0.0027252819996127593, 0.0027196130195599314, 0.0027141291361268876, 0.002708632592943364, 0.0027022114006935486, 0.0026964241821718004, 0.002691495163266414, 0.0026860037752028023, 0.002680297097789922, 0.002675507959377553, 0.0026703810315146775, 0.0026635031698138585, 0.0026595383915784102, 0.0026537065448272706, 0.002648882106378941, 0.0026426449027245067, 0.0026377457913310666, 0.0026319869295028703, 0.002627140230781931, 0.0026217473192705907, 0.002615884955490141, 0.0026114717583238544, 0.002606471104913258, 0.0026003943182461497, 0.002595488173704195, 0.0025902940317921873, 0.0025853573436117067, 0.0025805227258907898, 0.002574973278180031, 0.002569294173736125, 0.002565172394471509, 0.002560108348968372, 0.0025548493132061725, 0.0025501516373229345, 0.002544926692748309, 0.002539386277619217, 0.0025352865781834615, 0.002529957372046608, 0.0025249456722771617, 0.0025198431677251523, 0.0025157150355101165, 0.0025106510862575046, 0.0025054836429522507, 0.002501530327052543, 0.002496732119055066, 0.002491782240602853, 0.0024862542033328543, 0.002481667571867417, 0.0024769696465227753, 0.0024729236557115134, 0.002467731844600556, 0.0024636794322369887, 0.0024583486341206093, 0.002453701510551452, 0.002449008374242112, 0.002444997537116121, 0.0024397479694536223, 0.0024354272754862905, 0.002430934230713839, 0.0024260938550079506, 0.0024220609729776956, 0.0024173957811269376, 0.0024126003583660348, 0.002407842269583073, 0.002403488670409258, 0.002398724283973154, 0.0023949891989884366, 0.0023901611096724604, 0.0023853072688715267, 0.002382153473445214, 0.0023768005231561674, 0.0023734150687232613, 0.0023690342612098904, 0.002363554374980075, 0.0023595496752282737, 0.002355108193088589, 0.0023513777202294607, 0.0023467340406828695, 0.002342737585006814, 0.0023386800586844662, 0.0023335490779053153, 0.0023291843993190143, 0.0023251539557739825, 0.002321396551893226, 0.002317097798056368, 0.002313065155509061, 0.0023085976019501684, 0.0023048209454697957, 0.0023009362114992525, 0.002295946841227955, 0.0022925670466585352, 0.0022886202055295663, 0.0022840114327014557, 0.0022801885254531435, 0.002276238733195766, 0.002271461157111584, 0.0022678604166555616, 0.0022637899657378772, 0.002259979234284921, 0.002255911614546286, 0.0022515400687033046, 0.002247927791904658, 0.0022441543626233137, 0.002240269777082306, 0.0022364487031674278, 0.002233066181153325, 0.0022286737919785084, 0.00222427017496167, 0.002220753055215547, 0.0022174490549202474, 0.002212896500714123, 0.002209241086217974, 0.002205695606867916, 0.002201839528840667, 0.002197788732259401, 0.0021934816139816704, 0.0021902620239416136, 0.0021865545722123767, 0.002182569183059968, 0.0021792687384212125, 0.0021751879876579293, 0.0021723957312393136, 0.0021680985847654355, 0.00216362638290905, 0.002160549289796368, 0.0021569162781815976, 0.0021528807023839494, 0.0021491733936792505, 0.0021459856465558653, 0.0021419250021738534, 0.0021384928687309315, 0.002134848409748104, 0.0021310526628180275, 0.0021277974604994856, 0.002124562830847156, 0.0021206530521989666, 0.0021174037388326334, 0.0021136486204341052, 0.0021102433198913265, 0.0021068807300512814, 0.002103671003299366, 0.0020996139135344752, 0.0020962129854264536, 0.0020926253786975784, 0.002089408760158611, 0.0020862476875273778, 0.0020820594434293785, 0.0020789354881604336, 0.002075825856133763, 0.0020722095372288354, 0.0020688400562253913, 0.002065264537564612, 0.002062142824953688, 0.0020582773036689366, 0.0020549081391696487, 0.002051761736428099, 0.0020484714926819183, 0.002045195791704048, 0.002042141883534246, 0.002038896723284519, 0.002035461352871997, 0.0020317163854737634, 0.002028934607681419, 0.0020256912518691805, 0.0020226763889825503, 0.002018868554400147, 0.002015658041429041, 0.002012813127865749, 0.0020094079485196356, 0.002006464433257601, 0.0020026865269755943, 0.001999818005632343, 0.001996676147349977, 0.0019934649579226972, 0.0019902236427047425, 0.0019869641442450564, 0.0019834607423815345, 0.0019807912471670923, 0.001977630414434576, 0.001974776991742796, 0.0019719805206737614, 0.0019683115712333735, 0.001965012267880541, 0.0019628811552788, 0.0019590233209393253, 0.0019560951697972736, 0.0019528805149353241, 0.001949959244146677, 0.0019468330726210427, 0.0019433872084066803, 0.0019403749548863353, 0.0019379276649228163, 0.001935199401175071, 0.0019321669516752342, 0.0019287900899403862, 0.0019259901314009247, 0.0019229799097437146, 0.0019203209118651492, 0.001916914470244332, 0.0019145618458943708, 0.001910900931605803, 0.001908269592760397, 0.0019051393479458056, 0.0019027238071430475, 0.0018997875869640017, 0.0018967200860580695, 0.0018939682756484086, 0.0018906280148907433, 0.0018880700002357896, 0.001884938367792139, 0.001882465705524997, 0.001879354943438167, 0.0018768655148700677, 0.0018740722601900675, 0.0018709399720786939, 0.0018683497453041906, 0.00186494148885166, 0.001862723904196173, 0.0018599651047095124, 0.0018571013422583097, 0.0018542397337504163, 0.001851880383245381, 0.00184922549732229, 0.001846189151651093, 0.0018430061592620665, 0.0018406450033320912, 0.0018378116365056485, 0.0018348097219131887, 0.0018322721718245054, 0.0018297087721293793, 0.0018267812390279556, 0.001824255138801943, 0.0018213439366913267, 0.0018190324659891693, 0.0018161780691506074, 0.001813762988812024, 0.001810635962673197, 0.0018085898802382872, 0.0018057953919716446, 0.0018032032784373899, 0.0018003346670801485, 0.0017977163571880998, 0.0017954730383020693, 0.0017925472408283636, 0.0017898424360152734, 0.0017874546827182972, 0.0017845783910680829, 0.001782492852985992, 0.0017798532327495714, 0.0017771022583474405, 0.0017748983946928223, 0.0017722632698548425, 0.0017693947792784975, 0.0017668213874068377, 0.0017643935288236077, 0.001762292831803539, 0.0017596667661564426, 0.0017565611579422175, 0.0017544444721092336, 0.0017523446870784808, 0.0017491209746887243, 0.0017472539820508764, 0.001744511075542375, 0.0017420027983981916, 0.0017395907166896255, 0.0017367184451099352, 0.001734534841879005, 0.0017323333429106111, 0.0017296951812958079, 0.001727342139929533, 0.001724956813060479, 0.001722496167141279, 0.0017199776218538838, 0.00171767071546388, 0.001715334611279624, 0.0017130889214708336, 0.0017105832454814974, 0.0017082376663373517, 0.0017058182757214776, 0.001703411591006443, 0.0017010240516226207, 0.0016987788000343634, 0.0016959982042733049, 0.0016940218045160041, 0.0016916126586563353, 0.0016891648325586825, 0.0016872143682641243, 0.0016845614593226596, 0.0016821841813258029, 0.0016800469851919583, 0.001677618023989323, 0.0016752165563437822, 0.0016728019233726496, 0.0016707964748742857, 0.0016684089112719187, 0.001666338012936259, 0.0016639973889271329, 0.0016618023942490774, 0.00165899811088041, 0.0016575656232557126, 0.0016549985718614022, 0.0016527233911412104, 0.0016503374678515164, 0.0016481422199701359, 0.0016464339660680189, 0.0016435127817593248, 0.0016417800265896532, 0.0016393979568549964, 0.0016372092338445196, 0.0016350839336934898, 0.0016328920678850929, 0.0016307559520230695, 0.001628212378376962, 0.0016261796859907917, 0.0016238802332996525, 0.0016220363518056858, 0.00161987854932834, 0.0016174669194567416, 0.0016156240270772417, 0.0016131347972467276, 0.0016113231361876907, 0.001608849414125351, 0.001606683896222551, 0.0016047730110585689, 0.0016026470319567515, 0.0016007181940949522, 0.0015984358623557324, 0.001596570704298626, 0.0015939590007682065, 0.0015923201651146103, 0.0015900408400089613, 0.0015880886556780232, 0.001585848250293306, 0.0015837115584872662, 0.0015821429904982714, 0.0015796521670251552, 0.0015777917657812525, 0.0015759270155935416, 0.0015739431554850723, 0.0015715872507176495, 0.0015694827810096156, 0.0015677930059609935, 0.0015656903830988864, 0.0015636775609371917, 0.0015616956819680386, 0.0015594363362262291, 0.0015573319538296866, 0.0015554504427460155, 0.001553595428829015, 0.0015512643194857186, 0.0015495066824119672, 0.0015469251296183627, 0.0015454999135857048, 0.0015432699907770647, 0.0015412633783333668, 0.0015396317379781977, 0.001537553463900362, 0.0015354879179670076, 0.001533484078910468, 0.0015318077030575035, 0.0015300839090611718, 0.0015279928417710055, 0.0015263056827409724, 0.0015240354230627417, 0.001522181149422457, 0.0015201361679438767, 0.0015180792975505548, 0.0015160924472313907, 0.0015143214629331071, 0.0015126160445756145, 0.0015108033883734606, 0.001508467882480805, 0.0015070199489335728, 0.001504654054796057, 0.001503081453016161, 0.0015010343157752816, 0.0014993013322444832, 0.0014972700579424522, 0.0014956639044352675]\n",
      "[0.37285715, 0.64285713, 0.7342857, 0.79571426, 0.82857144, 0.8414286, 0.8685714, 0.87285715, 0.8842857, 0.8971428, 0.9, 0.9028571, 0.91714287, 0.92142856, 0.92714286, 0.93142855, 0.93142855, 0.93714285, 0.95, 0.94285715, 0.94857144, 0.9514286, 0.95285714, 0.95285714, 0.95714283, 0.96, 0.9614286, 0.9628571, 0.96428573, 0.9628571, 0.9714286, 0.9742857, 0.97, 0.9714286, 0.9728571, 0.9785714, 0.9742857, 0.97571427, 0.9785714, 0.9785714, 0.98142856, 0.98285717, 0.98142856, 0.98571426, 0.98714286, 0.98714286, 0.9885714, 0.98714286, 0.98714286, 0.99, 0.99, 0.99, 0.99, 0.9885714, 0.99285716, 0.99285716, 0.9942857, 0.9942857, 0.9957143, 0.9957143, 0.99714285, 0.9957143, 0.99714285, 0.99714285, 0.99714285, 0.99714285, 0.99714285, 0.99857146, 0.99857146, 0.99857146, 0.99857146, 0.99714285, 0.99857146, 0.99857146, 0.99857146, 1.0, 0.99857146, 1.0, 0.99857146, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print('## training loss and accuracy ##')\n",
    "print(hist.history['loss'])\n",
    "print(hist.history['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 모델 평가하기\n",
    "* 준비된 시험셋으로 학습한 모델을 평가합니다.\n",
    "* 케라스에서는 evaluate() 함수를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - ETA: 0s - loss: 0.5390 - accuracy: 0.88 - 0s 45us/sample - loss: 0.5433 - accuracy: 0.8820\n",
      "## evaluation loss and_metrics ##\n",
      "[0.5432631515190005, 0.882]\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = model.evaluate(X_test, Y_test, batch_size=32)\n",
    "print('## evaluation loss and_metrics ##')\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. 모델 사용하기\n",
    "* 임의의 입력으로 모델의 출력을 얻습니다.\n",
    "* 케라스에서는 predict() 함수를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## yhat ##\n",
      "[[2.4687968e-10 6.6460260e-13 8.7105595e-10 2.9268645e-09 6.3525686e-12\n",
      "  1.4755410e-11 1.8348182e-14 9.9999988e-01 6.5938255e-10 8.0849595e-08]]\n"
     ]
    }
   ],
   "source": [
    "xhat = X_test[0:1]\n",
    "yhat = model.predict(xhat)\n",
    "print('## yhat ##')\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. 러닝 모델 가시화 기능 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"295pt\" viewBox=\"0.00 0.00 284.00 221.00\" width=\"379pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1.33333 1.33333) rotate(0) translate(4 217)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-217 280,-217 280,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 1513896476296 -->\n",
       "<g class=\"node\" id=\"node1\"><title>1513896476296</title>\n",
       "<polygon fill=\"none\" points=\"0,-166.5 0,-212.5 276,-212.5 276,-166.5 0,-166.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"76\" y=\"-185.8\">dense_input: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"152,-166.5 152,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"180\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"152,-189.5 208,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"180\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"208,-166.5 208,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"242\" y=\"-197.3\">[(?, 784)]</text>\n",
       "<polyline fill=\"none\" points=\"208,-189.5 276,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"242\" y=\"-174.3\">[(?, 784)]</text>\n",
       "</g>\n",
       "<!-- 1512045582408 -->\n",
       "<g class=\"node\" id=\"node2\"><title>1512045582408</title>\n",
       "<polygon fill=\"none\" points=\"35.5,-83.5 35.5,-129.5 240.5,-129.5 240.5,-83.5 35.5,-83.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"80.5\" y=\"-102.8\">dense: Dense</text>\n",
       "<polyline fill=\"none\" points=\"125.5,-83.5 125.5,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"153.5\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"125.5,-106.5 181.5,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"153.5\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"181.5,-83.5 181.5,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"211\" y=\"-114.3\">(?, 784)</text>\n",
       "<polyline fill=\"none\" points=\"181.5,-106.5 240.5,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"211\" y=\"-91.3\">(?, 64)</text>\n",
       "</g>\n",
       "<!-- 1513896476296&#45;&gt;1512045582408 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>1513896476296-&gt;1512045582408</title>\n",
       "<path d=\"M138,-166.366C138,-158.152 138,-148.658 138,-139.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"141.5,-139.607 138,-129.607 134.5,-139.607 141.5,-139.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1512045528904 -->\n",
       "<g class=\"node\" id=\"node3\"><title>1512045528904</title>\n",
       "<polygon fill=\"none\" points=\"31.5,-0.5 31.5,-46.5 244.5,-46.5 244.5,-0.5 31.5,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"83.5\" y=\"-19.8\">dense_1: Dense</text>\n",
       "<polyline fill=\"none\" points=\"135.5,-0.5 135.5,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"163.5\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"135.5,-23.5 191.5,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"163.5\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"191.5,-0.5 191.5,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"218\" y=\"-31.3\">(?, 64)</text>\n",
       "<polyline fill=\"none\" points=\"191.5,-23.5 244.5,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"218\" y=\"-8.3\">(?, 10)</text>\n",
       "</g>\n",
       "<!-- 1512045582408&#45;&gt;1512045528904 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>1512045582408-&gt;1512045528904</title>\n",
       "<path d=\"M138,-83.3664C138,-75.1516 138,-65.6579 138,-56.7252\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"141.5,-56.6068 138,-46.6068 134.5,-56.6069 141.5,-56.6068\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pydot\n",
    "import graphviz\n",
    "from IPython.display import SVG\n",
    "from tensorflow.keras.utils import model_to_dot\n",
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + \"C:/Program Files (x86)/Graphviz2.38/bin\"\n",
    "\n",
    "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. 모델 저장과 모델 로딩 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model.save('mnist_mlp_model.h5')\n",
    "model = load_model('mnist_mlp_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
