{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 셋 \n",
    "* 리스트 형태로 작성 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 데이터 \n",
    "x_data = [[1, 2, 1, 1],\n",
    "          [2, 1, 3, 2],\n",
    "          [3, 1, 3, 4],\n",
    "          [4, 1, 5, 5],\n",
    "          [1, 7, 5, 5],\n",
    "          [1, 2, 5, 6],\n",
    "          [1, 6, 6, 6],\n",
    "          [1, 7, 7, 7]]\n",
    "\n",
    "# one-hot encoding\n",
    "y_data = [[0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 1, 0],\n",
    "          [0, 1, 0],\n",
    "          [0, 1, 0],\n",
    "          [1, 0, 0],\n",
    "          [1, 0, 0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 타입 변환 \n",
    "* 리스트 --> numpy의 ndarray로 변환 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 4)\n",
      "(8, 3)\n"
     ]
    }
   ],
   "source": [
    "x_data = np.asarray(x_data, dtype=np.float32)\n",
    "y_data = np.asarray(y_data, dtype=np.float32)\n",
    "print(x_data.shape)\n",
    "print(y_data.shape)\n",
    "\n",
    "nb_classes = 3  # 클래스의 종류 3개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'weight:0' shape=(4, 3) dtype=float32, numpy=\n",
      "array([[-0.8980837 , -1.8259144 , -0.44441807],\n",
      "       [-1.4882947 , -0.7855463 ,  0.19619656],\n",
      "       [ 0.17604657, -1.5252507 ,  0.635294  ],\n",
      "       [ 0.66812044,  1.4230527 ,  0.04561644]], dtype=float32)>, <tf.Variable 'bias:0' shape=(3,) dtype=float32, numpy=array([ 0.33875433,  0.3449861 , -0.6605785 ], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "W = tf.Variable(tf.random.normal((4, nb_classes)), name='weight')\n",
    "b = tf.Variable(tf.random.normal((nb_classes,)), name='bias')\n",
    "variables = [W, b]\n",
    "print(variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 가설 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[6.2787034e-02 3.9538752e-02 8.9767426e-01]\n",
      " [1.5100013e-01 1.3186018e-03 8.4768128e-01]\n",
      " [2.8089932e-01 4.3899636e-03 7.1471071e-01]\n",
      " [1.5661684e-01 6.8538109e-05 8.4331471e-01]\n",
      " [2.9546865e-05 1.4179445e-05 9.9995625e-01]\n",
      " [1.9907025e-01 6.0536587e-03 7.9487610e-01]\n",
      " [1.8745963e-04 1.7292357e-05 9.9979526e-01]\n",
      " [4.0955692e-05 2.9611417e-06 9.9995613e-01]], shape=(8, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def hypothesis(X):\n",
    "    return tf.nn.softmax(tf.matmul(X, W) + b)\n",
    "print(hypothesis(x_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Softmax one-hot 테스트\n",
    "* 데이터를 생성할때 numpy의 ndarray로 생성하고 타입을 설정해야 한다.\n",
    "* hypothesis(data)을 사용하면 가설값을 가져온다. [[0.0479028  0.9303597  0.02173743]] - 3가지 값을 가져온다. \n",
    "* tf.argmax(hypothesis(data), 1)은 열에서 가장 큰 원소의 위치를 반환 한다. [1] 윗 값 중에 가장 큰 인덱스 1이 반환 된다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.0479028  0.9303597  0.02173743]], shape=(1, 3), dtype=float32)\n",
      "tf.Tensor([1], shape=(1,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "data = np.array([[3., 2., 1., 8.]], dtype=np.float32)\n",
    "print(hypothesis(data))  # 가설값 출력 \n",
    "print(tf.argmax(hypothesis(data), 1)) # 가설값 중에 가장 큰 원소의 위치 출력 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cost 함수 (비용함수)\n",
    "* X : 입력 데이터 \n",
    "* Y : 정답 라벨 \n",
    "* hypothesis(X) : 입력 데이터에 대한 가설값 \n",
    "* -tf.reduce_sum(Y * tf.math.log(logits), axis=1) : 각 행에 대해 비용 합계\n",
    "* tf.reduce_mean : 비용합계에 대한 평균(평균 비용) - 스칼라 값으로 반환 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(5.6441216, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def cost_fn(X, Y):\n",
    "    logits = hypothesis(X)  # x에 대한 가설값 \n",
    "    cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.math.log(logits), axis=1))  # 각 행에 대해 비용을 구한 후 함계 반환 -> 평균 \n",
    "    return cost\n",
    "\n",
    "print(cost_fn(x_data, y_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 미분 연습하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(6.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant(3.0)\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(x)\n",
    "    y = x * x \n",
    "dy_dx = tape.gradient(y, x)\n",
    "print(dy_dx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  grad(기울기 계산) 함수\n",
    "* variables = [W, b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: shape=(4, 3), dtype=float32, numpy=\n",
      "array([[ 0.0041601 , -0.74228656,  0.7381264 ],\n",
      "       [-1.4857689 , -1.2378517 ,  2.7236207 ],\n",
      "       [-1.23269   , -1.8640661 ,  3.0967562 ],\n",
      "       [-1.1915689 , -1.9879254 ,  3.1794944 ]], dtype=float32)>, <tf.Tensor: shape=(3,), dtype=float32, numpy=array([-0.14367107, -0.3685745 ,  0.51224554], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "def grad_fn(X, Y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = cost_fn(X, Y)  # 비용 계산 \n",
    "        grads = tape.gradient(loss, variables) \n",
    "    return grads\n",
    "\n",
    "print(grad_fn(x_data, y_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 학습하기 \n",
    "* SGD : 확률적 경사 하강법\n",
    "* 계산된 기울기를 변수인 [W, b]를 갱신하면서 최적의 값을 찾아감"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epochs     1: 0.15928\n",
      "Loss at epochs   100: 0.15378\n",
      "Loss at epochs   200: 0.14859\n",
      "Loss at epochs   300: 0.14373\n",
      "Loss at epochs   400: 0.13916\n",
      "Loss at epochs   500: 0.13487\n",
      "Loss at epochs   600: 0.13083\n",
      "Loss at epochs   700: 0.12701\n",
      "Loss at epochs   800: 0.12340\n",
      "Loss at epochs   900: 0.11999\n",
      "Loss at epochs  1000: 0.11676\n",
      "Loss at epochs  1100: 0.11369\n",
      "Loss at epochs  1200: 0.11077\n",
      "Loss at epochs  1300: 0.10800\n",
      "Loss at epochs  1400: 0.10536\n",
      "Loss at epochs  1500: 0.10284\n",
      "Loss at epochs  1600: 0.10044\n",
      "Loss at epochs  1700: 0.09814\n",
      "Loss at epochs  1800: 0.09594\n",
      "Loss at epochs  1900: 0.09384\n",
      "Loss at epochs  2000: 0.09183\n"
     ]
    }
   ],
   "source": [
    "def fit(X, Y, epochs=2000, verbose=100):\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=0.1)\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        grads = grad_fn(X, Y)  # 기울기 계산 \n",
    "        optimizer.apply_gradients(zip(grads, variables))  # 갱신 \n",
    "        \n",
    "        if(i==0) | ((i+1) % verbose == 0):\n",
    "            print('Loss at epochs {:5}: {:.5f}'.format(i+1, cost_fn(X, Y).numpy()))        \n",
    "\n",
    "fit(x_data, y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[7.4743922e-04 4.7666922e-02 9.5158565e-01]], shape=(1, 3), dtype=float32)\n",
      "tf.Tensor([2], shape=(1,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "test_data = [[2,1,3,2]] # answer_label [[0,0,1]]\n",
    "test_data = np.asarray(test_data, dtype=np.float32)\n",
    "\n",
    "a = hypothesis(test_data)\n",
    "print(a)\n",
    "print(tf.argmax(a, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[3.3713121e-08 9.8246746e-05 9.9990165e-01]\n",
      " [7.4743817e-04 4.7666889e-02 9.5158565e-01]\n",
      " [3.8566617e-10 9.7003169e-02 9.0299690e-01]\n",
      " [7.9175763e-08 9.1177320e-01 8.8226721e-02]\n",
      " [1.5831372e-01 8.3478457e-01 6.9017108e-03]\n",
      " [8.3598949e-02 9.1640097e-01 1.5503129e-07]\n",
      " [8.2878691e-01 1.7121208e-01 9.9736792e-07]\n",
      " [9.6578580e-01 3.4214135e-02 3.9437280e-09]], shape=(8, 3), dtype=float32)\n",
      "tf.Tensor([2 2 2 1 1 1 0 0], shape=(8,), dtype=int64)\n",
      "tf.Tensor([2 2 2 1 1 1 0 0], shape=(8,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "b = hypothesis(x_data)\n",
    "print(b)\n",
    "print(tf.argmax(b, 1))          # 예측값 \n",
    "print(tf.argmax(y_data, 1))     # 실제값 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
