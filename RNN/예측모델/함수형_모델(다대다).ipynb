{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 함수형 모델 (다대다)\n",
    "* 2개 이상의 컬럼이 입력되는 경우 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 사용할 패키지 불러오기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split  # 데이터 분리를 위해 사용 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터셋 생성하기\n",
    "* 2행 100 열로 된 데이터 --> 100행에 2열 데이터로 변환 \n",
    "* 학습 데이터 \n",
    "* __검증 데이터__\n",
    "* 테스트 데이터\n",
    "* 사이킷 런에 잘 구현된 __train_test_split 함수__ 를 이용해서 데이터를 효율적으로 잘라냄 \n",
    "    - test_size=0.4 : 테스트 사이즈가 40%라는 의미 (train : 60%, test : 40%)\n",
    "    - suffle : 데이터를 섞을 것인지 선택 - 일반적으로 shuffule을 사용하면 결과가 더 좋음 \n",
    "* train : val : test - 6:2:2 로 설정  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2)\n"
     ]
    }
   ],
   "source": [
    "x = np.array([range(100), range(301, 401)])\n",
    "y = np.array([range(100), range(301, 401)])\n",
    "\n",
    "x = np.transpose(x)\n",
    "y = np.transpose(y)\n",
    "\n",
    "print(x.shape)\n",
    "\n",
    "# 학습 데이터와 테스트 데이터 분리하기 \n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=66, test_size=0.4, shuffle=False)\n",
    "\n",
    "# 검증 데이터와 테스트 데이터 분리하기 \n",
    "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, random_state=66, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 모델 구성하기\n",
    "* Dense 레이어가 두 개인 다층퍼셉트론 모델. \n",
    "* 첫 번째 레이어는 5개의 뉴런을 가진 Dense 레이어\n",
    "    - 오류역전파가 용이한 relu 활성화 함수를 사용.\n",
    "* 두 번째 레이어는 3개의 뉴런을 가진 Dense 레이어 \n",
    "* 출력 레이어인 세 번째 레이어는 하나의 수치값을 예측을 하기 위해서 1개의 뉴런을 가지며, 별도의 활성화 함수는 relu를 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 5)                 15        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 18        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 16        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 10        \n",
      "=================================================================\n",
      "Total params: 59\n",
      "Trainable params: 59\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(5, input_shape = (2, ), activation ='relu'))\n",
    "model.add(Dense(3))\n",
    "model.add(Dense(4))\n",
    "model.add(Dense(2))  # 출력 2 \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 모델 학습과정 설정하기\n",
    "#### 모델 컴파일\n",
    "* 모델을 실행시키지 전에 머신이 이해할 수 있도록 컴파일 시킴\n",
    "* loss : 손실 마수는 어떤 것을 사용할 것인가? --> mse\n",
    "* optimizer : 최적화 함수는? --> adam, rmsprop\n",
    "* metrics : 어떤 방식? --> accuracy, mse(mean squared error) 적용 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 모델 학습시키기\n",
    "* epochs : 훈련 횟수\n",
    "* batch_size : 몇 개씩 끊어서 작업을 할 것인가를 의미 \n",
    "    - batch_size를 크게 잡을 경우 속도가 빨라지지만 정확도가 떨어짐\n",
    "    - 작게 잡을 경우 속도는 떨어지지만 정확도는 올라감\n",
    "* valication_data : 검증 데이터 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60 samples, validate on 20 samples\n",
      "Epoch 1/300\n",
      "60/60 [==============================] - 1s 10ms/sample - loss: 68173.3283 - mse: 68173.3281 - val_loss: 72875.3086 - val_mse: 72875.3047\n",
      "Epoch 2/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 48525.6951 - mse: 48525.6914 - val_loss: 44704.7803 - val_mse: 44704.7852\n",
      "Epoch 3/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 25968.5658 - mse: 25968.5625 - val_loss: 13657.2243 - val_mse: 13657.2246\n",
      "Epoch 4/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 6131.6491 - mse: 6131.6475 - val_loss: 621.0832 - val_mse: 621.0831\n",
      "Epoch 5/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 413.1174 - mse: 413.1174 - val_loss: 1633.9719 - val_mse: 1633.9719\n",
      "Epoch 6/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 197.8777 - mse: 197.8778 - val_loss: 1548.7928 - val_mse: 1548.7928\n",
      "Epoch 7/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 195.8207 - mse: 195.8207 - val_loss: 1489.3570 - val_mse: 1489.3572\n",
      "Epoch 8/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 199.4730 - mse: 199.4730 - val_loss: 1700.7820 - val_mse: 1700.7820\n",
      "Epoch 9/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 193.8896 - mse: 193.8896 - val_loss: 1661.5619 - val_mse: 1661.5621\n",
      "Epoch 10/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 193.1136 - mse: 193.1136 - val_loss: 1419.8876 - val_mse: 1419.8876\n",
      "Epoch 11/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 187.9042 - mse: 187.9042 - val_loss: 1071.0445 - val_mse: 1071.0447\n",
      "Epoch 12/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 184.4140 - mse: 184.4140 - val_loss: 1350.1012 - val_mse: 1350.1011\n",
      "Epoch 13/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 173.5967 - mse: 173.5967 - val_loss: 1232.1106 - val_mse: 1232.1106\n",
      "Epoch 14/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 170.4525 - mse: 170.4525 - val_loss: 1270.0068 - val_mse: 1270.0068\n",
      "Epoch 15/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 169.3663 - mse: 169.3663 - val_loss: 1448.0454 - val_mse: 1448.0455\n",
      "Epoch 16/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 163.4786 - mse: 163.4786 - val_loss: 1349.4401 - val_mse: 1349.4399\n",
      "Epoch 17/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 167.7829 - mse: 167.7829 - val_loss: 1151.7738 - val_mse: 1151.7739\n",
      "Epoch 18/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 156.3411 - mse: 156.3411 - val_loss: 1230.8819 - val_mse: 1230.8820\n",
      "Epoch 19/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 165.9197 - mse: 165.9197 - val_loss: 1232.3789 - val_mse: 1232.3789\n",
      "Epoch 20/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 148.4305 - mse: 148.4305 - val_loss: 1176.6761 - val_mse: 1176.6761\n",
      "Epoch 21/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 141.6821 - mse: 141.6821 - val_loss: 1294.5869 - val_mse: 1294.5870\n",
      "Epoch 22/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 140.4783 - mse: 140.4783 - val_loss: 859.3451 - val_mse: 859.3451\n",
      "Epoch 23/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 131.5433 - mse: 131.5433 - val_loss: 1330.4007 - val_mse: 1330.4006\n",
      "Epoch 24/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 137.2844 - mse: 137.2844 - val_loss: 1196.5421 - val_mse: 1196.5421\n",
      "Epoch 25/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 132.7792 - mse: 132.7792 - val_loss: 989.9502 - val_mse: 989.9502\n",
      "Epoch 26/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 125.1048 - mse: 125.1049 - val_loss: 1065.4644 - val_mse: 1065.4645\n",
      "Epoch 27/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 123.9274 - mse: 123.9274 - val_loss: 866.3855 - val_mse: 866.3854\n",
      "Epoch 28/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 121.3007 - mse: 121.3007 - val_loss: 849.6849 - val_mse: 849.6849\n",
      "Epoch 29/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 117.6439 - mse: 117.6439 - val_loss: 775.9575 - val_mse: 775.9574\n",
      "Epoch 30/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 112.0946 - mse: 112.0946 - val_loss: 723.7494 - val_mse: 723.7494\n",
      "Epoch 31/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 113.1325 - mse: 113.1325 - val_loss: 906.8376 - val_mse: 906.8375\n",
      "Epoch 32/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 105.0149 - mse: 105.0149 - val_loss: 921.4879 - val_mse: 921.4879\n",
      "Epoch 33/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 108.3865 - mse: 108.3865 - val_loss: 980.5769 - val_mse: 980.5770\n",
      "Epoch 34/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 99.8822 - mse: 99.8822 - val_loss: 1222.9975 - val_mse: 1222.9976\n",
      "Epoch 35/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 105.7942 - mse: 105.7941 - val_loss: 901.4753 - val_mse: 901.4753\n",
      "Epoch 36/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 95.8898 - mse: 95.8897 - val_loss: 963.7785 - val_mse: 963.7784\n",
      "Epoch 37/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 91.3309 - mse: 91.3309 - val_loss: 548.6611 - val_mse: 548.6611\n",
      "Epoch 38/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 91.1070 - mse: 91.1071 - val_loss: 545.4098 - val_mse: 545.4098\n",
      "Epoch 39/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 87.7764 - mse: 87.7764 - val_loss: 992.9200 - val_mse: 992.9199\n",
      "Epoch 40/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 90.2352 - mse: 90.2352 - val_loss: 720.7310 - val_mse: 720.7310\n",
      "Epoch 41/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 80.2911 - mse: 80.2912 - val_loss: 731.2132 - val_mse: 731.2132\n",
      "Epoch 42/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 87.5017 - mse: 87.5017 - val_loss: 537.4151 - val_mse: 537.4152\n",
      "Epoch 43/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 73.7412 - mse: 73.7412 - val_loss: 716.3456 - val_mse: 716.3456\n",
      "Epoch 44/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 73.1447 - mse: 73.1448 - val_loss: 467.2865 - val_mse: 467.2865\n",
      "Epoch 45/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 73.2389 - mse: 73.2389 - val_loss: 437.7422 - val_mse: 437.7422\n",
      "Epoch 46/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 71.6839 - mse: 71.6839 - val_loss: 486.7784 - val_mse: 486.7784\n",
      "Epoch 47/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 65.8560 - mse: 65.8560 - val_loss: 553.4815 - val_mse: 553.4815\n",
      "Epoch 48/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 63.3370 - mse: 63.3370 - val_loss: 490.9617 - val_mse: 490.9618\n",
      "Epoch 49/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 61.9409 - mse: 61.9409 - val_loss: 519.6983 - val_mse: 519.6982\n",
      "Epoch 50/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 64.5077 - mse: 64.5077 - val_loss: 530.3438 - val_mse: 530.3439\n",
      "Epoch 51/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 56.6763 - mse: 56.6763 - val_loss: 472.5217 - val_mse: 472.5217\n",
      "Epoch 52/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 57.0814 - mse: 57.0814 - val_loss: 471.9871 - val_mse: 471.9872\n",
      "Epoch 53/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 51.0304 - mse: 51.0304 - val_loss: 418.9791 - val_mse: 418.9792\n",
      "Epoch 54/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 49.9459 - mse: 49.9459 - val_loss: 325.0043 - val_mse: 325.0044\n",
      "Epoch 55/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 47.6722 - mse: 47.6722 - val_loss: 362.7975 - val_mse: 362.7975\n",
      "Epoch 56/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 45.8810 - mse: 45.8810 - val_loss: 452.7557 - val_mse: 452.7557\n",
      "Epoch 57/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 42.2231 - mse: 42.2231 - val_loss: 333.3358 - val_mse: 333.3358\n",
      "Epoch 58/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 2ms/sample - loss: 39.7173 - mse: 39.7173 - val_loss: 277.6381 - val_mse: 277.6381\n",
      "Epoch 59/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 36.5572 - mse: 36.5572 - val_loss: 345.9964 - val_mse: 345.9964\n",
      "Epoch 60/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 36.9708 - mse: 36.9708 - val_loss: 174.7135 - val_mse: 174.7135\n",
      "Epoch 61/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 33.0412 - mse: 33.0412 - val_loss: 246.7397 - val_mse: 246.7397\n",
      "Epoch 62/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 32.6189 - mse: 32.6189 - val_loss: 266.4210 - val_mse: 266.4210\n",
      "Epoch 63/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 27.4301 - mse: 27.4301 - val_loss: 138.1015 - val_mse: 138.1015\n",
      "Epoch 64/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 27.5184 - mse: 27.5184 - val_loss: 190.5909 - val_mse: 190.5909\n",
      "Epoch 65/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 23.5372 - mse: 23.5372 - val_loss: 126.7940 - val_mse: 126.7940\n",
      "Epoch 66/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 22.6490 - mse: 22.6490 - val_loss: 162.7040 - val_mse: 162.7040\n",
      "Epoch 67/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 18.5455 - mse: 18.5455 - val_loss: 126.0093 - val_mse: 126.0093\n",
      "Epoch 68/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 17.0552 - mse: 17.0552 - val_loss: 140.7472 - val_mse: 140.7472\n",
      "Epoch 69/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 15.9101 - mse: 15.9101 - val_loss: 93.4134 - val_mse: 93.4134\n",
      "Epoch 70/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 13.7096 - mse: 13.7096 - val_loss: 109.9750 - val_mse: 109.9750\n",
      "Epoch 71/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 11.8923 - mse: 11.8923 - val_loss: 116.3442 - val_mse: 116.3442\n",
      "Epoch 72/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 11.1882 - mse: 11.1882 - val_loss: 115.6102 - val_mse: 115.6102\n",
      "Epoch 73/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 9.8665 - mse: 9.8665 - val_loss: 43.9491 - val_mse: 43.9491\n",
      "Epoch 74/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 6.6238 - mse: 6.6238 - val_loss: 31.5470 - val_mse: 31.5470\n",
      "Epoch 75/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 6.6689 - mse: 6.6689 - val_loss: 59.6913 - val_mse: 59.6913\n",
      "Epoch 76/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 5.3124 - mse: 5.3124 - val_loss: 28.1688 - val_mse: 28.1688\n",
      "Epoch 77/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 3.9757 - mse: 3.9757 - val_loss: 29.5399 - val_mse: 29.5399\n",
      "Epoch 78/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 3.1876 - mse: 3.1876 - val_loss: 19.2684 - val_mse: 19.2684\n",
      "Epoch 79/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 2.4717 - mse: 2.4717 - val_loss: 14.6903 - val_mse: 14.6903\n",
      "Epoch 80/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 2.1461 - mse: 2.1461 - val_loss: 13.2406 - val_mse: 13.2406\n",
      "Epoch 81/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 1.5289 - mse: 1.5289 - val_loss: 5.1257 - val_mse: 5.1257\n",
      "Epoch 82/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 1.1998 - mse: 1.1998 - val_loss: 11.6026 - val_mse: 11.6026\n",
      "Epoch 83/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 1.0066 - mse: 1.0066 - val_loss: 7.7231 - val_mse: 7.7231\n",
      "Epoch 84/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 0.6816 - mse: 0.6816 - val_loss: 4.4496 - val_mse: 4.4496\n",
      "Epoch 85/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 0.5322 - mse: 0.5322 - val_loss: 3.8462 - val_mse: 3.8462\n",
      "Epoch 86/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 0.4641 - mse: 0.4641 - val_loss: 3.8890 - val_mse: 3.8890\n",
      "Epoch 87/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 0.2967 - mse: 0.2967 - val_loss: 1.1227 - val_mse: 1.1227\n",
      "Epoch 88/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 0.2032 - mse: 0.2032 - val_loss: 1.0168 - val_mse: 1.0168\n",
      "Epoch 89/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 0.1122 - mse: 0.1122 - val_loss: 0.7954 - val_mse: 0.7954\n",
      "Epoch 90/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 0.0842 - mse: 0.0842 - val_loss: 0.8109 - val_mse: 0.8109\n",
      "Epoch 91/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 0.0461 - mse: 0.0461 - val_loss: 0.6002 - val_mse: 0.6002\n",
      "Epoch 92/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 0.0329 - mse: 0.0329 - val_loss: 0.3147 - val_mse: 0.3147\n",
      "Epoch 93/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 0.0263 - mse: 0.0263 - val_loss: 0.1906 - val_mse: 0.1906\n",
      "Epoch 94/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0749 - val_mse: 0.0749\n",
      "Epoch 95/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 0.0113 - mse: 0.0113 - val_loss: 0.0660 - val_mse: 0.0660\n",
      "Epoch 96/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0322 - val_mse: 0.0322\n",
      "Epoch 97/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 0.0036 - mse: 0.0036 - val_loss: 0.0235 - val_mse: 0.0235\n",
      "Epoch 98/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 99/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0066 - val_mse: 0.0066\n",
      "Epoch 100/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 5.9359e-04 - mse: 5.9359e-04 - val_loss: 0.0065 - val_mse: 0.0065\n",
      "Epoch 101/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 4.9789e-04 - mse: 4.9789e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Epoch 102/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 2.4256e-04 - mse: 2.4256e-04 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 103/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 1.5185e-04 - mse: 1.5185e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 104/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 6.3595e-05 - mse: 6.3595e-05 - val_loss: 2.4547e-04 - val_mse: 2.4547e-04\n",
      "Epoch 105/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 4.4701e-05 - mse: 4.4701e-05 - val_loss: 1.4796e-04 - val_mse: 1.4796e-04\n",
      "Epoch 106/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 1.9095e-05 - mse: 1.9095e-05 - val_loss: 3.3989e-05 - val_mse: 3.3989e-05\n",
      "Epoch 107/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 9.3311e-06 - mse: 9.3311e-06 - val_loss: 6.5207e-05 - val_mse: 6.5207e-05\n",
      "Epoch 108/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 6.0488e-06 - mse: 6.0488e-06 - val_loss: 1.8615e-05 - val_mse: 1.8615e-05\n",
      "Epoch 109/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 2.6629e-06 - mse: 2.6629e-06 - val_loss: 1.1374e-05 - val_mse: 1.1374e-05\n",
      "Epoch 110/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 1.3841e-06 - mse: 1.3841e-06 - val_loss: 9.9518e-06 - val_mse: 9.9518e-06\n",
      "Epoch 111/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 6.0380e-07 - mse: 6.0380e-07 - val_loss: 2.2815e-06 - val_mse: 2.2815e-06\n",
      "Epoch 112/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 2.8999e-07 - mse: 2.8999e-07 - val_loss: 1.6430e-06 - val_mse: 1.6430e-06\n",
      "Epoch 113/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 1.6720e-07 - mse: 1.6720e-07 - val_loss: 5.4965e-07 - val_mse: 5.4965e-07\n",
      "Epoch 114/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 4.7308e-08 - mse: 4.7308e-08 - val_loss: 2.9612e-07 - val_mse: 2.9612e-07\n",
      "Epoch 115/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 2.2142e-08 - mse: 2.2142e-08 - val_loss: 1.4619e-07 - val_mse: 1.4619e-07\n",
      "Epoch 116/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 2ms/sample - loss: 1.9148e-08 - mse: 1.9148e-08 - val_loss: 2.9615e-08 - val_mse: 2.9615e-08\n",
      "Epoch 117/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 5.7390e-09 - mse: 5.7390e-09 - val_loss: 2.1661e-08 - val_mse: 2.1661e-08\n",
      "Epoch 118/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 3.8725e-09 - mse: 3.8725e-09 - val_loss: 4.2419e-08 - val_mse: 4.2419e-08\n",
      "Epoch 119/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 3.1945e-09 - mse: 3.1945e-09 - val_loss: 5.8950e-09 - val_mse: 5.8950e-09\n",
      "Epoch 120/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 4.7792e-09 - mse: 4.7792e-09 - val_loss: 1.1456e-08 - val_mse: 1.1456e-08\n",
      "Epoch 121/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 1.7024e-09 - mse: 1.7024e-09 - val_loss: 1.1801e-08 - val_mse: 1.1801e-08\n",
      "Epoch 122/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 1.5973e-09 - mse: 1.5973e-09 - val_loss: 1.1684e-08 - val_mse: 1.1684e-08\n",
      "Epoch 123/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 1.1781e-09 - mse: 1.1781e-09 - val_loss: 1.0748e-08 - val_mse: 1.0748e-08\n",
      "Epoch 124/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 1.0860e-09 - mse: 1.0860e-09 - val_loss: 6.0743e-09 - val_mse: 6.0743e-09\n",
      "Epoch 125/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 9.3084e-10 - mse: 9.3084e-10 - val_loss: 9.0775e-09 - val_mse: 9.0775e-09\n",
      "Epoch 126/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 9.9689e-10 - mse: 9.9689e-10 - val_loss: 4.4609e-09 - val_mse: 4.4609e-09\n",
      "Epoch 127/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 8.4567e-10 - mse: 8.4567e-10 - val_loss: 6.8823e-09 - val_mse: 6.8823e-09\n",
      "Epoch 128/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 8.6070e-10 - mse: 8.6070e-10 - val_loss: 4.2761e-09 - val_mse: 4.2761e-09\n",
      "Epoch 129/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 8.0985e-10 - mse: 8.0985e-10 - val_loss: 3.8221e-09 - val_mse: 3.8221e-09\n",
      "Epoch 130/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 6.6138e-10 - mse: 6.6138e-10 - val_loss: 3.4030e-09 - val_mse: 3.4030e-09\n",
      "Epoch 131/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 6.4018e-10 - mse: 6.4018e-10 - val_loss: 4.5857e-09 - val_mse: 4.5857e-09\n",
      "Epoch 132/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 6.5587e-10 - mse: 6.5587e-10 - val_loss: 4.6148e-09 - val_mse: 4.6148e-09\n",
      "Epoch 133/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 5.7923e-10 - mse: 5.7923e-10 - val_loss: 3.6765e-09 - val_mse: 3.6765e-09\n",
      "Epoch 134/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 5.0390e-10 - mse: 5.0390e-10 - val_loss: 2.7248e-09 - val_mse: 2.7248e-09\n",
      "Epoch 135/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 3.8700e-10 - mse: 3.8700e-10 - val_loss: 2.0464e-09 - val_mse: 2.0464e-09\n",
      "Epoch 136/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 3.6318e-10 - mse: 3.6318e-10 - val_loss: 2.8776e-09 - val_mse: 2.8776e-09\n",
      "Epoch 137/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 4.1160e-10 - mse: 4.1160e-10 - val_loss: 1.4916e-09 - val_mse: 1.4916e-09\n",
      "Epoch 138/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 3.3017e-10 - mse: 3.3017e-10 - val_loss: 1.8965e-09 - val_mse: 1.8965e-09\n",
      "Epoch 139/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 3.8410e-10 - mse: 3.8410e-10 - val_loss: 1.3999e-09 - val_mse: 1.3999e-09\n",
      "Epoch 140/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 3.7485e-10 - mse: 3.7485e-10 - val_loss: 1.4174e-09 - val_mse: 1.4174e-09\n",
      "Epoch 141/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 3.9814e-10 - mse: 3.9814e-10 - val_loss: 1.8481e-09 - val_mse: 1.8481e-09\n",
      "Epoch 142/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 4.0337e-10 - mse: 4.0337e-10 - val_loss: 1.1605e-09 - val_mse: 1.1605e-09\n",
      "Epoch 143/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 3.8557e-10 - mse: 3.8557e-10 - val_loss: 1.0106e-09 - val_mse: 1.0106e-09\n",
      "Epoch 144/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 3.0585e-10 - mse: 3.0585e-10 - val_loss: 1.3333e-09 - val_mse: 1.3333e-09\n",
      "Epoch 145/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 3.1047e-10 - mse: 3.1047e-10 - val_loss: 1.5461e-09 - val_mse: 1.5461e-09\n",
      "Epoch 146/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 3.0979e-10 - mse: 3.0979e-10 - val_loss: 1.3773e-09 - val_mse: 1.3773e-09\n",
      "Epoch 147/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 3.7801e-10 - mse: 3.7801e-10 - val_loss: 1.2609e-09 - val_mse: 1.2609e-09\n",
      "Epoch 148/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 2.8898e-10 - mse: 2.8898e-10 - val_loss: 9.1604e-10 - val_mse: 9.1604e-10\n",
      "Epoch 149/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 2.7306e-10 - mse: 2.7306e-10 - val_loss: 1.0034e-09 - val_mse: 1.0034e-09\n",
      "Epoch 150/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 2.6184e-10 - mse: 2.6184e-10 - val_loss: 8.8949e-10 - val_mse: 8.8949e-10\n",
      "Epoch 151/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 2.8535e-10 - mse: 2.8535e-10 - val_loss: 5.2714e-10 - val_mse: 5.2714e-10\n",
      "Epoch 152/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 2.8719e-10 - mse: 2.8719e-10 - val_loss: 6.0136e-10 - val_mse: 6.0136e-10\n",
      "Epoch 153/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 2.3420e-10 - mse: 2.3420e-10 - val_loss: 7.7453e-10 - val_mse: 7.7453e-10\n",
      "Epoch 154/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 2.5502e-10 - mse: 2.5502e-10 - val_loss: 8.3564e-10 - val_mse: 8.3564e-10\n",
      "Epoch 155/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 2.3354e-10 - mse: 2.3354e-10 - val_loss: 6.5520e-10 - val_mse: 6.5520e-10\n",
      "Epoch 156/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 2.2214e-10 - mse: 2.2214e-10 - val_loss: 3.7289e-10 - val_mse: 3.7289e-10\n",
      "Epoch 157/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 2.7640e-10 - mse: 2.7640e-10 - val_loss: 5.1950e-10 - val_mse: 5.1950e-10\n",
      "Epoch 158/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 2.0203e-10 - mse: 2.0203e-10 - val_loss: 4.7330e-10 - val_mse: 4.7330e-10\n",
      "Epoch 159/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 2.2754e-10 - mse: 2.2754e-10 - val_loss: 5.2569e-10 - val_mse: 5.2569e-10\n",
      "Epoch 160/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 2.2817e-10 - mse: 2.2817e-10 - val_loss: 8.0363e-10 - val_mse: 8.0363e-10\n",
      "Epoch 161/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 2.6643e-10 - mse: 2.6643e-10 - val_loss: 5.6971e-10 - val_mse: 5.6971e-10\n",
      "Epoch 162/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 2.7033e-10 - mse: 2.7033e-10 - val_loss: 5.4933e-10 - val_mse: 5.4933e-10\n",
      "Epoch 163/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 1.8863e-10 - mse: 1.8863e-10 - val_loss: 4.8385e-10 - val_mse: 4.8385e-10\n",
      "Epoch 164/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 3.1715e-10 - mse: 3.1715e-10 - val_loss: 3.3397e-10 - val_mse: 3.3397e-10\n",
      "Epoch 165/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 3.4800e-10 - mse: 3.4800e-10 - val_loss: 3.9945e-10 - val_mse: 3.9945e-10\n",
      "Epoch 166/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 4.5791e-10 - mse: 4.5791e-10 - val_loss: 5.7917e-10 - val_mse: 5.7917e-10\n",
      "Epoch 167/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 2.8274e-10 - mse: 2.8274e-10 - val_loss: 1.6480e-10 - val_mse: 1.6480e-10\n",
      "Epoch 168/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 3.9177e-10 - mse: 3.9177e-10 - val_loss: 4.5911e-10 - val_mse: 4.5911e-10\n",
      "Epoch 169/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 5.2215e-10 - mse: 5.2215e-10 - val_loss: 9.7680e-10 - val_mse: 9.7680e-10\n",
      "Epoch 170/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 2ms/sample - loss: 6.4688e-10 - mse: 6.4688e-10 - val_loss: 6.4541e-09 - val_mse: 6.4541e-09\n",
      "Epoch 171/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 9.3924e-10 - mse: 9.3924e-10 - val_loss: 2.7332e-09 - val_mse: 2.7332e-09\n",
      "Epoch 172/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 1.0702e-09 - mse: 1.0702e-09 - val_loss: 1.2609e-09 - val_mse: 1.2609e-09\n",
      "Epoch 173/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 6.0701e-10 - mse: 6.0701e-10 - val_loss: 1.5374e-09 - val_mse: 1.5374e-09\n",
      "Epoch 174/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 1.1571e-09 - mse: 1.1571e-09 - val_loss: 8.4583e-10 - val_mse: 8.4583e-10\n",
      "Epoch 175/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 8.9343e-10 - mse: 8.9343e-10 - val_loss: 5.4933e-10 - val_mse: 5.4933e-10\n",
      "Epoch 176/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 1.0148e-09 - mse: 1.0148e-09 - val_loss: 6.3596e-09 - val_mse: 6.3596e-09\n",
      "Epoch 177/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 7.4175e-10 - mse: 7.4175e-10 - val_loss: 3.7071e-09 - val_mse: 3.7071e-09\n",
      "Epoch 178/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 1.9929e-09 - mse: 1.9929e-09 - val_loss: 2.9977e-10 - val_mse: 2.9977e-10\n",
      "Epoch 179/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 8.9698e-10 - mse: 8.9698e-10 - val_loss: 4.9185e-10 - val_mse: 4.9185e-10\n",
      "Epoch 180/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 8.3682e-10 - mse: 8.3682e-10 - val_loss: 6.0572e-10 - val_mse: 6.0572e-10\n",
      "Epoch 181/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 2.9455e-09 - mse: 2.9455e-09 - val_loss: 5.6247e-09 - val_mse: 5.6247e-09\n",
      "Epoch 182/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 3.9201e-09 - mse: 3.9201e-09 - val_loss: 9.0968e-09 - val_mse: 9.0968e-09\n",
      "Epoch 183/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 4.7835e-09 - mse: 4.7835e-09 - val_loss: 9.1226e-09 - val_mse: 9.1226e-09\n",
      "Epoch 184/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 2.3596e-09 - mse: 2.3596e-09 - val_loss: 9.2696e-10 - val_mse: 9.2696e-10\n",
      "Epoch 185/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 1.5225e-09 - mse: 1.5225e-09 - val_loss: 2.7303e-09 - val_mse: 2.7303e-09\n",
      "Epoch 186/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 3.4942e-09 - mse: 3.4942e-09 - val_loss: 2.4881e-08 - val_mse: 2.4881e-08\n",
      "Epoch 187/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 7.0933e-09 - mse: 7.0933e-09 - val_loss: 2.0400e-08 - val_mse: 2.0400e-08\n",
      "Epoch 188/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 2.9346e-09 - mse: 2.9346e-09 - val_loss: 1.9587e-09 - val_mse: 1.9587e-09\n",
      "Epoch 189/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 3.2139e-09 - mse: 3.2139e-09 - val_loss: 1.3807e-08 - val_mse: 1.3807e-08\n",
      "Epoch 190/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 2.0057e-09 - mse: 2.0057e-09 - val_loss: 2.7205e-09 - val_mse: 2.7205e-09\n",
      "Epoch 191/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 2.0824e-09 - mse: 2.0824e-09 - val_loss: 3.8308e-10 - val_mse: 3.8308e-10\n",
      "Epoch 192/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 3.8693e-09 - mse: 3.8693e-09 - val_loss: 6.5666e-09 - val_mse: 6.5666e-09\n",
      "Epoch 193/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 2.0193e-08 - mse: 2.0193e-08 - val_loss: 3.4634e-08 - val_mse: 3.4634e-08\n",
      "Epoch 194/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 1.2391e-08 - mse: 1.2391e-08 - val_loss: 1.0891e-08 - val_mse: 1.0891e-08\n",
      "Epoch 195/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 5.2600e-09 - mse: 5.2600e-09 - val_loss: 5.2489e-09 - val_mse: 5.2489e-09\n",
      "Epoch 196/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 3.6277e-09 - mse: 3.6277e-09 - val_loss: 6.6706e-09 - val_mse: 6.6706e-09\n",
      "Epoch 197/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 6.3364e-09 - mse: 6.3364e-09 - val_loss: 1.2980e-09 - val_mse: 1.2980e-09\n",
      "Epoch 198/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 1.0815e-08 - mse: 1.0815e-08 - val_loss: 1.5157e-08 - val_mse: 1.5157e-08\n",
      "Epoch 199/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 4.8443e-08 - mse: 4.8443e-08 - val_loss: 5.4173e-07 - val_mse: 5.4173e-07\n",
      "Epoch 200/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 9.0293e-08 - mse: 9.0293e-08 - val_loss: 3.0621e-09 - val_mse: 3.0621e-09\n",
      "Epoch 201/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 1.3630e-06 - mse: 1.3630e-06 - val_loss: 3.2596e-06 - val_mse: 3.2596e-06\n",
      "Epoch 202/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 1.4029e-06 - mse: 1.4029e-06 - val_loss: 4.9179e-07 - val_mse: 4.9179e-07\n",
      "Epoch 203/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 2.0921e-06 - mse: 2.0921e-06 - val_loss: 1.9163e-06 - val_mse: 1.9163e-06\n",
      "Epoch 204/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 1.0596e-06 - mse: 1.0596e-06 - val_loss: 4.1029e-06 - val_mse: 4.1029e-06\n",
      "Epoch 205/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 3.9807e-07 - mse: 3.9807e-07 - val_loss: 2.4920e-09 - val_mse: 2.4920e-09\n",
      "Epoch 206/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 1.8784e-07 - mse: 1.8784e-07 - val_loss: 4.7146e-07 - val_mse: 4.7146e-07\n",
      "Epoch 207/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 7.8320e-06 - mse: 7.8320e-06 - val_loss: 1.7860e-05 - val_mse: 1.7860e-05\n",
      "Epoch 208/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 1.7263e-05 - mse: 1.7263e-05 - val_loss: 1.8907e-06 - val_mse: 1.8907e-06\n",
      "Epoch 209/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 4.5013e-05 - mse: 4.5013e-05 - val_loss: 5.8313e-05 - val_mse: 5.8313e-05\n",
      "Epoch 210/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 1.8857e-04 - mse: 1.8857e-04 - val_loss: 7.4899e-05 - val_mse: 7.4899e-05\n",
      "Epoch 211/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 1.3033e-04 - mse: 1.3033e-04 - val_loss: 2.7396e-04 - val_mse: 2.7396e-04\n",
      "Epoch 212/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 8.6787e-04 - mse: 8.6787e-04 - val_loss: 4.0250e-06 - val_mse: 4.0250e-06\n",
      "Epoch 213/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 0.0240 - mse: 0.0240 - val_loss: 0.1103 - val_mse: 0.1103\n",
      "Epoch 214/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 0.1407 - mse: 0.1407 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 215/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 0.0483 - mse: 0.0483 - val_loss: 0.1679 - val_mse: 0.1679\n",
      "Epoch 216/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 0.0276 - mse: 0.0276 - val_loss: 0.0422 - val_mse: 0.0422\n",
      "Epoch 217/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 218/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 4.8433e-04 - mse: 4.8433e-04 - val_loss: 2.7662e-05 - val_mse: 2.7662e-05\n",
      "Epoch 219/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 3.2368e-04 - mse: 3.2368e-04 - val_loss: 1.1760e-04 - val_mse: 1.1760e-04\n",
      "Epoch 220/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 2.9073e-05 - mse: 2.9073e-05 - val_loss: 5.3612e-06 - val_mse: 5.3612e-06\n",
      "Epoch 221/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 7.1773e-06 - mse: 7.1773e-06 - val_loss: 1.8868e-07 - val_mse: 1.8868e-07\n",
      "Epoch 222/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 9.6617e-07 - mse: 9.6617e-07 - val_loss: 1.4247e-06 - val_mse: 1.4247e-06\n",
      "Epoch 223/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 3.3360e-07 - mse: 3.3360e-07 - val_loss: 1.7726e-07 - val_mse: 1.7726e-07\n",
      "Epoch 224/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 4.1091e-08 - mse: 4.1091e-08 - val_loss: 8.1521e-08 - val_mse: 8.1521e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 3.0231e-07 - mse: 3.0231e-07 - val_loss: 2.7716e-08 - val_mse: 2.7716e-08\n",
      "Epoch 226/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 5.4878e-08 - mse: 5.4878e-08 - val_loss: 2.9810e-09 - val_mse: 2.9810e-09\n",
      "Epoch 227/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 7.0286e-08 - mse: 7.0286e-08 - val_loss: 9.3984e-08 - val_mse: 9.3984e-08\n",
      "Epoch 228/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 1.0125e-06 - mse: 1.0125e-06 - val_loss: 1.2189e-07 - val_mse: 1.2189e-07\n",
      "Epoch 229/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 1.8093e-06 - mse: 1.8093e-06 - val_loss: 2.3423e-06 - val_mse: 2.3423e-06\n",
      "Epoch 230/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 2.8837e-06 - mse: 2.8837e-06 - val_loss: 7.6646e-06 - val_mse: 7.6646e-06\n",
      "Epoch 231/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 1.1257e-05 - mse: 1.1257e-05 - val_loss: 4.8627e-07 - val_mse: 4.8627e-07\n",
      "Epoch 232/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 1.4667e-05 - mse: 1.4667e-05 - val_loss: 1.6399e-05 - val_mse: 1.6399e-05\n",
      "Epoch 233/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 1.4595e-04 - mse: 1.4595e-04 - val_loss: 4.5720e-04 - val_mse: 4.5720e-04\n",
      "Epoch 234/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0332 - val_mse: 0.0332\n",
      "Epoch 235/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 0.0247 - mse: 0.0247 - val_loss: 0.0609 - val_mse: 0.0609\n",
      "Epoch 236/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 0.2571 - mse: 0.2571 - val_loss: 2.0251 - val_mse: 2.0251\n",
      "Epoch 237/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 0.2406 - mse: 0.2406 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 238/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 0.0043 - mse: 0.0043 - val_loss: 8.3121e-04 - val_mse: 8.3121e-04\n",
      "Epoch 239/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 0.0786 - mse: 0.0786 - val_loss: 0.1458 - val_mse: 0.1458\n",
      "Epoch 240/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 0.0365 - mse: 0.0365 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 241/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0301 - val_mse: 0.0301\n",
      "Epoch 242/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0251 - val_mse: 0.0251\n",
      "Epoch 243/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0072 - val_mse: 0.0072\n",
      "Epoch 244/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 0.0052 - mse: 0.0052 - val_loss: 9.4466e-04 - val_mse: 9.4466e-04\n",
      "Epoch 245/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 0.0012 - mse: 0.0012 - val_loss: 7.2441e-05 - val_mse: 7.2441e-05\n",
      "Epoch 246/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 2.4198e-05 - mse: 2.4198e-05 - val_loss: 9.8261e-06 - val_mse: 9.8261e-06\n",
      "Epoch 247/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 1.7364e-06 - mse: 1.7364e-06 - val_loss: 9.0337e-07 - val_mse: 9.0337e-07\n",
      "Epoch 248/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 5.2031e-08 - mse: 5.2031e-08 - val_loss: 6.5711e-08 - val_mse: 6.5711e-08\n",
      "Epoch 249/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 2.6062e-08 - mse: 2.6062e-08 - val_loss: 6.6539e-10 - val_mse: 6.6539e-10\n",
      "Epoch 250/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 2.7246e-08 - mse: 2.7246e-08 - val_loss: 4.2655e-09 - val_mse: 4.2655e-09\n",
      "Epoch 251/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 2.1194e-08 - mse: 2.1194e-08 - val_loss: 2.0890e-08 - val_mse: 2.0890e-08\n",
      "Epoch 252/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 4.1536e-08 - mse: 4.1536e-08 - val_loss: 7.2640e-08 - val_mse: 7.2640e-08\n",
      "Epoch 253/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 2.3260e-07 - mse: 2.3260e-07 - val_loss: 1.0494e-08 - val_mse: 1.0494e-08\n",
      "Epoch 254/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 1.9085e-07 - mse: 1.9085e-07 - val_loss: 1.4106e-06 - val_mse: 1.4106e-06\n",
      "Epoch 255/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 2.4289e-05 - mse: 2.4289e-05 - val_loss: 8.3185e-05 - val_mse: 8.3185e-05\n",
      "Epoch 256/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 1.3001e-04 - mse: 1.3001e-04 - val_loss: 6.7225e-04 - val_mse: 6.7225e-04\n",
      "Epoch 257/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 4.1668e-05 - mse: 4.1668e-05 - val_loss: 9.4766e-06 - val_mse: 9.4766e-06\n",
      "Epoch 258/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 1.7173e-04 - mse: 1.7173e-04 - val_loss: 5.3813e-06 - val_mse: 5.3813e-06\n",
      "Epoch 259/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 1.7503e-04 - mse: 1.7503e-04 - val_loss: 2.7660e-05 - val_mse: 2.7660e-05\n",
      "Epoch 260/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 3.6724e-04 - mse: 3.6724e-04 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "Epoch 261/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 0.0018 - mse: 0.0018 - val_loss: 7.2723e-04 - val_mse: 7.2723e-04\n",
      "Epoch 262/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0292 - val_mse: 0.0292\n",
      "Epoch 263/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 0.2920 - mse: 0.2920 - val_loss: 1.9478 - val_mse: 1.9478\n",
      "Epoch 264/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 0.1195 - mse: 0.1195 - val_loss: 0.1204 - val_mse: 0.1204\n",
      "Epoch 265/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 0.0251 - mse: 0.0251 - val_loss: 0.0250 - val_mse: 0.0250\n",
      "Epoch 266/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 267/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 6.4069e-04 - mse: 6.4069e-04 - val_loss: 6.6170e-07 - val_mse: 6.6170e-07\n",
      "Epoch 268/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 6.8269e-05 - mse: 6.8269e-05 - val_loss: 5.0151e-06 - val_mse: 5.0151e-06\n",
      "Epoch 269/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 2.1270e-05 - mse: 2.1270e-05 - val_loss: 3.0057e-05 - val_mse: 3.0057e-05\n",
      "Epoch 270/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 6.0790e-06 - mse: 6.0790e-06 - val_loss: 1.5763e-05 - val_mse: 1.5763e-05\n",
      "Epoch 271/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 1.7710e-05 - mse: 1.7710e-05 - val_loss: 3.5460e-04 - val_mse: 3.5460e-04\n",
      "Epoch 272/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 1.7423e-04 - mse: 1.7423e-04 - val_loss: 3.0259e-05 - val_mse: 3.0259e-05\n",
      "Epoch 273/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 9.3264e-05 - mse: 9.3264e-05 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Epoch 274/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0250 - val_mse: 0.0250\n",
      "Epoch 275/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 0.0073 - mse: 0.0073 - val_loss: 4.7543e-04 - val_mse: 4.7543e-04\n",
      "Epoch 276/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 4.7631e-04 - mse: 4.7631e-04 - val_loss: 8.2872e-06 - val_mse: 8.2872e-06\n",
      "Epoch 277/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 3.9729e-06 - mse: 3.9729e-06 - val_loss: 5.0241e-08 - val_mse: 5.0241e-08\n",
      "Epoch 278/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 4.9635e-07 - mse: 4.9635e-07 - val_loss: 1.6921e-07 - val_mse: 1.6921e-07\n",
      "Epoch 279/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 3.1138e-07 - mse: 3.1138e-07 - val_loss: 3.8242e-09 - val_mse: 3.8242e-09\n",
      "Epoch 280/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 1.0618e-07 - mse: 1.0618e-07 - val_loss: 3.1572e-07 - val_mse: 3.1572e-07\n",
      "Epoch 281/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 2ms/sample - loss: 2.9283e-07 - mse: 2.9283e-07 - val_loss: 4.4654e-07 - val_mse: 4.4654e-07\n",
      "Epoch 282/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 7.7555e-07 - mse: 7.7555e-07 - val_loss: 2.9080e-06 - val_mse: 2.9080e-06\n",
      "Epoch 283/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 1.7649e-04 - mse: 1.7649e-04 - val_loss: 0.0021 - val_mse: 0.0021\n",
      "Epoch 284/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0724 - val_mse: 0.0724\n",
      "Epoch 285/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 0.0077 - mse: 0.0077 - val_loss: 4.8345e-04 - val_mse: 4.8345e-04\n",
      "Epoch 286/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 0.1020 - mse: 0.1020 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 287/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0059 - val_mse: 0.0059\n",
      "Epoch 288/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0124 - val_mse: 0.0124\n",
      "Epoch 289/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0102 - val_mse: 0.0102\n",
      "Epoch 290/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 0.0037 - mse: 0.0037 - val_loss: 6.3718e-05 - val_mse: 6.3718e-05\n",
      "Epoch 291/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 2.2440e-04 - mse: 2.2440e-04 - val_loss: 2.7141e-04 - val_mse: 2.7141e-04\n",
      "Epoch 292/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 0.0012 - mse: 0.0012 - val_loss: 6.0167e-05 - val_mse: 6.0167e-05\n",
      "Epoch 293/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 0.0321 - mse: 0.0321 - val_loss: 0.1141 - val_mse: 0.1141\n",
      "Epoch 294/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 0.1576 - mse: 0.1576 - val_loss: 0.0108 - val_mse: 0.0108\n",
      "Epoch 295/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 0.0190 - mse: 0.0190 - val_loss: 5.2361e-04 - val_mse: 5.2361e-04\n",
      "Epoch 296/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 0.0049 - mse: 0.0049 - val_loss: 3.5965e-04 - val_mse: 3.5965e-04\n",
      "Epoch 297/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 1.1553e-04 - mse: 1.1553e-04 - val_loss: 2.1446e-05 - val_mse: 2.1446e-05\n",
      "Epoch 298/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 1.9215e-05 - mse: 1.9215e-05 - val_loss: 7.0395e-06 - val_mse: 7.0395e-06\n",
      "Epoch 299/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 8.9765e-07 - mse: 8.9765e-07 - val_loss: 8.8835e-07 - val_mse: 8.8835e-07\n",
      "Epoch 300/300\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 1.0339e-06 - mse: 1.0339e-06 - val_loss: 3.1254e-07 - val_mse: 3.1254e-07\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train, y_train, epochs=300, batch_size=1,validation_data = (x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 학습과정 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['mse'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.plot(hist.history['val_mse'])\n",
    "#plt.ylim(0.0, 1.5)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['loss', 'mse', 'val_loss', 'val_mse'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 모델 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 2ms/sample - loss: 3.0976e-07 - mse: 3.0976e-07\n",
      "loss :  3.097564331255853e-07\n",
      "mse :  3.0975644e-07\n"
     ]
    }
   ],
   "source": [
    "loss, mse = model.evaluate(x_test, y_test, batch_size =1)\n",
    "print(\"loss : \", loss)\n",
    "print(\"mse : \", mse )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 예측하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 2)\n",
      "결과물 : \n",
      " [[ 64.000885 365.00043 ]\n",
      " [ 79.000656 380.0004  ]\n",
      " [ 90.00047  391.00043 ]\n",
      " [ 65.00088  366.00043 ]\n",
      " [ 61.00094  362.00043 ]\n",
      " [ 95.000404 396.0004  ]\n",
      " [ 63.00092  364.00043 ]\n",
      " [ 88.00052  389.0004  ]\n",
      " [ 91.000465 392.00043 ]\n",
      " [ 99.00033  400.0004  ]\n",
      " [ 92.00042  393.00043 ]\n",
      " [ 85.00054  386.00043 ]\n",
      " [ 84.000565 385.00043 ]\n",
      " [ 77.00068  378.0004  ]\n",
      " [ 69.000824 370.00043 ]\n",
      " [ 74.00073  375.00043 ]\n",
      " [ 68.000824 369.00043 ]\n",
      " [ 72.00074  373.00043 ]\n",
      " [ 83.000595 384.00043 ]\n",
      " [ 96.00035  397.00043 ]]\n"
     ]
    }
   ],
   "source": [
    "y_predict = model.predict(x_test)\n",
    "print(\"결과물 : \\n\", y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RMSE 구하기\n",
    "* __평균 제곱근 오차 - RMSE(Root Mean Squared Error)__ \n",
    "    - 회귀 분석을 평가할 때 가장 많이 사용하는 지표 중에 하나\n",
    "    - MSE에 루트를 사용\n",
    "    - 원래 데이터에서 평균을 뺀 값을 제곱하여 모두 더한 뒤 전체 개수로 나눈 값에 루트를 씌운 것\n",
    "    - RMSE는 낮을수록 정밀도가 높음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE :  0.0005564089369248688\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "def RMSE(y_test, y_predict):\n",
    "    return np.sqrt(mean_squared_error(y_test, y_predict))\n",
    "print(\"RMSE : \", RMSE(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### R2 구하기\n",
    "* __결정 계수(R2)__\n",
    "    - 회귀 분석에서 많이 사용하는 지표 중에 하나\n",
    "    - RMSE와 반대로 높을수록 좋은 지표\n",
    "    - 0~1사이의 수치 - 0.73 정도의 값이 나오면 73%의 설명력을 가진다고 해석 \n",
    "    - 사이킷런에서 r2_score 함수로 제공 \n",
    "    - 만약 R2의 값이 음수가 나오면 학습 시 머신에 뭔가 잘못된 부분이 존재한다는 의미 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 :  0.9999999978087877\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_y_predict = r2_score(y_test, y_predict)\n",
    "print(\"R2 : \", r2_y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 새로운 데이터로 예측 수행하기 \n",
    "* x_predict에 새로운 값을 설정한 후 y_predict 값을 출력한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 2)\n",
      "[[200.86781 411.412  ]\n",
      " [201.86778 412.41202]\n",
      " [202.86777 413.41202]\n",
      " [203.86775 414.41202]\n",
      " [204.86775 415.41202]\n",
      " [205.8677  416.412  ]\n",
      " [206.86769 417.41202]\n",
      " [207.8677  418.41196]\n",
      " [208.86768 419.41202]\n",
      " [209.86766 420.41202]]\n"
     ]
    }
   ],
   "source": [
    "x_predict = np.array([range(201, 211), range(411, 421)])\n",
    "x_predict = np.transpose(x_predict)    # 입력 가능한 형태로 변환 \n",
    "print(x_predict.shape)\n",
    "y_predict = model.predict(x_predict)\n",
    "print(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
