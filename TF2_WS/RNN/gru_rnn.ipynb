{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU 레이어 사용하기 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* np.random.rand(100) : 0~1 사이의 랜덤한 숫자 100 개를 만듭니다.\n",
    "* np.random.choice(100, 2, replace=False) : 100중 2개를 추출하는데 중복없이 추출\n",
    "* np.zeros(100) : 100개의 0을 가진 배열 생성\n",
    "* zeros[idx] = 1 : 리스트중에 마킹 인덱스(idx)가 저장된 부분만 1로 설정해 원-핫 인코딩 벡터를 만듭니다.\n",
    "* list(zip(zeros, lst)) : list(zip([1, 2, 3], [4, 5, 6])) --> [(1, 4), (2, 5), (3, 6)]\n",
    "* np.prod(lst[idx]) : 리스트의 각 항목 곱하기 수행 b = array([1, 2, 3, 4]) --> np.prod(b) # 123*4 --> 24m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "[[0.         0.41756098]\n",
      " [0.         0.09956395]\n",
      " [0.         0.32879244]\n",
      " [0.         0.64176105]\n",
      " [0.         0.26842916]\n",
      " [0.         0.13842666]\n",
      " [0.         0.8944894 ]\n",
      " [0.         0.62032686]\n",
      " [0.         0.38305916]\n",
      " [0.         0.68130043]\n",
      " [0.         0.34426264]\n",
      " [0.         0.43402292]\n",
      " [0.         0.52795718]\n",
      " [0.         0.51890523]\n",
      " [0.         0.06847761]\n",
      " [0.         0.64590954]\n",
      " [0.         0.19327971]\n",
      " [0.         0.7546314 ]\n",
      " [0.         0.74800374]\n",
      " [0.         0.20723881]\n",
      " [0.         0.1875694 ]\n",
      " [0.         0.21445341]\n",
      " [0.         0.88867603]\n",
      " [0.         0.11633233]\n",
      " [0.         0.69789233]\n",
      " [0.         0.77930922]\n",
      " [0.         0.1322977 ]\n",
      " [1.         0.79006155]\n",
      " [0.         0.09808603]\n",
      " [0.         0.57595428]\n",
      " [0.         0.56373601]\n",
      " [0.         0.95534903]\n",
      " [0.         0.28024304]\n",
      " [0.         0.8767781 ]\n",
      " [0.         0.37387341]\n",
      " [0.         0.3774568 ]\n",
      " [0.         0.86854563]\n",
      " [0.         0.9698596 ]\n",
      " [0.         0.02918907]\n",
      " [0.         0.12338232]\n",
      " [0.         0.24455709]\n",
      " [0.         0.44288364]\n",
      " [0.         0.19584242]\n",
      " [0.         0.23040661]\n",
      " [0.         0.27608704]\n",
      " [0.         0.83192049]\n",
      " [0.         0.56607226]\n",
      " [0.         0.4578265 ]\n",
      " [0.         0.24426381]\n",
      " [0.         0.19893562]\n",
      " [0.         0.20359167]\n",
      " [0.         0.842199  ]\n",
      " [0.         0.15350467]\n",
      " [0.         0.92165309]\n",
      " [0.         0.46310773]\n",
      " [0.         0.05032561]\n",
      " [0.         0.34075966]\n",
      " [0.         0.63889177]\n",
      " [0.         0.10268394]\n",
      " [0.         0.55218722]\n",
      " [0.         0.69381695]\n",
      " [0.         0.13420875]\n",
      " [0.         0.95174792]\n",
      " [0.         0.06389247]\n",
      " [0.         0.987519  ]\n",
      " [0.         0.46086363]\n",
      " [0.         0.96448544]\n",
      " [0.         0.1605774 ]\n",
      " [0.         0.26341547]\n",
      " [0.         0.71875609]\n",
      " [0.         0.97150339]\n",
      " [0.         0.75408598]\n",
      " [0.         0.74808069]\n",
      " [0.         0.87735297]\n",
      " [0.         0.53365649]\n",
      " [0.         0.99670394]\n",
      " [0.         0.73538069]\n",
      " [0.         0.19058076]\n",
      " [0.         0.81467058]\n",
      " [0.         0.61118476]\n",
      " [0.         0.54469008]\n",
      " [0.         0.79593211]\n",
      " [0.         0.7443749 ]\n",
      " [0.         0.49538036]\n",
      " [0.         0.37010794]\n",
      " [0.         0.61181172]\n",
      " [0.         0.64493008]\n",
      " [0.         0.05069921]\n",
      " [0.         0.63403182]\n",
      " [0.         0.7899798 ]\n",
      " [0.         0.30741372]\n",
      " [0.         0.11503851]\n",
      " [0.         0.5937955 ]\n",
      " [0.         0.23827299]\n",
      " [0.         0.03395898]\n",
      " [0.         0.03206698]\n",
      " [1.         0.45367173]\n",
      " [0.         0.86337271]\n",
      " [0.         0.68764601]\n",
      " [0.         0.15882942]]\n",
      "0.35842858853685006\n"
     ]
    }
   ],
   "source": [
    "X = []   # 입력 데이터 리스트 \n",
    "Y = []   # 결과 리스트 \n",
    "\n",
    "for i in range(3000):\n",
    "    lst = np.random.rand(100)    \n",
    "    idx = np.random.choice(100, 2, replace=False)  \n",
    "    zeros = np.zeros(100)  \n",
    "    zeros[idx] = 1  \n",
    "    \n",
    "    X.append(np.array(list(zip(zeros, lst))))  \n",
    "    Y.append(np.prod(lst[idx]))   \n",
    "\n",
    "print(len(X[0]))\n",
    "print(X[0])\n",
    "print(Y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GRU 레이어를 사용한 곱셈 문제 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru (GRU)                    (None, 100, 30)           3060      \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 30)                5580      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 8,671\n",
      "Trainable params: 8,671\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.GRU(units=30, return_sequences=True, input_shape=[100,2]),\n",
    "    tf.keras.layers.GRU(units=30),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GRU 네트워크 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2048 samples, validate on 512 samples\n",
      "Epoch 1/100\n",
      "2048/2048 [==============================] - 3s 2ms/sample - loss: 0.0505 - val_loss: 0.0486\n",
      "Epoch 2/100\n",
      "2048/2048 [==============================] - 0s 220us/sample - loss: 0.0484 - val_loss: 0.0475\n",
      "Epoch 3/100\n",
      "2048/2048 [==============================] - 0s 223us/sample - loss: 0.0480 - val_loss: 0.0473\n",
      "Epoch 4/100\n",
      "2048/2048 [==============================] - 0s 228us/sample - loss: 0.0484 - val_loss: 0.0481\n",
      "Epoch 5/100\n",
      "2048/2048 [==============================] - 0s 223us/sample - loss: 0.0485 - val_loss: 0.0481\n",
      "Epoch 6/100\n",
      "2048/2048 [==============================] - 0s 225us/sample - loss: 0.0482 - val_loss: 0.0475\n",
      "Epoch 7/100\n",
      "2048/2048 [==============================] - 0s 224us/sample - loss: 0.0480 - val_loss: 0.0471\n",
      "Epoch 8/100\n",
      "2048/2048 [==============================] - 0s 222us/sample - loss: 0.0479 - val_loss: 0.0472\n",
      "Epoch 9/100\n",
      "2048/2048 [==============================] - 0s 224us/sample - loss: 0.0487 - val_loss: 0.0471\n",
      "Epoch 10/100\n",
      "2048/2048 [==============================] - 0s 222us/sample - loss: 0.0476 - val_loss: 0.0473\n",
      "Epoch 11/100\n",
      "2048/2048 [==============================] - 0s 223us/sample - loss: 0.0478 - val_loss: 0.0473\n",
      "Epoch 12/100\n",
      "2048/2048 [==============================] - 0s 230us/sample - loss: 0.0478 - val_loss: 0.0474\n",
      "Epoch 13/100\n",
      "2048/2048 [==============================] - 0s 231us/sample - loss: 0.0478 - val_loss: 0.0468\n",
      "Epoch 14/100\n",
      "2048/2048 [==============================] - 0s 227us/sample - loss: 0.0476 - val_loss: 0.0470\n",
      "Epoch 15/100\n",
      "2048/2048 [==============================] - 0s 224us/sample - loss: 0.0474 - val_loss: 0.0469\n",
      "Epoch 16/100\n",
      "2048/2048 [==============================] - 0s 227us/sample - loss: 0.0475 - val_loss: 0.0471\n",
      "Epoch 17/100\n",
      "2048/2048 [==============================] - 0s 225us/sample - loss: 0.0471 - val_loss: 0.0460\n",
      "Epoch 18/100\n",
      "2048/2048 [==============================] - 0s 226us/sample - loss: 0.0470 - val_loss: 0.0456\n",
      "Epoch 19/100\n",
      "2048/2048 [==============================] - 0s 224us/sample - loss: 0.0442 - val_loss: 0.0255\n",
      "Epoch 20/100\n",
      "2048/2048 [==============================] - 0s 225us/sample - loss: 0.0076 - val_loss: 0.0033\n",
      "Epoch 21/100\n",
      "2048/2048 [==============================] - 0s 223us/sample - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 22/100\n",
      "2048/2048 [==============================] - 0s 223us/sample - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 23/100\n",
      "2048/2048 [==============================] - 0s 222us/sample - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 24/100\n",
      "2048/2048 [==============================] - 0s 228us/sample - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 25/100\n",
      "2048/2048 [==============================] - 0s 228us/sample - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 26/100\n",
      "2048/2048 [==============================] - 0s 224us/sample - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 27/100\n",
      "2048/2048 [==============================] - 0s 226us/sample - loss: 0.0010 - val_loss: 8.3041e-04\n",
      "Epoch 28/100\n",
      "2048/2048 [==============================] - 0s 222us/sample - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 29/100\n",
      "2048/2048 [==============================] - 0s 223us/sample - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 30/100\n",
      "2048/2048 [==============================] - 0s 226us/sample - loss: 8.3464e-04 - val_loss: 7.1787e-04\n",
      "Epoch 31/100\n",
      "2048/2048 [==============================] - 0s 221us/sample - loss: 8.9075e-04 - val_loss: 7.3959e-04\n",
      "Epoch 32/100\n",
      "2048/2048 [==============================] - 0s 222us/sample - loss: 7.7395e-04 - val_loss: 7.1015e-04\n",
      "Epoch 33/100\n",
      "2048/2048 [==============================] - 0s 224us/sample - loss: 7.1550e-04 - val_loss: 8.5966e-04\n",
      "Epoch 34/100\n",
      "2048/2048 [==============================] - 0s 223us/sample - loss: 7.7196e-04 - val_loss: 7.6454e-04\n",
      "Epoch 35/100\n",
      "2048/2048 [==============================] - 0s 225us/sample - loss: 7.1415e-04 - val_loss: 6.3713e-04\n",
      "Epoch 36/100\n",
      "2048/2048 [==============================] - 0s 222us/sample - loss: 7.1977e-04 - val_loss: 6.5540e-04\n",
      "Epoch 37/100\n",
      "2048/2048 [==============================] - 0s 223us/sample - loss: 6.2185e-04 - val_loss: 5.8982e-04\n",
      "Epoch 38/100\n",
      "2048/2048 [==============================] - 0s 225us/sample - loss: 6.1793e-04 - val_loss: 5.1916e-04\n",
      "Epoch 39/100\n",
      "2048/2048 [==============================] - 0s 226us/sample - loss: 5.9984e-04 - val_loss: 6.3555e-04\n",
      "Epoch 40/100\n",
      "2048/2048 [==============================] - 0s 224us/sample - loss: 6.3567e-04 - val_loss: 4.9106e-04\n",
      "Epoch 41/100\n",
      "2048/2048 [==============================] - 0s 225us/sample - loss: 5.2347e-04 - val_loss: 4.3675e-04\n",
      "Epoch 42/100\n",
      "2048/2048 [==============================] - 0s 224us/sample - loss: 5.5307e-04 - val_loss: 4.5710e-04\n",
      "Epoch 43/100\n",
      "2048/2048 [==============================] - 0s 226us/sample - loss: 4.8366e-04 - val_loss: 4.0431e-04\n",
      "Epoch 44/100\n",
      "2048/2048 [==============================] - 0s 223us/sample - loss: 4.5731e-04 - val_loss: 3.8610e-04\n",
      "Epoch 45/100\n",
      "2048/2048 [==============================] - 0s 226us/sample - loss: 4.5624e-04 - val_loss: 3.8380e-04\n",
      "Epoch 46/100\n",
      "2048/2048 [==============================] - 0s 224us/sample - loss: 4.4299e-04 - val_loss: 8.2367e-04\n",
      "Epoch 47/100\n",
      "2048/2048 [==============================] - 0s 224us/sample - loss: 5.3849e-04 - val_loss: 3.9451e-04\n",
      "Epoch 48/100\n",
      "2048/2048 [==============================] - 0s 225us/sample - loss: 4.4949e-04 - val_loss: 3.6288e-04\n",
      "Epoch 49/100\n",
      "2048/2048 [==============================] - 0s 224us/sample - loss: 4.0349e-04 - val_loss: 4.0463e-04\n",
      "Epoch 50/100\n",
      "2048/2048 [==============================] - 0s 226us/sample - loss: 4.5028e-04 - val_loss: 7.7813e-04\n",
      "Epoch 51/100\n",
      "2048/2048 [==============================] - 0s 223us/sample - loss: 4.6253e-04 - val_loss: 4.3946e-04\n",
      "Epoch 52/100\n",
      "2048/2048 [==============================] - 0s 225us/sample - loss: 3.5826e-04 - val_loss: 2.8944e-04\n",
      "Epoch 53/100\n",
      "2048/2048 [==============================] - 0s 223us/sample - loss: 3.6776e-04 - val_loss: 3.1924e-04\n",
      "Epoch 54/100\n",
      "2048/2048 [==============================] - 0s 221us/sample - loss: 3.6850e-04 - val_loss: 2.8390e-04\n",
      "Epoch 55/100\n",
      "2048/2048 [==============================] - 0s 222us/sample - loss: 2.9925e-04 - val_loss: 3.3801e-04\n",
      "Epoch 56/100\n",
      "2048/2048 [==============================] - 0s 227us/sample - loss: 3.2710e-04 - val_loss: 3.7623e-04\n",
      "Epoch 57/100\n",
      "2048/2048 [==============================] - 0s 224us/sample - loss: 3.1543e-04 - val_loss: 2.4908e-04\n",
      "Epoch 58/100\n",
      "2048/2048 [==============================] - 0s 227us/sample - loss: 2.9289e-04 - val_loss: 2.8329e-04\n",
      "Epoch 59/100\n",
      "2048/2048 [==============================] - 0s 225us/sample - loss: 3.0280e-04 - val_loss: 2.8289e-04\n",
      "Epoch 60/100\n",
      "2048/2048 [==============================] - 0s 224us/sample - loss: 3.2312e-04 - val_loss: 2.2880e-04\n",
      "Epoch 61/100\n",
      "2048/2048 [==============================] - 0s 226us/sample - loss: 3.2836e-04 - val_loss: 2.4796e-04\n",
      "Epoch 62/100\n",
      "2048/2048 [==============================] - 0s 224us/sample - loss: 2.6031e-04 - val_loss: 3.1465e-04\n",
      "Epoch 63/100\n",
      "2048/2048 [==============================] - 0s 224us/sample - loss: 2.9968e-04 - val_loss: 2.5598e-04\n",
      "Epoch 64/100\n",
      "2048/2048 [==============================] - 0s 223us/sample - loss: 2.6885e-04 - val_loss: 2.4767e-04\n",
      "Epoch 65/100\n",
      "2048/2048 [==============================] - 0s 223us/sample - loss: 2.8480e-04 - val_loss: 2.1467e-04\n",
      "Epoch 66/100\n",
      "2048/2048 [==============================] - 0s 220us/sample - loss: 2.3692e-04 - val_loss: 3.1747e-04\n",
      "Epoch 67/100\n",
      "2048/2048 [==============================] - 0s 223us/sample - loss: 2.6789e-04 - val_loss: 2.1076e-04\n",
      "Epoch 68/100\n",
      "2048/2048 [==============================] - 0s 224us/sample - loss: 2.6692e-04 - val_loss: 6.9230e-04\n",
      "Epoch 69/100\n",
      "2048/2048 [==============================] - 0s 225us/sample - loss: 2.8591e-04 - val_loss: 1.8832e-04\n",
      "Epoch 70/100\n",
      "2048/2048 [==============================] - 0s 224us/sample - loss: 2.2232e-04 - val_loss: 2.2226e-04\n",
      "Epoch 71/100\n",
      "2048/2048 [==============================] - 0s 222us/sample - loss: 2.8165e-04 - val_loss: 1.7507e-04\n",
      "Epoch 72/100\n",
      "2048/2048 [==============================] - 0s 223us/sample - loss: 2.2318e-04 - val_loss: 1.7834e-04\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 0s 221us/sample - loss: 2.1471e-04 - val_loss: 1.9245e-04\n",
      "Epoch 74/100\n",
      "2048/2048 [==============================] - 0s 224us/sample - loss: 2.3475e-04 - val_loss: 4.5893e-04\n",
      "Epoch 75/100\n",
      "2048/2048 [==============================] - 0s 223us/sample - loss: 2.9003e-04 - val_loss: 2.6799e-04\n",
      "Epoch 76/100\n",
      "2048/2048 [==============================] - 0s 225us/sample - loss: 2.2809e-04 - val_loss: 1.7746e-04\n",
      "Epoch 77/100\n",
      "2048/2048 [==============================] - 0s 222us/sample - loss: 1.8275e-04 - val_loss: 1.5493e-04\n",
      "Epoch 78/100\n",
      "2048/2048 [==============================] - 0s 224us/sample - loss: 1.7064e-04 - val_loss: 1.5257e-04\n",
      "Epoch 79/100\n",
      "2048/2048 [==============================] - 0s 225us/sample - loss: 1.9514e-04 - val_loss: 2.0901e-04\n",
      "Epoch 80/100\n",
      "2048/2048 [==============================] - 0s 224us/sample - loss: 2.1328e-04 - val_loss: 1.9041e-04\n",
      "Epoch 81/100\n",
      "2048/2048 [==============================] - 0s 225us/sample - loss: 1.5972e-04 - val_loss: 1.5140e-04\n",
      "Epoch 82/100\n",
      "2048/2048 [==============================] - 0s 224us/sample - loss: 1.7101e-04 - val_loss: 1.3795e-04\n",
      "Epoch 83/100\n",
      "2048/2048 [==============================] - 0s 224us/sample - loss: 1.6045e-04 - val_loss: 1.5571e-04\n",
      "Epoch 84/100\n",
      "2048/2048 [==============================] - 0s 224us/sample - loss: 1.8270e-04 - val_loss: 1.9778e-04\n",
      "Epoch 85/100\n",
      "2048/2048 [==============================] - 0s 223us/sample - loss: 1.8628e-04 - val_loss: 2.0188e-04\n",
      "Epoch 86/100\n",
      "2048/2048 [==============================] - 0s 224us/sample - loss: 1.6895e-04 - val_loss: 2.9246e-04\n",
      "Epoch 87/100\n",
      "2048/2048 [==============================] - 0s 223us/sample - loss: 1.8871e-04 - val_loss: 1.9135e-04\n",
      "Epoch 88/100\n",
      "2048/2048 [==============================] - 0s 222us/sample - loss: 1.8069e-04 - val_loss: 1.4230e-04\n",
      "Epoch 89/100\n",
      "2048/2048 [==============================] - 0s 222us/sample - loss: 1.4598e-04 - val_loss: 1.6099e-04\n",
      "Epoch 90/100\n",
      "2048/2048 [==============================] - 0s 221us/sample - loss: 1.4909e-04 - val_loss: 1.5258e-04\n",
      "Epoch 91/100\n",
      "2048/2048 [==============================] - 0s 224us/sample - loss: 1.3952e-04 - val_loss: 1.7376e-04\n",
      "Epoch 92/100\n",
      "2048/2048 [==============================] - 0s 226us/sample - loss: 1.4361e-04 - val_loss: 1.5192e-04\n",
      "Epoch 93/100\n",
      "2048/2048 [==============================] - 0s 223us/sample - loss: 1.4680e-04 - val_loss: 1.4276e-04\n",
      "Epoch 94/100\n",
      "2048/2048 [==============================] - 0s 226us/sample - loss: 1.8699e-04 - val_loss: 2.9175e-04\n",
      "Epoch 95/100\n",
      "2048/2048 [==============================] - 0s 223us/sample - loss: 1.7992e-04 - val_loss: 5.3784e-04\n",
      "Epoch 96/100\n",
      "2048/2048 [==============================] - 0s 228us/sample - loss: 1.9286e-04 - val_loss: 1.9165e-04\n",
      "Epoch 97/100\n",
      "2048/2048 [==============================] - 0s 225us/sample - loss: 1.9748e-04 - val_loss: 1.2929e-04\n",
      "Epoch 98/100\n",
      "2048/2048 [==============================] - 0s 225us/sample - loss: 1.7077e-04 - val_loss: 2.5148e-04\n",
      "Epoch 99/100\n",
      "2048/2048 [==============================] - 0s 224us/sample - loss: 1.5781e-04 - val_loss: 2.9751e-04\n",
      "Epoch 100/100\n",
      "2048/2048 [==============================] - 0s 227us/sample - loss: 1.5823e-04 - val_loss: 1.4006e-04\n"
     ]
    }
   ],
   "source": [
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "history = model.fit(X[:2560], Y[:2560], epochs=100, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 그래프로 비교하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], 'b-', label='loss')\n",
    "plt.plot(history.history['val_loss'], 'r--', label='val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440/440 [==============================] - 0s 841us/sample - loss: 1.6736e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0001673627314051952"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X[2560:], Y[2560:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 예측하고 정확도 측정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17555552034565405 \t 0.16293754 \tdiff: 0.012617983509983582 \t 정답\n",
      "0.19768719414968244 \t 0.18540321 \tdiff: 0.012283981244752329 \t 정답\n",
      "0.15216611782430678 \t 0.14741081 \tdiff: 0.004755307830562883 \t 정답\n",
      "0.24321189653244973 \t 0.23448738 \tdiff: 0.008724511974725735 \t 정답\n",
      "0.33314158628776325 \t 0.3301228 \tdiff: 0.003018787606504092 \t 정답\n",
      "correctness: 97.95454545454545 %\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(X[2560:2560+5])\n",
    "\n",
    "# 5개 테스트 데이터에 대한 예측을 표시합니다.\n",
    "for i in range(5):\n",
    "    print(Y[2560+i], '\\t', prediction[i][0], '\\tdiff:', abs(prediction[i][0] - Y[2560+i]),\"\\t\", (lambda i : \"오답\" if abs(prediction[i][0] - Y[2560+i]) > 0.04 else \"정답\")(i)  )\n",
    "    \n",
    "prediction = model.predict(X[2560:])\n",
    "fail = 0\n",
    "for i in range(len(prediction)):\n",
    "    # 오차가 0.04 이상이면 오답입니다.\n",
    "    if abs(prediction[i][0] - Y[2560+i]) > 0.04:\n",
    "        fail += 1\n",
    "print('correctness:', (440 - fail) / 440 * 100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 정확도 97.9 %란 상당히 높은 성능을 보인다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
