{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Many to Many \n",
    "* 자연어 처리에서 형태소 분석, 객체명 인식 등에 활용  \n",
    "* 각각에 대해 모두 출력을 하는 구조 \n",
    "* 토큰화 --> 태깅 \n",
    "* padding\n",
    "* masking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 준비 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 준비 \n",
    "sentences = [['I', 'feel', 'hungry'],\n",
    "     ['tensorflow', 'is', 'very', 'difficult'],\n",
    "     ['tensorflow', 'is', 'a', 'framework', 'for', 'deep', 'learning'],\n",
    "     ['tensorflow', 'is', 'very', 'fast', 'changing']]\n",
    "\n",
    "# 문법\n",
    "pos = [['pronoun', 'verb', 'adjective'],\n",
    "     ['noun', 'verb', 'adverb', 'adjective'],\n",
    "     ['noun', 'verb', 'determiner', 'noun', 'preposition', 'adjective', 'noun'],\n",
    "     ['noun', 'verb', 'adverb', 'adjective', 'verb']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 전처리 \n",
    "* 중복되지 않은 원소를 갖는 하나의 리스트 생성하기 \n",
    "* word2idx : {워드 : 인덱스 } 형태의 딕셔너리 생성 \n",
    "* idx2word : {인덱스 : 워드 } 형태의 딕셔너리 생성 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "['<pad>', 'I', 'a', 'changing', 'deep', 'difficult', 'fast', 'feel', 'for', 'framework', 'hungry', 'is', 'learning', 'tensorflow', 'very']\n",
      "{'<pad>': 0, 'I': 1, 'a': 2, 'changing': 3, 'deep': 4, 'difficult': 5, 'fast': 6, 'feel': 7, 'for': 8, 'framework': 9, 'hungry': 10, 'is': 11, 'learning': 12, 'tensorflow': 13, 'very': 14}\n",
      "{0: '<pad>', 1: 'I', 2: 'a', 3: 'changing', 4: 'deep', 5: 'difficult', 6: 'fast', 7: 'feel', 8: 'for', 9: 'framework', 10: 'hungry', 11: 'is', 12: 'learning', 13: 'tensorflow', 14: 'very'}\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "print(type(sentences))\n",
    "# 중복되지 않은 원소를 갖는 하나의 리스트 생성하기 \n",
    "word_list = sum(sentences, [])       # 하나의 리스트로 생성 \n",
    "word_list = sorted(set(word_list))   # 집합으로 만들고 정렬함 \n",
    "word_list = ['<pad>'] + word_list    # 리스트 맨 앞에 <pad> 추가 \n",
    "\n",
    "# {워드 : 인덱스 } 형태의 딕셔너리 생성 \n",
    "word2idx = {word : idx for idx, word in enumerate(word_list)}\n",
    "\n",
    "# {인덱스 : 워드 } 형태의 딕셔너리 생성 \n",
    "idx2word = {idx : word for idx, word in enumerate(word_list)}\n",
    "\n",
    "print(word_list)\n",
    "print(word2idx)\n",
    "print(idx2word)\n",
    "print(len(idx2word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 품사를 위한 토큰 사전 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<pad>', 'adjective', 'adverb', 'determiner', 'noun', 'preposition', 'pronoun', 'verb']\n",
      "{0: '<pad>', 1: 'adjective', 2: 'adverb', 3: 'determiner', 4: 'noun', 5: 'preposition', 6: 'pronoun', 7: 'verb'}\n",
      "{'<pad>': 0, 'adjective': 1, 'adverb': 2, 'determiner': 3, 'noun': 4, 'preposition': 5, 'pronoun': 6, 'verb': 7}\n"
     ]
    }
   ],
   "source": [
    "pos_list = sum(pos, [])           # 하나의 리스트로 생성 \n",
    "pos_list = sorted(set(pos_list))  # 집합으로 만들고 정렬함 \n",
    "pos_list = ['<pad>'] + pos_list   # 리스트 맨 앞에 <pad> 추가 \n",
    "\n",
    "idx2pos = {idx : pos for idx, pos in enumerate(pos_list)}\n",
    "pos2idx = {pos : idx for idx, pos in enumerate(pos_list)}\n",
    "\n",
    "print(pos_list)\n",
    "print(idx2pos)\n",
    "print(pos2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 토큰 시퀀스를 인덱스 시퀀스로 변환하고 패딩하기 \n",
    "* sentence를 word의 시퀀스로 간주하고 문제를 해결\n",
    "* 토큰인 word를 integer index로 맵핑하고 있는 토큰의 딕셔너리를 만듦\n",
    "* 정답이 품사의 시퀀스 형태로 주어져 있기 때문에 품사를 integer index로 맵핑하고 있는 딕셔너리 만듦\n",
    "* 입력과 출력의 길이가 같음을 표현하기 위해서 각각의 딕셔너리에는 pad 토큰이 포함되어 있습니다.\n",
    "* 각각의 integer index의 시퀀스를 pad_sequences function을 이용하여 max_sequence가 가리키고 있는 값만큼의 길이로 padding 합니다. \n",
    "* x_data_len : 각 문장의 길이 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  7 10  0  0  0  0  0  0  0]\n",
      " [13 11 14  5  0  0  0  0  0  0]\n",
      " [13 11  2  9  8  4 12  0  0  0]\n",
      " [13 11 14  6  3  0  0  0  0  0]] [3, 4, 7, 5]\n",
      "[[6 7 1 0 0 0 0 0 0 0]\n",
      " [4 7 2 1 0 0 0 0 0 0]\n",
      " [4 7 3 4 5 1 4 0 0 0]\n",
      " [4 7 2 1 7 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "max_sequence = 10\n",
    "x_data = list(map(lambda sentence : [word2idx.get(token) for token in sentence], sentences))\n",
    "y_data = list(map(lambda sentence : [pos2idx.get(token) for token in sentence], pos))\n",
    "\n",
    "# 패딩 \n",
    "x_data = pad_sequences(sequences=x_data, maxlen=max_sequence, padding='post', truncating='post')\n",
    "x_data_mask = ((x_data != 0) * 1).astype(np.float32)\n",
    "x_data_len = list(map(lambda sentence : len(sentence), sentences))\n",
    "\n",
    "y_data = pad_sequences(sequences=y_data, maxlen=max_sequence, padding='post', truncating='post')\n",
    "\n",
    "print(x_data, x_data_len)\n",
    "print(y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 생성 (many to many : sequence tagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "15\n",
      "15\n",
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(pos2idx)   # 결과 종류 \n",
    "hidden_dim = 10\n",
    "\n",
    "input_dim = len(word2idx)\n",
    "output_dim = len(word2idx)\n",
    "one_hot = np.eye(len(word2idx))\n",
    "\n",
    "print(num_classes)\n",
    "print(input_dim)\n",
    "print(output_dim)\n",
    "print(one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 \n",
    "* embedding layer의 경우 이전 예제들과 동일한 방식 즉 토큰을 one hot vector로 표현하고 embedding layer를 학습시키지 않으며 0으로 padding된 부분을 연산에서 제외하는 방식으로 활용 \n",
    "* return_sequences=True : RNN이 있는 모든 토큰에 대해서 출력을 내어 줌\n",
    "* 토큰(워드)는 숫자가 아니기 때문에 Embedding레이어를 이용하여 숫자로 처리할 수 있도록 변환 \n",
    "* TimeDistributed와 Dense를 이용하여 매 토큰마다 품사가 무엇인지 classification을 하는 형태로 RNN을 many to many 방식으로 활용하는 구조를 완성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 10, 15)            225       \n",
      "_________________________________________________________________\n",
      "simple_rnn_4 (SimpleRNN)     (None, 10, 10)            260       \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 10, 8)             88        \n",
      "=================================================================\n",
      "Total params: 573\n",
      "Trainable params: 348\n",
      "Non-trainable params: 225\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=input_dim, output_dim=output_dim, mask_zero=True, trainable=False, input_length=max_sequence,\n",
    "                             embeddings_initializer=tf.keras.initializers.Constant(one_hot)),\n",
    "    tf.keras.layers.SimpleRNN(units=hidden_dim, return_sequences=True),\n",
    "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(units=num_classes))\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 학습 \n",
    "* 매 토큰마다 loss를 계산\n",
    "* masking : 데이터의 시퀀스를 구성하는 토큰들 중에서 길이를 맞춰주기 위해 존재할 뿐인 pad 토큰에 대해서는 loss를 계산하지 않겠다는 개념 \n",
    "* element-wise 연산으로 마스킹을 반영"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실 함수 정의 \n",
    "def loss_fn(model, x, y, x_len, max_sequence):\n",
    "    masking = tf.sequence_mask(x_len, maxlen=max_sequence, dtype=tf.float32)\n",
    "    valid_time_step = tf.cast(x_len, dtype=tf.float32)\n",
    "    sequence_loss = tf.keras.losses.sparse_categorical_crossentropy(y_true=y, y_pred=model(x), from_logits=True) * masking\n",
    "    sequence_loss = tf.reduce_sum(sequence_loss, axis=-1) / valid_time_step\n",
    "    sequence_loss = tf.reduce_mean(sequence_loss)\n",
    "    \n",
    "    return sequence_loss\n",
    "\n",
    "#하이퍼 파라미터 \n",
    "lr = 0.1              # 학습률 확인 \n",
    "epochs = 30           # 학습 횟수 \n",
    "batch_size = 2        # 배치 크기 \n",
    "opt = tf.keras.optimizers.Adam(learning_rate=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 학습 데이터 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((None, 10), (None, 10), (None,)), types: (tf.int32, tf.int32, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "tr_dataset = tf.data.Dataset.from_tensor_slices((x_data, y_data, x_data_len)) # 데이터셋 자르기  \n",
    "tr_dataset = tr_dataset.shuffle(buffer_size=4)                                # 섞기 \n",
    "tr_dataset = tr_dataset.batch(batch_size=2)\n",
    "\n",
    "print(tr_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* many to many에서는 Sequence loss 를 계산함 \n",
    "* loss function이 시퀀스의 유효한 길이와 max_sequences를 입력으로 받고 있음\n",
    "* with 블록에서 mini batch마다의 시퀀스 loss를 계산하고 그 아래에 있는 코드로 Gradient를 계산하고 이를 이용하여 optimizer가 Gradient Descent를 하는 구조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :   5, tr_loss : 0.142\n",
      "epoch :  10, tr_loss : 0.010\n",
      "epoch :  15, tr_loss : 0.002\n",
      "epoch :  20, tr_loss : 0.001\n",
      "epoch :  25, tr_loss : 0.001\n",
      "epoch :  30, tr_loss : 0.001\n"
     ]
    }
   ],
   "source": [
    "tr_loss_hist = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    avg_tr_loss = 0\n",
    "    tr_step = 0\n",
    "    \n",
    "    for x_mb, y_mb, x_mb_len in tr_dataset:\n",
    "        with tf.GradientTape() as tape:\n",
    "            tr_loss = loss_fn(model, x=x_mb, y=y_mb, x_len=x_mb_len, max_sequence=max_sequence)\n",
    "        grads = tape.gradient(target=tr_loss, sources=model.variables)\n",
    "        opt.apply_gradients(grads_and_vars=zip(grads, model.variables))\n",
    "        avg_tr_loss += tr_loss\n",
    "        tr_step += 1\n",
    "    else:\n",
    "        avg_tr_loss /= tr_step\n",
    "        tr_loss_hist.append(avg_tr_loss)\n",
    "    \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print('epoch : {:3}, tr_loss : {:.3f}'.format(epoch + 1, avg_tr_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 0. 0. 0. 0. 0.]]\n",
      "[['pronoun', 'verb', 'adjective', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'],\n",
      " ['noun', 'verb', 'adverb', 'adjective', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'],\n",
      " ['noun', 'verb', 'determiner', 'noun', 'preposition', 'adjective', 'noun', '<pad>', '<pad>', '<pad>'],\n",
      " ['noun', 'verb', 'adverb', 'adjective', 'verb', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']]\n",
      "[['pronoun', 'verb', 'adjective'],\n",
      " ['noun', 'verb', 'adverb', 'adjective'],\n",
      " ['noun', 'verb', 'determiner', 'noun', 'preposition', 'adjective', 'noun'],\n",
      " ['noun', 'verb', 'adverb', 'adjective', 'verb']]\n"
     ]
    }
   ],
   "source": [
    "print(x_data_mask)\n",
    "yhat = model.predict(x_data)\n",
    "yhat = np.argmax(yhat, axis=-1) * x_data_mask\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(list(map(lambda row : [idx2pos.get(elm) for elm in row], yhat.astype(np.int32).tolist())), width=120)\n",
    "pprint(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x205ee107848>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(tr_loss_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
