{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Many to Many Bidirectional \n",
    "* 형태소 분석기 \n",
    "* many to many 방식으로 데이터를 읽을 때 불균형 발생 이를 해결하기 위해 bidirectional 방식을 사용 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from pprint import pprint\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 준비 \n",
    "sentences = [['I', 'feel', 'hungry'],\n",
    "     ['tensorflow', 'is', 'very', 'difficult'],\n",
    "     ['tensorflow', 'is', 'a', 'framework', 'for', 'deep', 'learning'],\n",
    "     ['tensorflow', 'is', 'very', 'fast', 'changing']]\n",
    "\n",
    "# 문법(품사)\n",
    "pos = [['pronoun', 'verb', 'adjective'],\n",
    "     ['noun', 'verb', 'adverb', 'adjective'],\n",
    "     ['noun', 'verb', 'determiner', 'noun', 'preposition', 'adjective', 'noun'],\n",
    "     ['noun', 'verb', 'adverb', 'adjective', 'verb']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 전처리\n",
    "* 중복되지 않은 원소를 갖는 하나의 리스트 생성하기\n",
    "* word2idx : {워드 : 인덱스 } 형태의 딕셔너리 생성\n",
    "* idx2word : {인덱스 : 워드 } 형태의 딕셔너리 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "['<pad>', 'I', 'a', 'changing', 'deep', 'difficult', 'fast', 'feel', 'for', 'framework', 'hungry', 'is', 'learning', 'tensorflow', 'very']\n",
      "{'<pad>': 0, 'I': 1, 'a': 2, 'changing': 3, 'deep': 4, 'difficult': 5, 'fast': 6, 'feel': 7, 'for': 8, 'framework': 9, 'hungry': 10, 'is': 11, 'learning': 12, 'tensorflow': 13, 'very': 14}\n",
      "{0: '<pad>', 1: 'I', 2: 'a', 3: 'changing', 4: 'deep', 5: 'difficult', 6: 'fast', 7: 'feel', 8: 'for', 9: 'framework', 10: 'hungry', 11: 'is', 12: 'learning', 13: 'tensorflow', 14: 'very'}\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "print(type(sentences))\n",
    "# 중복되지 않은 원소를 갖는 하나의 리스트 생성하기 \n",
    "word_list = sum(sentences, [])       # 하나의 리스트로 생성 \n",
    "word_list = sorted(set(word_list))   # 집합으로 만들고 정렬함 \n",
    "word_list = ['<pad>'] + word_list    # 리스트 맨 앞에 <pad> 추가 \n",
    "\n",
    "# {워드 : 인덱스 } 형태의 딕셔너리 생성 \n",
    "word2idx = {word : idx for idx, word in enumerate(word_list)}\n",
    "\n",
    "# {인덱스 : 워드 } 형태의 딕셔너리 생성 \n",
    "idx2word = {idx : word for idx, word in enumerate(word_list)}\n",
    "\n",
    "print(word_list)\n",
    "print(word2idx)\n",
    "print(idx2word)\n",
    "print(len(idx2word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 품사를 위한 토큰 사전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<pad>', 'adjective', 'adverb', 'determiner', 'noun', 'preposition', 'pronoun', 'verb']\n",
      "{0: '<pad>', 1: 'adjective', 2: 'adverb', 3: 'determiner', 4: 'noun', 5: 'preposition', 6: 'pronoun', 7: 'verb'}\n",
      "{'<pad>': 0, 'adjective': 1, 'adverb': 2, 'determiner': 3, 'noun': 4, 'preposition': 5, 'pronoun': 6, 'verb': 7}\n"
     ]
    }
   ],
   "source": [
    "pos_list = sum(pos, [])           # 하나의 리스트로 생성 \n",
    "pos_list = sorted(set(pos_list))  # 집합으로 만들고 정렬함 \n",
    "pos_list = ['<pad>'] + pos_list   # 리스트 맨 앞에 <pad> 추가 \n",
    "\n",
    "idx2pos = {idx : pos for idx, pos in enumerate(pos_list)}\n",
    "pos2idx = {pos : idx for idx, pos in enumerate(pos_list)}\n",
    "\n",
    "print(pos_list)\n",
    "print(idx2pos)\n",
    "print(pos2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 토큰 시퀀스를 인덱스 시퀀스로 변환하고 패딩하기\n",
    "* sentence를 word의 시퀀스로 간주하고 문제를 해결\n",
    "* 토큰인 word를 integer index로 맵핑하고 있는 토큰의 딕셔너리를 만듦\n",
    "* 정답이 품사의 시퀀스 형태로 주어져 있기 때문에 품사를 integer index로 맵핑하고 있는 딕셔너리 만듦\n",
    "* 입력과 출력의 길이가 같음을 표현하기 위해서 각각의 딕셔너리에는 pad 토큰이 포함되어 있습니다.\n",
    "* 각각의 integer index의 시퀀스를 pad_sequences function을 이용하여 max_sequence가 가리키고 있는 값만큼의 길이로 padding 합니다.\n",
    "* x_data_len : 각 문장의 길이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  7 10  0  0  0  0  0  0  0]\n",
      " [13 11 14  5  0  0  0  0  0  0]\n",
      " [13 11  2  9  8  4 12  0  0  0]\n",
      " [13 11 14  6  3  0  0  0  0  0]] [3, 4, 7, 5]\n",
      "[[1. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 0. 0. 0. 0. 0.]]\n",
      "[[6 7 1 0 0 0 0 0 0 0]\n",
      " [4 7 2 1 0 0 0 0 0 0]\n",
      " [4 7 3 4 5 1 4 0 0 0]\n",
      " [4 7 2 1 7 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "max_sequence = 10\n",
    "x_data = list(map(lambda sentence : [word2idx.get(token) for token in sentence], sentences))\n",
    "y_data = list(map(lambda sentence : [pos2idx.get(token) for token in sentence], pos))\n",
    "\n",
    "# 패딩 - 길이를 맞춰줌 \n",
    "x_data = pad_sequences(sequences=x_data, maxlen=max_sequence, padding='post', truncating='post')\n",
    "x_data_mask = ((x_data != 0) * 1).astype(np.float32)\n",
    "x_data_len = list(map(lambda sentence : len(sentence), sentences))\n",
    "\n",
    "y_data = pad_sequences(sequences=y_data, maxlen=max_sequence, padding='post', truncating='post')\n",
    "\n",
    "print(x_data, x_data_len)\n",
    "print(x_data_mask)\n",
    "print(y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 생성 (many to many : sequence tagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "15\n",
      "15\n",
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(pos2idx)   # 결과 종류 \n",
    "hidden_dim = 10\n",
    "\n",
    "input_dim = len(word2idx)\n",
    "output_dim = len(word2idx)\n",
    "one_hot = np.eye(len(word2idx))\n",
    "\n",
    "print(num_classes)\n",
    "print(input_dim)\n",
    "print(output_dim)\n",
    "print(one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델\n",
    "* 기존 모델에 tf.keras.layers.Bidirectional을 추가하면 Bidirectional RNN으로 모델링 됨\n",
    "* embedding layer의 경우 이전 예제들과 동일한 방식 즉 토큰을 one hot vector로 표현하고 embedding layer를 학습시키지 않으며 0으로 padding된 부분을 연산에서 제외하는 방식으로 활용\n",
    "* return_sequences=True : RNN이 있는 모든 토큰에 대해서 출력을 내어 줌\n",
    "* 토큰(워드)는 숫자가 아니기 때문에 Embedding레이어를 이용하여 숫자로 처리할 수 있도록 변환\n",
    "* TimeDistributed와 Dense를 이용하여 매 토큰마다 품사가 무엇인지 classification을 하는 형태로 RNN을 many to many 방식으로 활용하는 구조를 완성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 10, 15)            225       \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 10, 20)            520       \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 10, 8)             168       \n",
      "=================================================================\n",
      "Total params: 913\n",
      "Trainable params: 688\n",
      "Non-trainable params: 225\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=input_dim, output_dim=output_dim, mask_zero=True, trainable=False, input_length=max_sequence,\n",
    "                             embeddings_initializer=tf.keras.initializers.Constant(one_hot)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.SimpleRNN(units=hidden_dim, return_sequences=True)),\n",
    "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(units=num_classes))\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 학습\n",
    "* 매 토큰마다 loss를 계산\n",
    "* masking : 데이터의 시퀀스를 구성하는 토큰들 중에서 길이를 맞춰주기 위해 존재할 뿐인 pad 토큰에 대해서는 loss를 계산하지 않겠다는 개념\n",
    "* element-wise 연산으로 마스킹을 반영"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실 함수 정의 \n",
    "def loss_fn(model, x, y, x_len, max_sequence):\n",
    "    masking = tf.sequence_mask(x_len, maxlen=max_sequence, dtype=tf.float32)\n",
    "    valid_time_step = tf.cast(x_len, dtype=tf.float32)\n",
    "    sequence_loss = tf.keras.losses.sparse_categorical_crossentropy(y_true=y, y_pred=model(x), from_logits=True) * masking\n",
    "    sequence_loss = tf.reduce_sum(sequence_loss, axis=-1) / valid_time_step\n",
    "    sequence_loss = tf.reduce_mean(sequence_loss)\n",
    "    \n",
    "    return sequence_loss\n",
    "\n",
    "#하이퍼 파라미터 \n",
    "lr = 0.1              # 학습률 확인 \n",
    "epochs = 30           # 학습 횟수 \n",
    "batch_size = 2        # 배치 크기 \n",
    "opt = tf.keras.optimizers.Adam(learning_rate=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 학습 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((None, 10), (None, 10), (None,)), types: (tf.int32, tf.int32, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "tr_dataset = tf.data.Dataset.from_tensor_slices((x_data, y_data, x_data_len)) # 데이터셋 자르기  \n",
    "tr_dataset = tr_dataset.shuffle(buffer_size=4)                                # 섞기 \n",
    "tr_dataset = tr_dataset.batch(batch_size=2)\n",
    "\n",
    "print(tr_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 학습 수행 \n",
    "* many to many에서는 Sequence loss 를 계산함\n",
    "* loss function이 시퀀스의 유효한 길이와 max_sequences를 입력으로 받고 있음\n",
    "* with 블록에서 mini batch마다의 시퀀스 loss를 계산하고 그 아래에 있는 코드로 Gradient를 계산하고 이를 이용하여 optimizer가 Gradient Descent를 하는 구조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :   5, tr_loss : 0.034\n",
      "epoch :  10, tr_loss : 0.002\n",
      "epoch :  15, tr_loss : 0.000\n",
      "epoch :  20, tr_loss : 0.000\n",
      "epoch :  25, tr_loss : 0.000\n",
      "epoch :  30, tr_loss : 0.000\n"
     ]
    }
   ],
   "source": [
    "tr_loss_hist = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    avg_tr_loss = 0\n",
    "    tr_step = 0\n",
    "    \n",
    "    for x_mb, y_mb, x_mb_len in tr_dataset:\n",
    "        with tf.GradientTape() as tape:\n",
    "            tr_loss = loss_fn(model, x=x_mb, y=y_mb, x_len=x_mb_len, max_sequence=max_sequence)\n",
    "        grads = tape.gradient(target=tr_loss, sources=model.variables)\n",
    "        opt.apply_gradients(grads_and_vars=zip(grads, model.variables))\n",
    "        avg_tr_loss += tr_loss\n",
    "        tr_step += 1\n",
    "    else:\n",
    "        avg_tr_loss /= tr_step\n",
    "        tr_loss_hist.append(avg_tr_loss)\n",
    "    \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print('epoch : {:3}, tr_loss : {:.3f}'.format(epoch + 1, avg_tr_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 0. 0. 0. 0. 0.]]\n",
      "[['pronoun', 'verb', 'adjective', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'],\n",
      " ['noun', 'verb', 'adverb', 'adjective', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'],\n",
      " ['noun', 'verb', 'determiner', 'noun', 'preposition', 'adjective', 'noun', '<pad>', '<pad>', '<pad>'],\n",
      " ['noun', 'verb', 'adverb', 'adjective', 'verb', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']]\n",
      "[['pronoun', 'verb', 'adjective'],\n",
      " ['noun', 'verb', 'adverb', 'adjective'],\n",
      " ['noun', 'verb', 'determiner', 'noun', 'preposition', 'adjective', 'noun'],\n",
      " ['noun', 'verb', 'adverb', 'adjective', 'verb']]\n"
     ]
    }
   ],
   "source": [
    "print(x_data_mask)\n",
    "yhat = model.predict(x_data)\n",
    "yhat = np.argmax(yhat, axis=-1) * x_data_mask\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(list(map(lambda row : [idx2pos.get(elm) for elm in row], yhat.astype(np.int32).tolist())), width=120)\n",
    "pprint(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x203f9197388>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(tr_loss_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
